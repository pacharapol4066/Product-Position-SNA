{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoY8sy40TCb5"
   },
   "source": [
    "### IS - Brand position\n",
    "Finding Product position on Social Network (PPSN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28353,
     "status": "ok",
     "timestamp": 1604024868503,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "GkBEUBUqTGuf",
    "outputId": "cb22db45-820a-48fd-c11a-a0568439778f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1604024868819,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_5mrzpx3TH9K",
    "outputId": "129bb192-4ac2-4b03-bc89-7ee7a65d5032"
   },
   "source": [
    "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Master_PJ_DRMABS/Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1604024879769,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cC0cBdCdTCb6"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import pymongo\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1604024879770,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "1kqXURiiTCb-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1604028167896,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "weEcXSD8TCcI",
    "outputId": "1219680e-0d54-4649-a26e-535e112f0650"
   },
   "outputs": [],
   "source": [
    "#!pip install pythainlp\n",
    "import pythainlp\n",
    "from pythainlp import Tokenizer\n",
    "from pythainlp.util import normalize\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus.common import thai_words\n",
    "from pythainlp import sent_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.util import dict_trie\n",
    "from pythainlp.tag import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpa16DrfTCeL"
   },
   "outputs": [],
   "source": [
    "# https://thainlp.org/pythainlp/docs/2.0/api/tag.html\n",
    "from pythainlp.spell import correct\n",
    "from pythainlp.tag import pos_tag\n",
    "\n",
    "#https://thainlp.org/pythainlp/docs/2.0/api/transliterate.html\n",
    "from pythainlp.transliterate import romanize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score\n",
    "import scipy.stats\n",
    "from scipy.spatial.distance import cosine\n",
    "#from mlxtend.evaluate import lift_score\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1604027698593,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "sna_e7nATCch"
   },
   "outputs": [],
   "source": [
    "# Files definition\n",
    "root_input_path = 'Datasource'\n",
    "root_output_path = 'output'\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(root_input_path+\"/comment_meiji.csv\")\n",
    "#comment_file.append(root_input_path+\"/comment_DDCF.csv\")\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(\"comment_meiji.csv\")\n",
    "#comment_file.append(\"comment_DDCF.csv\")\n",
    "\n",
    "comment_nlp_file = root_output_path+\"/comment_nlpToken.csv\"\n",
    "comment_cooc_freq_file = root_output_path+\"/comment_cooc_freq.xlsx\"\n",
    "comment_cooc_lift_file = root_output_path+\"/comment_cooc_Lift.xlsx\"\n",
    "comment_cooc_jacc_file = root_output_path+\"/comment_cooc_jacc.xlsx\"\n",
    "comment_cooc_corr_file = root_output_path+\"/comment_cooc_corr.xlsx\"\n",
    "comment_cooc_cosine_file = root_output_path+\"/comment_cooc_cosine.xlsx\"\n",
    "\n",
    "#comment_nlp_file = \"comment_nlpToken.csv\"\n",
    "#comment_cooc_nlp_file = \"comment_cooc.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"NIDA_PPSN_PRD\"]\n",
    "col_thread = mydb[\"NIDA_PPSN_THREAD\"]\n",
    "col_comment = mydb[\"NIDA_PPSN_COMMENT\"]\n",
    "col_scrape = mydb[\"NIDA_PPSN_SCRAPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.get_term_topics เทียบคำที่ได้ไป Review Literature ตามค่าความน่าจะเป็น แล้วสรุป Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Domain ที่พบหลักๆ นอกเหนือจากตัว Product ห้างที่ขาย แบรนด์ (อย่างไรก็ตามต้องทำ LDA Vis อีกรอบเพื่อจัดกลุ่มใหม่หลังคัดเลือก Topic/Term)</b><br>\n",
    "ค้นหาเทียบเคียงกับ ปัจจัยที่มีผลต่อการบริโภคนม\n",
    "1. แม่และเด็ก (Kurajdova et al, 2015)\n",
    "2. ออกกำลังกาย เล่นเวท วิ่ง พูดถึง Whey หางนม โปรตีน เป็นหลัก (คิดว่าแตกจากหมวดสุขภาพ)\n",
    "3. โปรโมชั่น เช่น จัดโปร ส่วนลด พันแถม แพ๊กคู่ (สุภชาติ ชัยณรงค์สิงห์, 2539)\n",
    "4. เอานมให้หมาแมวกิน (เทรนด์ใหม่)\n",
    "5. รสชาติและคุณภาพ เช่น หอม เหม็น มัน อร่อย บูด เสีย GMP (ชาลิสา สถีระกานนท์, 2560)\n",
    "6. ความยากง่ายในการหาซื้อ (Aen De Alwis et al, 2009 & สุภชาติ ชัยณรงค์สิงห์, 2539)\n",
    "7. ทำกาแฟ ทำขนม (Kurajdova et al, 2015)\n",
    "8. สุขภาพ ความสูง ส่วนผสมเพื่อสุขภาพ การขับถ่าย อนุมูลอิสระ (Kurajdova et al, 2015 & Aen De Alwis et al, 2009 & สุภชาติ ชัยณรงค์สิงห์, 2539)\n",
    "9. ราคาและความคุ้มค่า (ปิยฉัตร ช่างเหล็ก, 2561)\n",
    "<br><br>ตรงนี้ต้องหา Paper มาช่วยยันในบางหัวข้อ ถ้ามีส่วนเกินถือว่าเป็นบริบทของประเทศไทย"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# องค์ประกอบพื้นฐาน ตาม master ที่ใช้ตัดคำ และ Generalized\n",
    "#get_terms_topics('ซื้อ',dictionary,model)\n",
    "#get_terms_topics('ขาย',dictionary,model)\n",
    "\n",
    "# ไล่เช็คทีละ Topic โดยเลือกจาก Top30 Prob แต่ละกลุ่ม และดูตัวที่สนใจ (ตามทบทวนวรรณกรรม)\n",
    "# สุดที่ 99 กลุ่ม\n",
    "#get_topics_terms(99,dictionary,model).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.สรุป Term & reduced_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrributes = ['การบูด','โปร','โปรโมชั่น','แถม','บูด','เป็นผลดี','หา','หมดอายุ', 'กลิ่น','หอม','กลิ่นหอม', 'แนะนำ', 'กิน', 'shelf life','แม่','คุณแม่'\n",
    " ,'ลูก','เด็ก','เลี้ยงลูก','เลี้ยงเด็ก','พัฒนาการ','คุณแม่มือใหม่','สั่ง', 'ค่าใช้จ่าย', 'เพิ่มขึ้น', 'สินค้า', 'ชอบ','นิยม', 'สี', 'ซื้อไม่ได้'\n",
    " , 'ทิ้ง', 'จืด','หวาน' , 'fat', 'นิยม','ราคาสูง','กาแฟ','ชงกาแฟ','หาย','ต้ม','อุ่น','ร้อน', 'พื้นฐาน', 'ขายไม่ดี','สูง','ส่วนสูง'\n",
    " , 'กาแฟสด', 'จ่าย', 'ขาย', 'รส','รสชาติ', 'กลมกล่อม','ไขมัน','พนักงาน','ไมโครเวฟ','ฟาร์ม'\n",
    " ,'ส่วนผสม','ผสม','เบาหวาน','รสพื้นฐาน','โปรตีน','เวย์','เวท','วิ่ง','protein','whey','ขับถ่าย','อึ','dha','น้ำตาล','เบาหวาน'\n",
    " ,'ฝา', 'นมสด','ถ้วย', 'ร้าน', 'ดื่ม', 'เซเว่น', 'ขวด', 'นึกถึง', 'เสียใจ', 'แตก', 'ซื้อ','ขาย','มีลูก','เทรนเนอร์'\n",
    " ,'ขายไม่ดี','แพคคู่','ค่าจัดส่ง','shelf life','พนักงานขายนม','แพ้นม','แพ้นมวัว','เล่นเวท','ฝาน้ำเงิน','ฝาสีเขียว'\n",
    " ,'นมอุ่น','ชานม','กินนม','ดื่มนม','ท้องเสีย','ลูกสุนัข','สุนัข','หมา','แมว','คายทิ้ง','เจมส์จิ','แป้ง','ลดราคา'\n",
    " ,'ซื้อประจำ','ซื้อไม่ได้','คาปูชิโน่','อเมริกาโน่','ร้านนม','whey formula','ผิดสังเกต','เสียความรู้สึก','ชี้แจง','บำรุง','น้ำผึ้ง'\n",
    " ,'อาหารเสริม','มีประโยชน์','วิตามิน','นมผง','แคลเซี่ยม','ท้อง','แพะ','อร่อย','โภชนาการ','โรงเรียน','พ่อแม่','ครู','ยูเอชที'\n",
    " ,'ผู้บริโภค','ขโมย','ไอโอดีน','นมข้นหวาน','เนย','ตรวจสอบ','แกลลอน','มันดี','นมวัว','อาเจียน','เวฟ','ไมโครเวฟ','สารอาหาร'\n",
    " ,'ขนส่ง','ถูก','แพง','เค้ก','ทิ้ง','วันหมดอายุ','โอเมก้า','กล่อง','พลังงาน','โภชนาการ','ขนมปัง','ของแถม','ราคาสูง','น้ำนมโค'\n",
    " ,'บรรจุภัณฑ์','นมถั่วเหลือง','ความแข็งแรง','แข็งแรง','พรีเซ็นเตอร์','ญี่ปุ่น','น้ำผลไม้','ออกกำลังกาย','ประหยัด','วิปปิ้ง','เชื้อจุลินทรีย์'\n",
    " ,'แลคโตส']\n",
    "\n",
    "stores = ['tops','makro','lotus','bigc','7-Eleven']\n",
    "\n",
    "products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ']\n",
    "milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์']\n",
    "\n",
    "reduceCol = attrributes + stores\n",
    "reduceCol_all = attrributes + stores + milk_kind + products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(reduceCol_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_keyword(wtkn,redCol):\n",
    "    del_list = []\n",
    "    ret_wtkn = wtkn\n",
    "    for each in ret_wtkn:\n",
    "        if each not in redCol:\n",
    "            del_list.append(each)\n",
    "    ret_wtkn = [x for x in ret_wtkn if x not in del_list]\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKW--A73mzli"
   },
   "source": [
    "### 7.สร้าง (Custom) Bag of word ด้วย dictionary.doc2bow จัดลง dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คัด headline ที่พูดถึง domain นม\n",
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]\n",
    "df_urls_milk['t_mention_dairy'] = df_urls_milk['t_mention_dairy'].apply(lambda x: repr(x))\n",
    "df_urls_milk['t_mention_brand'] = df_urls_milk['t_mention_brand'].apply(lambda x: repr(x))\n",
    "df_urls_milk['t_mention_product'] = df_urls_milk['t_mention_product'].apply(lambda x: repr(x))\n",
    "\n",
    "df_cmt_process['cmt_mention_dairy'] = df_cmt_process['cmt_mention_dairy'].apply(lambda x: repr(x))\n",
    "df_cmt_process['cmt_mention_brand'] = df_cmt_process['cmt_mention_brand'].apply(lambda x: repr(x))\n",
    "df_cmt_process['cmt_mention_product'] = df_cmt_process['cmt_mention_product'].apply(lambda x: repr(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เมื่อ join กันแล้ว คอมเม้นทุกคอมเม้นจะอยู่ใน domain นมทั้งหมด\n",
    "df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['_id_x','_id_y','headline_y'],inplace=True)\n",
    "df_join_url.rename(columns={\"headline_x\":\"headline\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x,reduceCol))\n",
    "#df_join_url['token_text_reduce_tfidf'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x,reduceCol_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.set_index('commentId',inplace=True)\n",
    "df_join_url.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text_reduce'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dictionary_tfidf = gensim.corpora.Dictionary(df_join_url['token_text_reduce_tfidf'])\n",
    "#gensim_corpus = [dictionary_tfidf.doc2bow(text, allow_update=True) for text in df_join_url['token_text_reduce_tfidf']]\n",
    "#tfidf_model = TfidfModel(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['reduce_bow'] = df_join_url[\"token_text_reduce\"].map(dictionary.doc2bow)\n",
    "df_join_url['reduce_bow_txt'] = df_join_url[\"reduce_bow\"].apply(lambda x:[(dictionary[id_], frequence) for id_, frequence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def freq_brand(x):\n",
    "    e = eval(x)\n",
    "    e.sort()\n",
    "    f = [(k,len(list(g))) for k, g in groupby(e)]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['t_mention_dairy'] = df_join_url['t_mention_dairy'].apply(lambda x: freq_brand(x))\n",
    "df_join_url['t_mention_product'] = df_join_url['t_mention_product'].apply(lambda x: freq_brand(x))\n",
    "df_join_url['t_mention_brand'] = df_join_url['t_mention_brand'].apply(lambda x: freq_brand(x))\n",
    "df_join_url['cmt_mention_dairy'] = df_join_url['cmt_mention_dairy'].apply(lambda x: freq_brand(x))\n",
    "df_join_url['cmt_mention_product'] = df_join_url['cmt_mention_product'].apply(lambda x: freq_brand(x))\n",
    "df_join_url['cmt_mention_brand'] = df_join_url['cmt_mention_brand'].apply(lambda x: freq_brand(x))\n",
    "df_join_url.drop(columns=['Retrived_date','reduce_bow'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.insert(3,'mention_domain',value=None)\n",
    "df_join_url.insert(4,'mention_product',value=None)\n",
    "df_join_url.insert(5,'mention_brand',value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute brand & product เข้า comment และสรุปก่อนเข้า BoW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Impute จากหัวกระทู้\n",
    "\n",
    "# 1.headline มี comment มี เอา comment\n",
    "# 2.headline มี comment ไม่มี เอา headline\n",
    "# 3.headline ไม่มี comment มี เอา comment\n",
    "# 4.ไม่มีทั้งคู่ ปล่อยไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.t_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) == 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_domain'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.t_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) == 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_brand'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.t_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) == 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_product'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['t_mention_dairy','t_mention_product','t_mention_brand'\n",
    "                          ,'cmt_mention_dairy','cmt_mention_product','cmt_mention_brand'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf_list = []\n",
    "#for doc in tfidf_model[gensim_corpus]:\n",
    "#    tfidf_list.append([(dictionary_tfidf[id], np.around(freq, decimals=4)) for id, freq in doc])\n",
    "#df_join_url.insert(11,'reduce_tfidf',value=tfidf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cooccurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brand_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"mention_brand\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)\n",
    "df_prd_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"mention_product\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)\n",
    "df_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"reduce_bow_txt\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Matrix\n",
    "#df_tfidf_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"reduce_tfidf\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)\n",
    "#df_tfidf_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brand_cooc.reset_index(inplace=True)\n",
    "df_prd_cooc.reset_index(inplace=True)\n",
    "df_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = pd.merge(df_brand_cooc, df_prd_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "join_df = pd.merge(join_df, df_cooc, on='commentId', how='inner')\n",
    "join_df.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EpwX95XlTCdl",
    "_Q9pU1J6TCe5",
    "NKW--A73mzli",
    "uBBA36fDTCfZ",
    "O8nlNNE4TCfj"
   ],
   "name": "EDA_Token_CoocMat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
