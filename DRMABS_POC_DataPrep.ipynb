{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IS Proof of concept - DRMABS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import bigrams\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install pythainlp\n",
    "import pythainlp\n",
    "from pythainlp import word_tokenize, Tokenizer\n",
    "from pythainlp.corpus.common import thai_words\n",
    "from pythainlp import sent_tokenize\n",
    "from pythainlp.corpus import thai_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Files definition\n",
    "root_path = 'Datasource'\n",
    "urls_past_file = root_path+\"/urls_pasteurized.csv\"\n",
    "comment_past_file = root_path+\"/comment_pasteurized.csv\"\n",
    "comment_past_nlp_file = root_path+\"/comment_nlp_pasteurized.csv\"\n",
    "\n",
    "# จำนวนกระทู้ที่ต้องการให้ดึงใน 1 นาที\n",
    "postNum = 6\n",
    "postNumSleep = math.ceil(60/postNum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### กรณียังไม่เคยดึง URL ที่มีการพูดถึง Keyword ใน Pantip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get list of URL from search page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = 'https://pantip.com/search?q=นมพาสเจอร์ไรส์'\n",
    "driver = webdriver.Chrome(executable_path='selenium/chromedriver.exe')\n",
    "driver.get(urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scroll down to get all data (Crawler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all URLs (web scraping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=driver.page_source\n",
    "soup=BeautifulSoup(content,'lxml')\n",
    "urlList = []\n",
    "# ใช้ class_ เพื่อดึง div class จำเพาะ เพื่อไม่ให้ข้อความอื่นที่ไม่ต้องการปนมา\n",
    "for div in soup.find_all(\"div\", class_=lambda value: value and value==\"title col-md-12\"):\n",
    "    for a in div.find_all(\"a\", class_=lambda value: value and value==\"datasearch-in\", href=True):\n",
    "        urlList.append(str(a['href']).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save URLs into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls = pd.DataFrame(urlList)\n",
    "df_urls.insert(1,'Retrived date',today)\n",
    "df_urls.columns = ['URLs','Retrived date']\n",
    "df_urls.to_csv(urls_past_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### กรณีเคยเก็บ URL แล้ว ให้เริ่มตรงนี้ได้เลย เพื่อไม่ให้ต้องทำ Request บ่อยๆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop for scaping by URLs from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_URLRead = pd.read_csv(urls_past_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>Retrived date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://pantip.com/topic/39702636</td>\n",
       "      <td>2020-09-22 11:08:36.425204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pantip.com/topic/39799524</td>\n",
       "      <td>2020-09-22 11:08:36.425204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://pantip.com/topic/39797060</td>\n",
       "      <td>2020-09-22 11:08:36.425204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://pantip.com/topic/39907475</td>\n",
       "      <td>2020-09-22 11:08:36.425204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://pantip.com/topic/40142515</td>\n",
       "      <td>2020-09-22 11:08:36.425204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                URLs               Retrived date\n",
       "0  https://pantip.com/topic/39702636  2020-09-22 11:08:36.425204\n",
       "1  https://pantip.com/topic/39799524  2020-09-22 11:08:36.425204\n",
       "2  https://pantip.com/topic/39797060  2020-09-22 11:08:36.425204\n",
       "3  https://pantip.com/topic/39907475  2020-09-22 11:08:36.425204\n",
       "4  https://pantip.com/topic/40142515  2020-09-22 11:08:36.425204"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_URLRead.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_urls = list(df_URLRead['URLs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "startResult = 0\n",
    "endResult = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_list = []\n",
    "for cnt,au in enumerate(all_urls[startResult:endResult],0):\n",
    "    driver = webdriver.Chrome(executable_path='selenium/chromedriver.exe')\n",
    "    driver.get(au)\n",
    "    content=driver.page_source\n",
    "    soup=BeautifulSoup(content,'lxml')\n",
    "    for div in soup.find_all(\"div\", class_=lambda value: value and value==\"display-post-story\"):\n",
    "        #if len(str(div.text).strip()) > 1:\n",
    "        comments_list.append([au,str(div.text).strip()])\n",
    "    time.sleep(postNumSleep)\n",
    "    driver.quit()\n",
    "    \n",
    "    #จำกัดจำนวนกระทู้ สำหรับ Debug\n",
    "    #if cnt == 3:\n",
    "    #    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comments = pd.DataFrame(comments_list)\n",
    "df_comments.insert(2,'Retrived date',today)\n",
    "df_comments.columns = ['URLs', 'text', 'Retrived date']\n",
    "df_comments.to_csv(comment_past_file, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### กรณีเคย Scraping ลงไฟล์แล้ว เริ่มตรงนี้ได้เลย ป้องกันโดนแบน IP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean data & NLP Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkStopwords(w):\n",
    "    returnList = []\n",
    "    stopwords = list(thai_stopwords())\n",
    "    for i in w:  # comment\n",
    "        if i not in stopwords:\n",
    "            returnList.append(i)\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_textList = pd.read_csv(comment_past_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_importantKey():\n",
    "    keys = ['ซีพี','เมจิ','ดัชมิลล์','dairy home','แดรี่โฮม'\n",
    "            ,'สตอเบอรี่','ช็อกโกแล็ต','คอนเฟล็ก'\n",
    "            ,'พาสเจอร์ไรซ์','พลาสเจอ','พาสเจอร์ไรส์','ฟาสเจอร์'\n",
    "            ,'พลาสติก','พาสติก',\n",
    "            'ดัชมิลล์selected','grass fed milk']\n",
    "    return keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "garbage_char = [string.punctuation,'\\xa0',' ','\\n']\n",
    "\n",
    "words = set(thai_words())  # thai_words() returns frozenset\n",
    "for i in token_importantKey():\n",
    "    words.add(i)\n",
    "custom_tokenizer = Tokenizer(words)\n",
    "\n",
    "for ii in list(df_textList['text']):\n",
    "    #wtkn = sent_tokenize(ii, engine=\"whitespace+newline\")\n",
    "    wtkn = custom_tokenizer.word_tokenize(ii)\n",
    "    wtkn = [w for w in wtkn if w.isalnum()]\n",
    "    wtkn = [x for x in wtkn if x not in garbage_char]\n",
    "    wtkn = [y.strip('.') for y in wtkn]\n",
    "    wtkn = [s for s in wtkn if not s.isdigit()]\n",
    "    corpus.append(wtkn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge list\n",
    "merge_corpus_list = list(itertools.chain.from_iterable(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "chk_corpus_list = checkStopwords(merge_corpus_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['รบกวน',\n",
       " 'ปอ',\n",
       " 'โท',\n",
       " 'ทำ',\n",
       " 'นม',\n",
       " 'ขวด',\n",
       " 'เพราะอะไร',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'ตอบ',\n",
       " 'ตอน',\n",
       " 'นม',\n",
       " 'พลาสเจอ',\n",
       " 'ขวด',\n",
       " 'นมสด',\n",
       " 'นมสด',\n",
       " 'ตอน',\n",
       " 'วาง',\n",
       " 'แถม',\n",
       " 'หาย',\n",
       " 'ขนาด',\n",
       " 'สาย',\n",
       " 'https',\n",
       " 'sites',\n",
       " 'google',\n",
       " 'com',\n",
       " 'site',\n",
       " 'khorngnganthnxmxahar',\n",
       " 'ทน',\n",
       " 'ขวด',\n",
       " 'ขนาด',\n",
       " 'cc',\n",
       " 'ขวด',\n",
       " 'ขวด',\n",
       " 'ขวด',\n",
       " 'ทนทาน',\n",
       " 'ขวด',\n",
       " 'ขวด',\n",
       " 'Cost',\n",
       " 'แตก',\n",
       " 'เบา',\n",
       " 'ทน',\n",
       " 'ทน',\n",
       " 'ผม',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'นะคะ',\n",
       " 'หา',\n",
       " 'คอม',\n",
       " 'มอน',\n",
       " 'หา',\n",
       " 'คน',\n",
       " 'นม',\n",
       " 'ไหม',\n",
       " 'ตามใจ',\n",
       " 'ปาก',\n",
       " 'ขนม',\n",
       " 'อาหาร',\n",
       " 'ขยะ',\n",
       " 'ชา',\n",
       " 'ขนม',\n",
       " 'อาหาร',\n",
       " 'อาหาร',\n",
       " 'ถาม',\n",
       " 'ขาย',\n",
       " 'นม',\n",
       " 'ขวด',\n",
       " 'ไหม',\n",
       " 'ขวด',\n",
       " 'บาท',\n",
       " 'ตก',\n",
       " 'ขวด',\n",
       " 'บาท',\n",
       " 'ขวด',\n",
       " 'บาท',\n",
       " 'หรอ',\n",
       " 'ขวด',\n",
       " 'บาท',\n",
       " 'ขวด',\n",
       " 'บาท',\n",
       " 'ขวด',\n",
       " 'นม',\n",
       " 'ขวด',\n",
       " 'เจอ',\n",
       " 'ไหม',\n",
       " 'เมษายน',\n",
       " 'เวลา',\n",
       " 'อากาศ',\n",
       " 'ตา',\n",
       " 'ตรวจ',\n",
       " 'เสมอ',\n",
       " 'นม',\n",
       " 'ราด',\n",
       " 'ทราบ',\n",
       " 'นม',\n",
       " 'กาย',\n",
       " 'รอ',\n",
       " 'อาการ',\n",
       " 'แมว',\n",
       " 'แมว',\n",
       " 'คาบ',\n",
       " 'แมว',\n",
       " 'ฝน',\n",
       " 'ฝาก',\n",
       " 'รอ',\n",
       " 'หมอ',\n",
       " 'บอ',\n",
       " 'รอด',\n",
       " 'หย',\n",
       " 'อดนม',\n",
       " 'แพะ',\n",
       " 'นม',\n",
       " 'นะคะ',\n",
       " 'หยอด',\n",
       " 'CC',\n",
       " 'นม',\n",
       " 'ตอน',\n",
       " 'ตา',\n",
       " 'รอบ',\n",
       " 'ตะ',\n",
       " 'หย',\n",
       " 'อดนม',\n",
       " 'ทำ',\n",
       " 'รอด',\n",
       " 'รอด',\n",
       " 'ไหม',\n",
       " 'นมผง',\n",
       " 'แมว',\n",
       " 'แนะนำ',\n",
       " 'นม',\n",
       " 'แพะ',\n",
       " 'ขวดนม',\n",
       " 'แมว',\n",
       " 'ทำตาม',\n",
       " 'โครงการ',\n",
       " 'แนวทาง',\n",
       " 'นม',\n",
       " 'จำนวน',\n",
       " 'ประกาศ',\n",
       " 'คณะกรรมการ',\n",
       " 'อาหาร',\n",
       " 'นม',\n",
       " 'เยาวชน',\n",
       " 'นม',\n",
       " 'ภาวะ',\n",
       " 'สร',\n",
       " 'ศ',\n",
       " 'เผย',\n",
       " 'นม',\n",
       " 'แนวทาง',\n",
       " 'นม',\n",
       " 'รายงาน',\n",
       " 'นม',\n",
       " 'ประกาศ',\n",
       " 'นม',\n",
       " 'UHT',\n",
       " 'นม',\n",
       " 'UHT',\n",
       " 'ลดราคา',\n",
       " 'นม',\n",
       " 'UHT',\n",
       " 'นม',\n",
       " 'ประกาศ',\n",
       " 'ประสาน',\n",
       " 'แนวทาง',\n",
       " 'โครงการ',\n",
       " 'นม',\n",
       " 'มาตรฐาน',\n",
       " 'https',\n",
       " 'www',\n",
       " 'facebook',\n",
       " 'com',\n",
       " 'MheeRlaii',\n",
       " 'posts',\n",
       " 'เวลา',\n",
       " 'ขวบ',\n",
       " 'นม',\n",
       " 'นม',\n",
       " 'ชง',\n",
       " 'บอ',\n",
       " 'แนะนำ',\n",
       " 'ขวบ',\n",
       " 'นม',\n",
       " 'ธรรมดา',\n",
       " 'ขาย',\n",
       " 'นม',\n",
       " 'เนย',\n",
       " 'อาหาร',\n",
       " 'นม',\n",
       " 'แกลลอน',\n",
       " 'นอน',\n",
       " 'ขวบ',\n",
       " 'ทาน',\n",
       " 'uht',\n",
       " 'ทาน',\n",
       " 'Gold',\n",
       " 'Progress',\n",
       " 'UHT',\n",
       " 'ทาน',\n",
       " 'รส',\n",
       " 'หอม',\n",
       " 'หวาน',\n",
       " 'สารอาหาร',\n",
       " 'ทราบ',\n",
       " 'นม',\n",
       " 'อาหาร',\n",
       " 'ราคา',\n",
       " 'นมสด',\n",
       " 'ภาพ',\n",
       " 'ไหม',\n",
       " 'นมสด',\n",
       " 'ชอบ',\n",
       " 'นม',\n",
       " 'วจะ',\n",
       " 'นม',\n",
       " 'แตก',\n",
       " 'ตรงไหน',\n",
       " 'คำตอบ',\n",
       " 'ㅜㅡㅜ',\n",
       " 'นมสด',\n",
       " 'นม',\n",
       " 'ไข',\n",
       " 'ขาย',\n",
       " 'สดๆ',\n",
       " 'บอ',\n",
       " 'แทบ',\n",
       " 'pasteurized',\n",
       " 'milk',\n",
       " 'นม',\n",
       " 'dairy',\n",
       " 'product',\n",
       " 'pasteurization',\n",
       " 'ทำลาย',\n",
       " 'โรค',\n",
       " 'คน',\n",
       " 'pathogen',\n",
       " 'การทำงาน',\n",
       " 'นมสด',\n",
       " 'ผม',\n",
       " 'ป',\n",
       " 'เหรอ',\n",
       " 'ชอบ',\n",
       " 'นม',\n",
       " 'ยา',\n",
       " 'นม',\n",
       " 'โรค',\n",
       " 'คน',\n",
       " 'ไปหา',\n",
       " 'ชวน',\n",
       " 'ทำ',\n",
       " 'ส',\n",
       " 'ชอบ',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'ลอง',\n",
       " 'ทำ',\n",
       " 'มาจาก',\n",
       " 'นะคะ',\n",
       " 'ตอน',\n",
       " 'ทำ',\n",
       " 'ฟอง',\n",
       " 'นม',\n",
       " 'แพะ',\n",
       " 'เนย',\n",
       " 'นะคะ',\n",
       " 'ตอน',\n",
       " 'ทำ',\n",
       " 'ทำ',\n",
       " 'รอบ',\n",
       " 'นม',\n",
       " 'แพะ',\n",
       " 'ลอง',\n",
       " 'ทำ',\n",
       " 'ขนม',\n",
       " 'ปรากฎ',\n",
       " 'นา',\n",
       " 'คาว',\n",
       " 'แพะ',\n",
       " 'Single',\n",
       " 'Farm',\n",
       " 'ลอง',\n",
       " 'บอ',\n",
       " 'ผสม',\n",
       " 'นมผง',\n",
       " 'ลอง',\n",
       " 'คาว',\n",
       " 'พ',\n",
       " 'ไบโอ',\n",
       " 'สารอาหาร',\n",
       " 'http',\n",
       " 'bit',\n",
       " 'ly',\n",
       " 'N',\n",
       " 'RBeN',\n",
       " 'นมสด',\n",
       " 'กวน',\n",
       " 'คน',\n",
       " 'นะคะ',\n",
       " 'เตา',\n",
       " 'เนย',\n",
       " 'เนย',\n",
       " 'ละลาย',\n",
       " 'ยย',\n",
       " 'ทำ',\n",
       " 'แอบ',\n",
       " 'หา',\n",
       " 'คาว',\n",
       " 'หวาน',\n",
       " 'นม',\n",
       " 'แพะ',\n",
       " 'แพะ',\n",
       " 'ซอส',\n",
       " 'โท',\n",
       " 'สต',\n",
       " 'เนย',\n",
       " 'กรอบ',\n",
       " 'ตามมา',\n",
       " 'ประโคม',\n",
       " 'สส',\n",
       " 'รส',\n",
       " 'แอบ',\n",
       " 'กลบ',\n",
       " 'หวาน',\n",
       " 'เจอ',\n",
       " 'ซอส',\n",
       " 'รส',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'งง',\n",
       " 'document',\n",
       " 'ready',\n",
       " 'function',\n",
       " 'sel',\n",
       " 'rating',\n",
       " 'readOnly',\n",
       " 'true',\n",
       " 'แพะ',\n",
       " 'Single',\n",
       " 'Farm',\n",
       " 'คะแนน',\n",
       " 'samgee',\n",
       " 'em',\n",
       " 'color',\n",
       " 'ccc',\n",
       " 'px',\n",
       " 'SR',\n",
       " 'Sponsored',\n",
       " 'Review',\n",
       " 'กระ',\n",
       " 'SR',\n",
       " 'ไอ',\n",
       " 'มร',\n",
       " 'สว',\n",
       " 'ลา',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'กก',\n",
       " 'ออกมา',\n",
       " 'ซอส',\n",
       " 'ซอส',\n",
       " 'BBQ',\n",
       " 'ชอบ',\n",
       " 'เครป',\n",
       " 'ตอน',\n",
       " 'เครป',\n",
       " 'ซอส',\n",
       " 'ซอส',\n",
       " 'แปลก',\n",
       " 'ของคาว',\n",
       " 'ของหวาน',\n",
       " 'ซอส',\n",
       " 'เจอ',\n",
       " 'แซ',\n",
       " 'น',\n",
       " 'ช',\n",
       " 'กรอบ',\n",
       " 'ซอส',\n",
       " 'กก',\n",
       " 'บอ',\n",
       " 'ลอง',\n",
       " 'นม',\n",
       " 'แพะ',\n",
       " 'ลอง',\n",
       " 'ทำ',\n",
       " 'นะคะ',\n",
       " 'มมม',\n",
       " 'ป',\n",
       " 'ลอง',\n",
       " 'นม',\n",
       " 'แพะ',\n",
       " 'ตรา',\n",
       " 'ราคา',\n",
       " 'บาท',\n",
       " 'นม',\n",
       " 'นม',\n",
       " 'นม',\n",
       " 'กลบ',\n",
       " 'กลบ',\n",
       " 'ระบบ',\n",
       " 'บรรยากาศ',\n",
       " 'สนทนา',\n",
       " 'โดยรวม',\n",
       " 'Pantip',\n",
       " 'com',\n",
       " 'ลบ',\n",
       " 'ระบบ',\n",
       " 'กลบ',\n",
       " 'application',\n",
       " 'Pantip',\n",
       " 'com',\n",
       " 'ทางกฎหมาย',\n",
       " 'application',\n",
       " 'โดยตรง',\n",
       " 'เผลอ']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chk_corpus_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus_list = pd.DataFrame(chk_corpus_list)\n",
    "df_corpus_list.columns = ['text']\n",
    "df_corpus_list.to_csv(comment_past_nlp_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
