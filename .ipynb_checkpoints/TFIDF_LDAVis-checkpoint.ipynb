{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoY8sy40TCb5"
   },
   "source": [
    "### IS - Brand position\n",
    "Finding Product position on Social Network (PPSN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28353,
     "status": "ok",
     "timestamp": 1604024868503,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "GkBEUBUqTGuf",
    "outputId": "cb22db45-820a-48fd-c11a-a0568439778f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1604024868819,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_5mrzpx3TH9K",
    "outputId": "129bb192-4ac2-4b03-bc89-7ee7a65d5032"
   },
   "source": [
    "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Master_PJ_DRMABS/Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1604024879769,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cC0cBdCdTCb6"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import pymongo\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\types\\oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\builtins\\misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1604024879770,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "1kqXURiiTCb-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6121,
     "status": "ok",
     "timestamp": 1604024888335,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "acWWFhczTCcO"
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 5596,
     "status": "ok",
     "timestamp": 1604024888336,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "l0SZe4-LTCcd"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"NIDA_PPSN_PRD\"]\n",
    "col_thread = mydb[\"NIDA_PPSN_THREAD\"]\n",
    "col_comment = mydb[\"NIDA_PPSN_COMMENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_keyword(wtkn,redCol):\n",
    "    del_list = []\n",
    "    ret_wtkn = wtkn\n",
    "    for each in ret_wtkn:\n",
    "        if each not in redCol:\n",
    "            del_list.append(each)\n",
    "    ret_wtkn = [x for x in ret_wtkn if x not in del_list]\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Process หัวกระทู้เพื่อดึง Domain (Brand & Product) ไม่ใช้โมเดลเทรนแล้วทำนาย ต้องการความถูกต้อง 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# จริงๆต้องใช้เงื่อนไข t_mention_brand.str.len() != 0 และ t_mention_dairy.str.len() != 0\n",
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_brand.str.len() != 0) | (df_thr_process.t_mention_dairy.str.len() != 0)]\n",
    "df_urls_milk['t_mention_brand'] = df_urls_milk['t_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_product'] = df_urls_milk['t_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['_id_x','_id_y','headline_x'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')\n",
    "#df_join_url.drop(columns=['_id_x','_id_y','headline_x'],inplace=True)\n",
    "df_join_url.columns = ['URLs','token_headline','t_mention_dairy','t_mention_product','t_mention_brand'\n",
    "                       ,'commentId','headline','text','Retrived_date','token_text','cmt_mention_dairy'\n",
    "                       ,'cmt_mention_product','cmt_mention_brand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>t_mention_dairy</th>\n",
       "      <th>t_mention_product</th>\n",
       "      <th>t_mention_brand</th>\n",
       "      <th>commentId</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>Retrived_date</th>\n",
       "      <th>token_text</th>\n",
       "      <th>cmt_mention_dairy</th>\n",
       "      <th>cmt_mention_product</th>\n",
       "      <th>cmt_mention_brand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>{'รสหวาน'}</td>\n",
       "      <td>{'เมจิ'}</td>\n",
       "      <td>1</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "      <td>[ปี, 7-Eleven, ยังมี, นม, เมจิ, รสหวาน, ขาย, อ...</td>\n",
       "      <td>[นม, นม]</td>\n",
       "      <td>[รสหวาน, รสหวาน]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>{'รสหวาน'}</td>\n",
       "      <td>{'เมจิ'}</td>\n",
       "      <td>2</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เบาหวานครับ แฮ่ๆ</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "      <td>[เบาหวาน, แฮ่]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>{'รสหวาน'}</td>\n",
       "      <td>{'เมจิ'}</td>\n",
       "      <td>3</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "      <td>[หาซื้อไม่ได้นี่คิดได้, , คน, กินกัน, ทำ, คน, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[รสหวาน]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                URLs             token_headline  \\\n",
       "0  https://pantip.com/topic/39868603  [นม, เมจิ, รสหวาน, หายาก]   \n",
       "1  https://pantip.com/topic/39868603  [นม, เมจิ, รสหวาน, หายาก]   \n",
       "2  https://pantip.com/topic/39868603  [นม, เมจิ, รสหวาน, หายาก]   \n",
       "\n",
       "  t_mention_dairy t_mention_product t_mention_brand  commentId  \\\n",
       "0            [นม]        {'รสหวาน'}        {'เมจิ'}          1   \n",
       "1            [นม]        {'รสหวาน'}        {'เมจิ'}          2   \n",
       "2            [นม]        {'รสหวาน'}        {'เมจิ'}          3   \n",
       "\n",
       "                     headline  \\\n",
       "0  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "2  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "\n",
       "                                                text           Retrived_date  \\\n",
       "0  เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา... 2020-11-29 00:13:26.571   \n",
       "1                                   เบาหวานครับ แฮ่ๆ 2020-11-29 00:13:26.571   \n",
       "2  หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย... 2020-11-29 00:13:26.571   \n",
       "\n",
       "                                          token_text cmt_mention_dairy  \\\n",
       "0  [ปี, 7-Eleven, ยังมี, นม, เมจิ, รสหวาน, ขาย, อ...          [นม, นม]   \n",
       "1                                     [เบาหวาน, แฮ่]                []   \n",
       "2  [หาซื้อไม่ได้นี่คิดได้, , คน, กินกัน, ทำ, คน, ...                []   \n",
       "\n",
       "  cmt_mention_product cmt_mention_brand  \n",
       "0    [รสหวาน, รสหวาน]            [เมจิ]  \n",
       "1                  []                []  \n",
       "2            [รสหวาน]                []  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join_url.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_product']]\n",
    "df_view.column = ['URLs','t_mention_product']\n",
    "df_view_count = df_view.groupby('t_mention_product').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_urls_milk = df_cmt_process[(df_cmt_process.cmt_mention_brand.str.len() != 0) | (df_cmt_process.cmt_mention_product.str.len() != 0)]\n",
    "df_c_urls_milk['cmt_mention_brand'] = df_c_urls_milk['cmt_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_product'] = df_c_urls_milk['cmt_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_view2 = df_c_urls_milk[['URLs','cmt_mention_product']]\n",
    "df_view2.column = ['URLs','cmt_mention_product']\n",
    "df_view_count2 = df_view2.groupby('cmt_mention_product').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวนกระทู้ 1515\n",
      "จำนวน comment 62710\n",
      "จำนวนกระทู้พูดถึง brand หรือ มีนมเกี่ยวข้อง อย่างใดอย่างหนึ่ง 436\n",
      "จำนวนกระทู้มีระบุตัว product 52\n",
      "จำนวน comment พูดถึง brand หรือมีนมเกี่ยวข้องง อย่างใดอย่างหนึ่ง 4660\n",
      "จำนวน comment มีระบุตัว product 2124\n",
      "odd product/นม กระทู้ 0.12\n",
      "odd product/นม comment 0.46\n",
      "หมายเหตุ : ไม่ได้ impute ขั้วกระทู้เข้า comment\n"
     ]
    }
   ],
   "source": [
    "print('จำนวนกระทู้',df_thr_process.shape[0])\n",
    "print('จำนวน comment',df_cmt_process.shape[0])\n",
    "print('จำนวนกระทู้พูดถึง brand หรือ มีนมเกี่ยวข้อง อย่างใดอย่างหนึ่ง',df_urls_milk.shape[0])\n",
    "print('จำนวนกระทู้มีระบุตัว product',df_view[(df_view.t_mention_product!=\"{'นม'}\")&(df_view.t_mention_product!=\"set()\")].shape[0])\n",
    "print('จำนวน comment พูดถึง brand หรือมีนมเกี่ยวข้องง อย่างใดอย่างหนึ่ง',df_c_urls_milk.shape[0])\n",
    "print('จำนวน comment มีระบุตัว product',df_view2[(df_view2.cmt_mention_product!=\"{'นม'}\")&(df_view2.cmt_mention_product!=\"set()\")].shape[0])\n",
    "print('odd product/นม กระทู้',round(df_view[(df_view.t_mention_product!=\"{'นม'}\")&(df_view.t_mention_product!=\"set()\")].shape[0]/df_urls_milk.shape[0],2))\n",
    "print('odd product/นม comment',round(df_view2[(df_view2.cmt_mention_product!=\"{'นม'}\")&(df_view2.cmt_mention_product!=\"set()\")].shape[0]/df_c_urls_milk.shape[0],2))\n",
    "print('หมายเหตุ : ไม่ได้ impute ขั้วกระทู้เข้า comment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "จาก Issue นี้จะพบว่าทำ Product position ได้ยาก แต่ทำ Brand position แทนได้ เนื่องจากสัดส่วนของข้อความที่มีการพูดถึง brand+flavor \n",
    "มีน้อยกว่าครึ่ง จึงให้ใช้วิธีเอา brand ของหัวกระทู้แปะไปในทุก comment แทน เพื่อทำ Brand Position ส่วน flavor จะกลายเป็น attribute ไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cmt_mention_product</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>set()</th>\n",
       "      <td>2536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'รสจืด'}</th>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'ช็อกโกแลต'}</th>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'ไขมันต่ำ'}</th>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'รสหวาน'}</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'รสจืด', 'รสกล้วย', 'สตรอว์เบอร์รี'}</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'มอลต์', 'ช็อกโกแลต', 'ไขมันต่ำ', 'รสกาแฟ'}</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'มอลต์', 'ไขมัน 0%'}</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'รสกลมกล่อม', 'รสธรรมชาติ', 'ไขมันต่ำ'}</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'รสหวาน', 'มอลต์'}</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>157 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              URLs\n",
       "cmt_mention_product                               \n",
       "set()                                         2536\n",
       "{'รสจืด'}                                      294\n",
       "{'ช็อกโกแลต'}                                  261\n",
       "{'ไขมันต่ำ'}                                   185\n",
       "{'รสหวาน'}                                     140\n",
       "...                                            ...\n",
       "{'รสจืด', 'รสกล้วย', 'สตรอว์เบอร์รี'}            1\n",
       "{'มอลต์', 'ช็อกโกแลต', 'ไขมันต่ำ', 'รสกาแฟ'}     1\n",
       "{'มอลต์', 'ไขมัน 0%'}                            1\n",
       "{'รสกลมกล่อม', 'รสธรรมชาติ', 'ไขมันต่ำ'}         1\n",
       "{'รสหวาน', 'มอลต์'}                              1\n",
       "\n",
       "[157 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_view_count2.sort_values(by='URLs',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. (ยกเลิกแต่เก็บ code) คัดเลือกคำมาเป็น Attribute ด้วย TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import gensim\n",
    "#from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag of Word & calculate TF-IDF\n",
    "#dictionary = gensim.corpora.Dictionary(df_join_url['token_text'])\n",
    "#gensim_corpus = [dictionary.doc2bow(text, allow_update=True) for text in df_join_url['token_text']]\n",
    "#model = TfidfModel(gensim_corpus)\n",
    "#vector = model[gensim_corpus]\n",
    "#word_frequencies = [[(dictionary[id], tfidf_val) for id, tfidf_val in couple] for couple in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,len(word_frequencies)):\n",
    "#    word_frequencies[i].sort(key=lambda tup:(-tup[1], tup[0]))  # SORT LIST of TUPLE DESCENDINGLY\n",
    "#    word_frequencies[i] = word_frequencies[i][:10]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List complehension : get the first element of each tuple in a list\n",
    "# https://www.kite.com/python/answers/how-to-get-the-first-element-of-each-tuple-in-a-list-in-python\n",
    "#first_tuple_elements = [[a for a,tf in couple] for couple in word_frequencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_tuple_elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. คัดเลือกคำมาเป็น Attribute ด้วย LDAvis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/models/ldamodel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Bag of Word & calculate TF-IDF\n",
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text'])\n",
    "gensim_corpus = [dictionary.doc2bow(text, allow_update=True) for text in df_join_url['token_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.6 s\n"
     ]
    }
   ],
   "source": [
    "num_topics = 20\n",
    "chunksize = 5000                  # size of the doc looked at every pass\n",
    "iterations = 50\n",
    "eval_every = 1                    # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "%time model = gensim.models.LdaModel(corpus=gensim_corpus, id2word=id2word, chunksize=chunksize \\\n",
    "                                     ,alpha='auto', eta='auto',iterations=iterations \\\n",
    "                                     ,num_topics=num_topics \\\n",
    "                                     , eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pyLDAvis.gensim.prepare(model, gensim_corpus, dictionary, R=40, lambda_step=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the most relevant topics to the given word.\n",
    "# Set probability = 0.0001\n",
    "\n",
    "#def get_terms_topics(term_text, d, model, minProb=0.0001):\n",
    "#    listofTup = []\n",
    "#    for tt_couple in model.get_term_topics(dictionary.token2id[term_text], minimum_probability=minProb):\n",
    "#        id_, prob = tt_couple\n",
    "#        listofTup.append((d[id_], prob))\n",
    "#    df = pd.DataFrame(listofTup)\n",
    "#    df.insert(0,'Term',value=term_text)\n",
    "#    df.columns = ['Term','topic','prob']\n",
    "#    return df.sort_values(by='prob', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# องค์ประกอบพื้นฐาน ตาม master ที่ใช้ตัดคำ และ Generalized\n",
    "#get_terms_topics('ซื้อ',dictionary,model)\n",
    "#get_terms_topics('ขาย',dictionary,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the most relevant topics to the given word.\n",
    "# Set probability = 0.0001\n",
    "\n",
    "def get_topics_terms(topic, d, model, minProb=0.0001):\n",
    "    listofTup = []\n",
    "    for tt_couple in model.get_topic_terms(topic, topn=100):\n",
    "        id_, prob = tt_couple\n",
    "        listofTup.append((d[id_], prob))\n",
    "    df = pd.DataFrame(listofTup)\n",
    "    df.insert(0,'Topic',value=d[topic])\n",
    "    df.columns = ['Topic','term','prob']\n",
    "    return df.sort_values(by='prob', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ไล่เช็คทีละ Topic โดยเลือกจาก Top100 Prob แต่ละกลุ่ม และดูตัวที่สนใจ (ตามทบทวนวรรณกรรม)\n",
    "# สุดที่ num_topics = 20 กลุ่ม\n",
    "\n",
    "for i in range(0,20):\n",
    "    if i ==0:\n",
    "        df = get_topics_terms(i, dictionary, model)\n",
    "    else:\n",
    "        df = df.append(get_topics_terms(i, dictionary, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='term', keep='first', inplace=True, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['term'].to_excel('uniqueText.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สรุปคำที่จะนำมาเป็น Attribute (รวม link ที่เป็นเคสยกเว้น)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrributes = ['hiq','lactose','เกินไป','เข้มข้น','เจ้าหน้าที่','เจือจาง','เด็ก','เต้าฮวย','เติบโต','เติม','เท','เนย','เนื้อ'\n",
    "               ,'เปรี้ยว','เปลี่ยนไป','เพื่อน','เมลาโทนิน','เย็น','เยี่ยม','เลี้ยง','เลี้ยงดู','เลี้ยงลูก','เวย์','เสี่ยง','แกลลอน','แก้ว','แข็งแรง','แคลเซียม','แคลเซี่ยม','แช่เย็น'\n",
    "               ,'แดรี่โฮม','แถม','แนะนำ','แพ้','แพ็ค','แพง','แพ้นม','แพ้นมวัว','แพะ','แฟน','แม่','แมว','โกโก้','โค','โฆษณา','โด๊ป','โปรโมชั่น','โปรตีน','โรงเรียน'\n",
    "               ,'โรงพยาบาล','โอเมก้า','ในประเทศ','ให้นม','ไขมัน','ไขมันต่ำ','ไม่ชอบ','ไม่อร่อย','ไอโอดีน','กระดูก','กรีก','กล้วย','กล่อง','กลัว','กลิ่น','กาแฟ'\n",
    "               ,'การผลิต','กิจกรรม','ข้น','ขวด','ครอบครัว','ครีม','คลอด','คลอดลูก','ความเจ็บปวด','ความมัน','ความร้อน','ความสุข','ค่าขนส่ง','คาว','คุณแม่'\n",
    "               ,'คุณค่า','คุณภาพ','คุ้ม','งาน','จิตรลดา','จืด','จุลินทรีย์','ชง','ชอบ','ชาเขียว','ชาไข่มุก','ชานมไข่มุก','ชิม','ซื้อ','ญี่ปุ่น','ดั้งเดิม','ดี','ต้ม','ตอนเช้า'\n",
    "               ,'ตอนกลางวัน','ตั้งครรภ์','ตั้งท้อง','ติดใจ','ตู้เย็น','ถ้วย','ท้อง','ท้องเสีย','ท้องผูก','นมเปรี้ยว','นมโคแท้','นมกล่อง','นมข้น','นมควาย','นมถั่วเหลือง'\n",
    "               ,'นมผง','นมวัว','นมสด','นอน','น้ำตาล','น้ำนม','น้ำนมโค','น้ำผลไม้','น้ำผึ้ง','บรรจุ','บริจาค','บูด','ปริมาณ','ปรุงแต่ง','ปลอดภัย','ปวดท้อง','ผง'\n",
    "               ,'ผลไม้','ผลิต','ผสม','ผัก','ผู้หญิง','ฝา','พกพา','พนักงาน','พยาบาล','พลังงาน','พ่อ','พาสเจอร์ไรส์','ฟาร์ม','มะนาว','มะพร้าว','มะลิ','มีประโยชน์'\n",
    "               ,'มีปัญหา','มีลูก','มื้อ','ยาคูลท์','รสกลมกล่อม','รสกาแฟ','รสจืด','รสชาติ','รสธรรมชาติ','รสหวาน','ราคาแพง','ร่างกาย','ร้าน','ลดราคา','ลอง','ลำไส้'\n",
    "               ,'ลูก','ลูกค้า','ลูกชาย','ลูกสาว','วัว','วิตามิน','ส่วนผสม','สะดวก','สารอาหาร','สิ่งแปลกปลอม','สีน้ำเงิน','สีส้ม','สุดยอด','สูตร','หมดอายุ','หมอ','หมา'\n",
    "               ,'หวาน','หอม','ห้าง','หางนม','หาซื้อ','อยากสูง','อร่อย','อ้วก','ออกกำลังกาย','อาหาร','อึ','อุณหภูมิ','อุ่น','ไขมันทรานส์','ดาราเดลี่','แดรี่ฟาร์ม','แดรี่ควีน'\n",
    "               ,'ยืดเส้นยืดสาย','ฟุตบอล','กระโดดเชือก','มวลกระดูก','ของแถม','ราคาสูง','บรรจุภัณฑ์','ความแข็งแรง','แข็งแรง','พรีเซ็นเตอร์','แลคโตส','ขายไม่ดี'\n",
    "               ,'แพคคู่','ค่าจัดส่ง','shelf life','พนักงานขายนม','ซื้อประจำ','หายาก','คุมอาหาร','นักวิ่ง','ร้านนมสด','ดูแลสุขภาพ','เจมส์ จิ','เจมส์จิ','ณเดช','ณเดชน์'\n",
    "               ,'อยากสูง','ส่วนสูง','สูงขึ้น','รักษามะเร็ง','รักษาเบาหวาน','ทำฟอง','ตีฟอง','โฟมนม','มื้อเช้า']\n",
    "\n",
    "stores = ['tops','makro','lotus','bigc','7-Eleven']\n",
    "\n",
    "products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ','วิปครีม']\n",
    "\n",
    "milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์','nondairy','non dairy']\n",
    "\n",
    "#  EDA ใน Excel ได้ flavor 68 ตัว (ถ้าดึงยี่ห้ออื่นก็เพิ่มอีก)\n",
    "avai_flavs = ['เมจิเมจิโกลด์','เมจิเมล่อน','เมจิไขมัน 0%','เมจิไขมันต่ำ','เมจิไฮโปรตีน','เมจิช็อกโกแลต','เมจิชาเขียวมัจฉะ','เมจิดาร์คช็อกโกแลต'\n",
    " ,'เมจินมฟรีแลคโตส','เมจิบัลแกเรีย','เมจิมอลต์','เมจิรสกลมกล่อม','เมจิรสกล้วย','เมจิรกาแฟ','เมจิรสจืด','เมจิรสธรรมชาติ','เมจิรสหวาน'\n",
    " ,'เมจิสตรอว์เบอร์รี','เมจิอัลมอนด์','เอ็มมิลค์นมฟรีแลคโตส','เอ็มมิลค์รสจืด','แดรี่โฮมgrass fed','แดรี่โฮมเบดไทม์','แดรี่โฮมช็อกโกแลต'\n",
    " ,'แดรี่โฮมรสกล้วย','แดโฮมรสจืด','แดรี่โฮมรสหวาน','แดรี่โฮมสตรอว์เบอร์รี','แมคโนเลียไขมันต่ำ','แมคโนเลียช็อกโกแลต','แมคโนเลียรสจืด'\n",
    " ,'โชคชัยไขมันต่ำ','โชคชัยช็อกโกแลต','โชคชัยรสกาแฟ','โชคชัยรสจืด','โชคชัยสตรอว์เบอร์รี','ฟร์โมสต์ไขมัน 0%','โฟร์โมสต์ไขมันต่ำ'\n",
    " ,'โฟร์โมสต์คาราเมล','โฟร์โมสต์ช็อกโกแลต','โฟร์โมสต์รสกาแฟ','โฟร์โมสต์รสจืด','โฟร์โมสต์สตรอว์เบอร์รี','ไทยเดนมาร์คช็อกโกแลต'\n",
    " ,'ไทยเดนมาร์ครสกาแฟ','ไทยเดนมาร์ครสจืด','ไทยเดนมาร์ครสหวาน','ไทยเดนมาร์คสตรอว์เบอร์รี','คาเนชั่นรสจืด','จิตรลดาช็อกโกแลต'\n",
    " ,'จิตรลดารสจืด','จิตรลดารสหวาน','จิตรลดาสตรอว์เบอร์รี','ดัชมิลล์ไขมัน 0%','ดัชมิลล์ไขมันต่ำ','ดัชมิลล์ไฮโปรตีน','ดัชลล์อกกแลต'\n",
    " ,'ดัชมิลล์มอลต์','ดัชมิลล์รสกาแฟ','ดัชมิลล์รสจืด','ดัชมิลล์สตรอว์เบอร์รี','หนองโพไขมัน 0%','หนองโพไขมันต่ำ','หนองโพช็อกโกแลต'\n",
    " ,'หนองโพรสกาแฟ','หนองโพรสจืด','หนองโพรสหวาน','หนองโพสตรอว์เบอร์รี']\n",
    "\n",
    "reduceCol = attrributes + stores + products\n",
    "reduceCol_all = attrributes + stores + milk_kind + products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "print(len(attrributes))\n",
    "print(len(reduceCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.สร้าง (Reduce) Bag of word ด้วย dictionary.doc2bow จัดลง dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)\n",
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คัด headline ที่พูดถึง domain นม\n",
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]\n",
    "#df_urls_milk = df_thr_process[(df_thr_process.URLs.isin(execption_urls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เมื่อ join กันแล้ว คอมเม้นทุกคอมเม้นจะอยู่ใน domain นมทั้งหมด\n",
    "df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['_id_x','_id_y','headline_y'],inplace=True)\n",
    "df_join_url.rename(columns={\"headline_x\":\"headline\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.ทำ Topic Modeling จาก Reduce BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.1 สร้าง Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text_reduce'])\n",
    "gensim_corpus = [dictionary.doc2bow(text, allow_update=True) for text in df_join_url['token_text_reduce']]\n",
    "word_frequencies = [[(dictionary[id], frequence) for id, frequence in couple] for couple in gensim_corpus]\n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.2 หา Optimal Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = r'E:/master_BADS/IS_BADS/Product-Position-SNA/mallet-2.0.8/'\n",
    "#mlp = r'D:/development_TestCase/Product-Position-SNA/mallet-2.0.8/'\n",
    "import os\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models import CoherenceModel\n",
    "os.environ.update({'MALLET_HOME':mlp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mallet_path = \"D:/development_TestCase/Product-Position-SNA/mallet-2.0.8/bin/mallet\"\n",
    "mallet_path = \"E:/master_BADS/IS_BADS/Product-Position-SNA/mallet-2.0.8/bin/mallet\"\n",
    "limit=20; start=2; step=2;\n",
    "coherence_values = []\n",
    "model_list = []\n",
    "for num_topics in range(start, limit, step):\n",
    "    model = LdaMallet(mallet_path, corpus=gensim_corpus, num_topics=num_topics, id2word=id2word)\n",
    "    model_list.append(model)\n",
    "    coherencemodel = CoherenceModel(model=model, texts=df_join_url['token_text_reduce'], dictionary=dictionary, coherence='c_v')\n",
    "    coherence_values.append(coherencemodel.get_coherence())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.show_topics(formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.3 สร้าง LdaModel ตามกลุ่มที่หาได้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = 8\n",
    "chunksize = 4000                  # size of the doc looked at every pass\n",
    "iterations = 50\n",
    "eval_every = 1                    # Don't evaluate model perplexity, takes too much time.\n",
    "\n",
    "# Make a index to word dictionary.\n",
    "temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "id2word = dictionary.id2token\n",
    "\n",
    "%time model = gensim.models.LdaModel(corpus=gensim_corpus, id2word=id2word, chunksize=chunksize \\\n",
    "                                     ,alpha='auto', eta='auto',iterations=iterations \\\n",
    "                                     ,num_topics=num_topics \\\n",
    "                                     , eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.gensim.prepare(model, gensim_corpus, dictionary, R=40, lambda_step=0.1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EpwX95XlTCdl",
    "_Q9pU1J6TCe5",
    "NKW--A73mzli",
    "uBBA36fDTCfZ",
    "O8nlNNE4TCfj"
   ],
   "name": "EDA_Token_CoocMat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
