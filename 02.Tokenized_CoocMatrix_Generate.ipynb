{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoY8sy40TCb5"
   },
   "source": [
    "### IS - Brand position\n",
    "Finding Product position on Semantic Network (PPSN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28353,
     "status": "ok",
     "timestamp": 1604024868503,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "GkBEUBUqTGuf",
    "outputId": "cb22db45-820a-48fd-c11a-a0568439778f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1604024868819,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_5mrzpx3TH9K",
    "outputId": "129bb192-4ac2-4b03-bc89-7ee7a65d5032"
   },
   "source": [
    "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Master_PJ_DRMABS/Datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity: 1 คือเหมือน 0 คือต่าง<br>\n",
    "dissimilarity 1 คือต่าง 0 คือเหมือน : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1604024879769,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cC0cBdCdTCb6"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import pymongo\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1604024879770,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "1kqXURiiTCb-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1604028167896,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "weEcXSD8TCcI",
    "outputId": "1219680e-0d54-4649-a26e-535e112f0650"
   },
   "outputs": [],
   "source": [
    "from pythainlp.util import normalize\n",
    "from newnewthaicut import word_tokenize  # IOB Tagging tokenized\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.spell import correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from sklearn.metrics import jaccard_score\n",
    "#from mlxtend.evaluate import lift_score\n",
    "#from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1604027698593,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "sna_e7nATCch"
   },
   "outputs": [],
   "source": [
    "# Files definition\n",
    "root_input_path = 'Datasource'\n",
    "root_output_path = 'output'\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(root_input_path+\"/comment_meiji.csv\")\n",
    "#comment_file.append(root_input_path+\"/comment_DDCF.csv\")\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(\"comment_meiji.csv\")\n",
    "#comment_file.append(\"comment_DDCF.csv\")\n",
    "\n",
    "comment_nlp_file = root_output_path+\"/comment_nlpToken.csv\"\n",
    "comment_cooc_freq_file = root_output_path+\"/comment_cooc_freq.xlsx\"\n",
    "comment_cooc_jacc_file = root_output_path+\"/comment_cooc_jacc.xlsx\"\n",
    "\n",
    "comment_robust_jaccard = root_output_path+\"/comment_robust_jaccard.xlsx\"\n",
    "comment_robust_lift = root_output_path+\"/comment_robust_lift.xlsx\"\n",
    "comment_robust_incur = root_output_path+\"/comment_robust_incur.xlsx\"\n",
    "comment_robust_cosine = root_output_path+\"/comment_robust_cosine.xlsx\"\n",
    "\n",
    "#comment_nlp_file = \"comment_nlpToken.csv\"\n",
    "#comment_cooc_nlp_file = \"comment_cooc.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"NIDA_PPSN_PRD\"]\n",
    "col_thread = mydb[\"NIDA_PPSN_THREAD\"]\n",
    "col_comment = mydb[\"NIDA_PPSN_COMMENT\"]\n",
    "col_scrape = mydb[\"NIDA_PPSN_SCRAPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlnotsqqTCcl"
   },
   "source": [
    "### 1.Clean data & NLP Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_corpus = col_scrape.find()\n",
    "df_Corpus = pd.DataFrame(cursor_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2677,
     "status": "ok",
     "timestamp": 1604027704431,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "VXYRZDubTCcm"
   },
   "outputs": [],
   "source": [
    "df_Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1604027718134,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "Xf0_nwz8TCdB",
    "outputId": "d39ed4de-8549-4488-d8c5-04e62e8a4dfd"
   },
   "outputs": [],
   "source": [
    "print('All comment:',df_Corpus.shape[0])\n",
    "print('All URLs ก่อนตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1604027719151,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "vRH0T2gLTCdE",
    "outputId": "0722d375-5945-44d8-bc71-f39dcc58a0e9"
   },
   "outputs": [],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1604027721340,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "LXg1m0eoTCdK",
    "outputId": "567e2a04-8322-4104-9f68-6d509815fd24"
   },
   "outputs": [],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Corpus.drop('_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1604027723160,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_O0BSe9ETCdO"
   },
   "outputs": [],
   "source": [
    "seqNum = list(range(1,df_Corpus.shape[0]+1))\n",
    "df_Corpus.insert(0,'commentId',seqNum)\n",
    "df_Corpus.columns = ['commentId','URLs','headline','text','article_date','Retrived_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1604027724691,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "w-muagoxTCdR",
    "outputId": "a8afe33d-943b-422e-838d-ba8514e9497d"
   },
   "outputs": [],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1604027727940,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "jZFN_aTsTCdU"
   },
   "outputs": [],
   "source": [
    "# Drop NA & banned comments\n",
    "df_Corpus = df_Corpus.dropna()\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('ความคิดเห็นนี้ถูกลบ')!= 0]\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('แก้ไขข้อความเมื่อ')!= 0]\n",
    "df_Corpus = df_Corpus.set_index('commentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1604027727941,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "ki-qD4YMTCdX",
    "outputId": "3102d8b3-3251-463e-f3e2-50a119fe787b"
   },
   "outputs": [],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1604027730567,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "c0J7GD3ATCda",
    "outputId": "f8748ddd-9aab-40d2-ee9e-38ba742906b7"
   },
   "outputs": [],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027730892,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "PKvz8tQpTCdd",
    "outputId": "62e2d990-0240-4a01-cef5-515147c6750c"
   },
   "outputs": [],
   "source": [
    "df_Corpus.insert(4,'token_text',None)\n",
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็ควันเวลา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('กระทู้เก่าที่สุด :',min(df_Corpus.article_date))\n",
    "print('กระทู้ใหม่ที่สุด :',max(df_Corpus.article_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เก็บเฉพาะหัวกระทู้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thread = df_Corpus.copy()\n",
    "df_thread = df_thread[['URLs','headline']]\n",
    "df_thread.drop_duplicates(subset =\"URLs\", keep = 'first', inplace = True)\n",
    "df_thread.insert(2,'token_headline',None)\n",
    "df_thread.insert(3,'mention_product',None)\n",
    "df_thread.insert(4,'mention_brand',None)\n",
    "df_thread.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpwX95XlTCdl"
   },
   "source": [
    "## 2.ตัดคำและเก็บลง MongoDB (ใช้ insight จาก jupyter งานก่อน)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U__d4agTCdl"
   },
   "source": [
    "https://www.thainlp.org/pythainlp/tutorials/notebooks/pythainlp-get-started.html#Thai-Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1604028299778,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cr_O7hE5htx2"
   },
   "outputs": [],
   "source": [
    "def normThai(w):\n",
    "    returnList = []\n",
    "    for i in w:\n",
    "        returnList.append(normalize(i))\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1604030224171,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "rAcuuoYiTCdu"
   },
   "outputs": [],
   "source": [
    "garbage_char = ['ไม่','','.','..','...','มกราคม', 'กุมภาพันธ์','มีนาคม', 'เมษายน','พฤษภาคม', 'มิถุนายน', 'กรกฎาคม','สิงหาคม','กันยายน'\n",
    "                ,'ตุลาคม','พฤศจิกายน', 'ธันวาคม','วันจันทร์','วันอังคาร','วันพุธ','วันพฤหัสบดี','วันศุกร์','วันเสาร์','วันอาทิตย์','กก'\n",
    "                ,'เมนู','Menu','Net','net','สาขา','บาท','ราคา','ฯ','ๆ','กก','อันนี้','😆', '🤣','😢','😏','😂','😿','🥺','ววว','xx','อิอิ','แย้ววว']\n",
    "naka = ['นะคะ','นะค่ะ','น่ะค่ะ','น่ะคะ','ฮ้าฟ','ค้าบ','คร้าบ']\n",
    "\n",
    "stopwords = set(thai_stopwords()).union(set(naka))\n",
    "stopwords.remove('ไม่')\n",
    "stopwords.remove('สูง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1604027849933,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "mAwAGA5ITCdx",
    "outputId": "d95e59bb-b35e-4592-f16e-0915a7975f84"
   },
   "outputs": [],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_custom(x):\n",
    "    custom_punc = '!.—-\"$#&฿/&\\'()*+,:;<=>?@[\\\\]^_`{|}~'\n",
    "    x = x.translate(str.maketrans('', '', custom_punc)).strip()\n",
    "    x = x.translate(str.maketrans({\"\\t\":None,\"\\n\": None})).strip()\n",
    "    x = x.lower()\n",
    "    wtkn = word_tokenize(x)\n",
    "    wtkn = [j for j in wtkn if j not in stopwords]\n",
    "    wtkn = [w for w in wtkn if len(w) >= 2]\n",
    "    wtkn = [y for y in wtkn if y not in garbage_char]\n",
    "    wtkn = [s for s in wtkn if not s.isdigit()]\n",
    "    wtkn = normThai(wtkn)\n",
    "    return wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_Thread(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"URLs\": lx,\n",
    "            \"headline\": df.headline[c],\n",
    "            \"token_headline\":df.token_headline[c],\n",
    "            \"t_mention_dairy\":df.t_mention_dairy[c],\n",
    "            \"t_mention_product\": df.t_mention_product[c],\n",
    "            \"t_mention_brand\": df.t_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_comments(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"commentId\":int(df.commentId[c]),\n",
    "            \"URLs\": lx,\n",
    "            \"headline\":df.headline[c],\n",
    "            \"text\": df.text[c],\n",
    "            \"Retrived_date\": df.Retrived_date[c],\n",
    "            \"token_text\":df.token_text[c],\n",
    "            \"cmt_mention_dairy\": df.cmt_mention_dairy[c],\n",
    "            \"cmt_mention_product\": df.cmt_mention_product[c],\n",
    "            \"cmt_mention_brand\": df.cmt_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_keyword(wtkn):  \n",
    "    ret_wtkn = wtkn\n",
    "    for i,each in enumerate(ret_wtkn,0):\n",
    "        if each in ['ดัชมิลล์','ดัชมิล','ดัชมิว','dutchmill','dutch mill','dutch milk','dutchmilk','duchmill','duchie-bio','ดัชชี่']:\n",
    "            ret_wtkn[i] = 'ดัชมิลล์'\n",
    "        elif each  in ['เมจิ','ซีพีเมจิ','ซีพี เมจิ','cp meiji','meiji','meji','miji','cpmeijicom','cpmeijitensai','cpmeijithailand']:\n",
    "            ret_wtkn[i] = 'เมจิ'\n",
    "        elif each  in ['โฟร์โมสต์','โฟร์โมสท์','โฟร์โมส','โฟโมสต์','โฟโมต','โฟรโมสต์','โฟรโมสต','foremost']:\n",
    "            ret_wtkn[i] = 'โฟร์โมสต์'\n",
    "        elif each  in ['แดรี่โฮม','dairy home','dairyhome','เดรี่โฮม','เดลี่โฮม']:\n",
    "            ret_wtkn[i] = 'แดรี่โฮม'\n",
    "        elif each  in ['โชคชัย','อืมม มิลค์','umm milk','นมฟาร์มโชคชัย']:\n",
    "            ret_wtkn[i] = 'โชคชัย'\n",
    "        elif each  in ['เอ็มมิลค์','mmilk','เอ็มมิ้ลค์','เอ็มมิลล์','m milk']:\n",
    "            ret_wtkn[i] = 'เอ็มมิลค์'\n",
    "        elif each  in ['ไทยเดนมาร์ค','ไทยเดนมาร์ก','ไทย เดนมาร์ค','ไทย เดนมาร์ก','วัวแดง']:\n",
    "            ret_wtkn[i] = 'ไทยเดนมาร์ค'\n",
    "        elif each  in ['สตอเบอร์รี่','สตรอว์เบอร์รี','รสสตรอเบอรี่','สตอเบอรี่','สตรอเบอรี่','สตรอวเบอรี่','สตรอเบอร์รี่']:\n",
    "            ret_wtkn[i] = 'สตรอว์เบอร์รี'\n",
    "        elif each  in ['ชอคโกแล็ต','ช็อกโกแลต','ช็อคโกแลต','ช๊อกโกแลต','ช็อคโกแล็ต','ช็อกโกเลต','ช็อค']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลต'\n",
    "        elif each  in ['มิ้นท์ชอค','มิ้นต์ช้อก','ช็อคโกแลตมินต์','มินต์ช็อคโกแลต']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลตมินต์'\n",
    "        elif each  in ['ไขมันต่ำ','low fat','พร่องมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมันต่ำ'\n",
    "        elif each  in ['ไขมัน 0','ไขมัน 0%','0 fat','0% fat','ขาดมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมัน 0%'\n",
    "        elif each  in ['high protein','hi protein','ไฮโปรตีน']:\n",
    "            ret_wtkn[i] = 'ไฮโปรตีน'\n",
    "        elif each  in ['free lactose','lactose free','ฟรีแลคโตส','แลคโตสฟรี']:\n",
    "            ret_wtkn[i] = 'นมฟรีแลคโตส'\n",
    "        elif each  in ['พาส','พาสเจอไรซ์','พาสเจอร์ไรซ์','พาสเจอร์ไรส์','พาซเจอไรซ์','พาสเจอร์ไลท์']:\n",
    "            ret_wtkn[i] = 'พาสเจอร์ไรส์'\n",
    "        elif each  in ['เมจิโกลด์ แม็กซ์','เมจิโกลด์','เมจิ โกลด์','เมจิโกล์ดแม็กซ์','gold','gold max']:\n",
    "            ret_wtkn[i] = 'เมจิโกลด์'\n",
    "        elif each  in ['ฝาน้ำเงิน','รสจืด']:\n",
    "            ret_wtkn[i] = 'รสจืด'\n",
    "        elif each  in ['ท็อปส์','ทอปส์','ท้อปส์','ท๊อปส์','tops']:\n",
    "            ret_wtkn[i] = 'tops'\n",
    "        elif each  in ['แมคโคร','แม็คโคร','makro']:\n",
    "            ret_wtkn[i] = 'makro'\n",
    "        elif each  in ['โลตัส','lotus']:\n",
    "            ret_wtkn[i] = 'lotus'\n",
    "        elif each  in ['บิ๊กซี','bigc','big c']:\n",
    "            ret_wtkn[i] = 'bigc'\n",
    "        elif each in ['ดาร์คช็อกโกแลต','ดาร์กช็อก','ดาร์กช็อกโกแลต']:\n",
    "            ret_wtkn[i] = 'ดาร์คช็อกโกแลต'\n",
    "        elif each in ['bedtime','bed time','เบดไทม์']:\n",
    "            ret_wtkn[i] = 'เบดไทม์'\n",
    "        elif each in ['เมจิ บัลแกเรีย','เมจิบัลแกเรีย','บัลแกเรีย','bulgaria']:\n",
    "            ret_wtkn[i] = 'เมจิบัลแกเรีย'\n",
    "        elif each in ['โยเกิร์ต','โยเกิต','โยเกิรต','โยเกิร์ตพร้อมดื่ม']:\n",
    "            ret_wtkn[i] = 'โยเกิร์ต'\n",
    "        elif each in ['7 Eleven','7 eleven','เซเว่น อีเลฟเว่น','เซเว่นอีเลฟเว่น','เซเว่น','เซเวน','7 11']:\n",
    "            ret_wtkn[i] = '7-Eleven'\n",
    "        elif each in ['บีทาเก้น','บีทาเกน']:\n",
    "            ret_wtkn[i] = 'บีทาเก้น'\n",
    "        elif each in ['โปร','โปรโมชั่น']:\n",
    "            ret_wtkn[i] = 'โปรโมชั่น'\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_brands_product(x,catType):\n",
    "    ret_wtkn = []\n",
    "    brands = ['ดัชมิลล์','เมจิ','โฟร์โมสต์','โชคชัย','แดรี่โฮม','เอ็มมิลค์','แมคโนเลีย','ไทยเดนมาร์ค','หนองโพ','คาเนชั่น','บีทาเก้น','จิตรลดา']\n",
    "    products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ','วิปครีม']\n",
    "    milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์','nondairy','non dairy']\n",
    "    \n",
    "    choiceList = []\n",
    "    if catType == 'b':\n",
    "        choiceList = brands\n",
    "    elif catType == 'm':\n",
    "        choiceList = milk_kind\n",
    "    elif catType == 'p':\n",
    "        choiceList = products\n",
    "        \n",
    "    for i,each in enumerate(x,0):\n",
    "        if each in choiceList:\n",
    "            ret_wtkn.append(each)\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy ชุดคำจาก File มา Process ก่อนลง MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment = df_Corpus.reset_index().copy()\n",
    "df_process_thread = df_thread.reset_index().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Tokenize comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['text'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['token_text'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['cmt_mention_dairy'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_comment['cmt_mention_brand'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_comment['cmt_mention_product'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Insert comments to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hunm5MT7TCd2",
    "outputId": "15710375-8df1-46f0-85a2-04c66e1de5d9"
   },
   "outputs": [],
   "source": [
    "col_comment.delete_many({})\n",
    "process_data = create_InsertMany_comments(df_process_comment)\n",
    "col_comment.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Tokenize head of thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['headline'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['token_headline'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6) Mark domain/entity mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['t_mention_dairy'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_thread['t_mention_brand'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_thread['t_mention_product'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7) Insert thread to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_thread.delete_many({})\n",
    "process_data = create_InsertMany_Thread(df_process_thread)\n",
    "col_thread.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027734766,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "J30GMUlJTCdh"
   },
   "outputs": [],
   "source": [
    "del df_thread,df_Corpus,df_process_comment,df_process_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Process หัวกระทู้ เพื่อทำ Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เคสหลุดเงื่อนไข แต่ต้องใช้\n",
    "1. https://pantip.com/topic/30833944\n",
    "2. https://pantip.com/topic/30105850\n",
    "4. https://pantip.com/topic/35439062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]\n",
    "df_urls_milk['t_mention_dairy'] = df_urls_milk['t_mention_dairy'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_brand'] = df_urls_milk['t_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_product'] = df_urls_milk['t_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_urls_milk = df_cmt_process[(df_cmt_process.cmt_mention_dairy.str.len() != 0) | (df_cmt_process.URLs.isin(execption_urls))]\n",
    "df_c_urls_milk['cmt_mention_dairy'] = df_c_urls_milk['cmt_mention_dairy'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_brand'] = df_c_urls_milk['cmt_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_product'] = df_c_urls_milk['cmt_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('จำนวนกระทู้ที่มีการพูดถึงนม:',df_urls_milk.shape[0])\n",
    "print('%จำนวนกระทู้ที่มีการพูดถึงนมเทียบทั้งหมด:',round((df_urls_milk.shape[0]/df_thr_process.shape[0])*100,2))\n",
    "print('จำนวน comment ที่มีการพูดถึงนม:',df_c_urls_milk.shape[0])\n",
    "print('%จำนวน comment ที่มีการพูดถึงนมเทียบทั้งหมด:',round((df_c_urls_milk.shape[0]/df_cmt_process.shape[0])*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* จำนวน comment ที่มีการพูดถึงนม ไม่ได้ impute มาจากหัวกระทู้ ถ้า impute จะมีเยอะกว่านี้อีก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA#2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุ domain ของนม บนหัวกระทู้"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_dairy']]\n",
    "df_view.column = ['URLs','t_mention_dairy']\n",
    "df_view_count = df_view.groupby('t_mention_dairy').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]\n",
    "\n",
    "# set() ในเคสนี้คือกระทู้ที่พูดถึงนมแต่ไม่มี domain ในหัวกระทู้ ต้องดึง custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ Product บนหัวกระทู้ (Headline)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_product']]\n",
    "df_view.column = ['URLs','t_mention_product']\n",
    "df_view_count = df_view.groupby('t_mention_product').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]\n",
    "\n",
    "# set() หมายถึง กระทู้นั้นอยู่ใน domain นม แต่ไม่ระบุ product flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ Product ใน comment ทั้งใต้หัวกระทู้ ที่มี domain ของนม และส่วน comment<br>\n",
    "อย่างไรก็ตามยังไม่ได้ impute domain จากหัวกระทู้เข้าไป"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_c_urls_milk[['URLs','cmt_mention_product']]\n",
    "df_view.column = ['URLs','cmt_mention_product']\n",
    "df_view_count = df_view.groupby('cmt_mention_product').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ brand ใน comment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_c_urls_milk[['URLs','cmt_mention_brand']]\n",
    "df_view.column = ['URLs','cmt_mention_brand']\n",
    "df_view_count = df_view.groupby('cmt_mention_brand').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.สรุป Term & reduced_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrributes = ['เก็บรักษา','เข้มข้น','เค้ก','เจมส์','เจมส์ จิ','เจมส์จิ','เจลลาติน','เจือจาง','เชื้อ','เชื้อโรค','เชื้อจุลินทรีย์','เชื้อรา','เด็ก','เด็กเล็ก','เด็กแรกเกิด'\n",
    "               ,'เด็กโต','เด็กชาย','เด็กทารก','เด็กน้อย','เด็กวัยรุ่น','เด็กอ่อน','เติบโต','เตี้ย','เนย','เนยแข็ง','เนยสด','เนสเล่','เนสกาแฟ','เนสท์เล่','เน่า','เน่าเสีย'\n",
    "               ,'เบาหวาน','เมจิ','เมจิโกลด์','เมจิบัลแกเรีย','เมล่อน','เย็น','เล่นเวท','เล่นกล้าม','เลี้ยง','เลี้ยงเด็ก','เลี้ยงดู','เลี้ยงลูก','เลี้ยงสัตว์','เวย์','เวย์โปรตีน'\n",
    "               ,'เหม็นเขียว','เหม็นเปรี้ยว','เหม็นคาว','เหม็นบูด','เอนไซม์','เอ็นไซม์','เอนฟาโกร','เอ็มมิลค์','เอสเปรสโซ','เอสเปรสโซ่','เอสเพรสโซ','เอสเพรสโซ่'\n",
    "               ,'แข็งแรง','แคนตาลูป','แคลเซียม','แคลเซี่ยม','แคลอรี','แคลอรี่','แจก','แช่เย็น','แชร์','แดรี่โฮม','แตงโม','แถม','แบคทีเรีย','แบบสอบถาม','แพ็ก'\n",
    "               ,'แพกเกจ','แพ็กเกจ','แพ็ค','แพ๊ค','แพคเกจ','แพ็คเกจ','แพคคู่','แพ้ท้อง','แพ้นม','แพ้นมวัว','แม่','แมกนีเซียม','แมคโนเลีย','แม่ลูกอ่อน','แร่ธาตุ'\n",
    "               ,'แลกโตส','แล็กโต๊ส','แลคโตส','แลคติก','แอโรบิค','แอนตี้ไบโอติก','แอปเปิล','แอปเปิ้ล','โกโก้','โฆษณา','โชคชัย','โซเดียม','โด้บ','โด๊บ','โด้ป'\n",
    "               ,'โด๊ป','โด้ปนม','โปรโมชั่น','โปรตีน','โพแทสเซียม','โฟเลต','โฟร์โมสต์','โฟลิค','โภชนาการ','โยเกิร์ต','โยเกิร์ท','โรคเบาหวาน','โรคกระเพาะ'\n",
    "               ,'โรคขาดอาหาร','โรคท้องร่วง','โรคประจำตัว','โรคภัยไข้เจ็บ','โรคภูมิแพ้','โรคมะเร็ง','โรคหัวใจ','โรงเรียน','โรงงาน','โอวัลติน','ให้นม','ให้อาหาร'\n",
    "               ,'ไขมัน','ไขมัน 0%','ไขมันต่ำ','ไทยเดนมาร์ค','ไอติม','ไอศกรีม','ไอศครีม','ไฮโปรตีน','กรดไขมัน','กรดอะมิโน','กระดูกพรุน','กระบวนการผลิต'\n",
    "               ,'กระป๋อง','กล้วย','กล้วหอม','กล่อง','กลิ่น','กลิ่นคาว','กลิ่นหอม','กลูโคส','กาเฟอีน','กาแฟ','กาแฟเย็น','กาแฟร้อน','กาแฟสด','การบรรจุ'\n",
    "               ,'การผลิต','การย่อยอาหาร','การลดน้ำหนัก','การลดราคา','การออกกำลังกาย','ข้น','ขนม','ขนมเค้ก','ขนมปัง','ขนมปังแผ่น','ขนมหวาน','ขนส่ง'\n",
    "               ,'ขวดโหล','ขวดนม','ขวบ','ขาดตลาด','ขายไม่ดี','ขายไม่ออก','ขายปลีก','ขายส่ง','ข้าว','ข้าวโพด','ข้าวโอ๊ต','ข้าวกล้อง','คนรุ่นใหม่','คนวัยหนุ่มสาว'\n",
    "               ,'คนสูงอายุ','ครรภ์','คลอเรสเตอรอล','คลอเลสเตอรอล','คลอโรฟิล','คลอดลูก','ความคุ้มค่า','ความมัน','ความร้อน','คอเลสเตอรอล','คาเฟอีน','ค่าขนส่ง'\n",
    "               ,'คาปูชิโน','คาปูชิน่','คาร์โบไฮเดรต','คาราเมล','คาว','คุณแม่','คุณแม่มือใหม่','คุณค่า','คุณประโยชน์','คุณภาพ','คุณภาพดี','ฆ่าเชื้อ','จิตรลดา','จืด'\n",
    "               ,'จุลินทรีย์','ฉลาก','ชง','ชงนม','ช็อกโกแลต','ช่องแช่แข็ง','ชอบ','ชา','ชาเขียว','ชาเขียวมัจฉะ','ชาเย็น','ชิม','ซื้อ','ซุปเปอร์มาร์เกต','ซุปเปอร์มาร์เก็ต'\n",
    "               ,'ดัชมิลล์','ดาร์คช็อกโกแลต','ต้ม','ตลาด','ตัวแทนจำหน่าย','ตู้เย็น','ท้องเสีย','ท้องตลาด','ท้องร่วง','ท้องว่าง','ท้องอืด','ทุเรียน','ธรรมชาติ','ธัญญาหาร'\n",
    "               ,'ธัญพืช','ธาตุเหล็ก','นม','นมเปรี้ยว','นมกล่อง','นมข้น','นมข้นหวาน','นมควาย','นมถั่วเหลือง','นมผง','นมฟรีแลคโตส','นมยูเอชที','นมวัว','นมสด'\n",
    "               ,'นมฮอกไกโด','นอน','น้ำ','นำเข้า','น้ำเชื่อม','น้ำเต้าหู้','น้ำตาล','น้ำตาลเทียม','น้ำตาลทราย','น้ำตาลทรายแดง','น้ำนม','น้ำผึ้ง','น้ำหนัก','บรรจุขวด'\n",
    "               ,'บลูเบอร์รี่','บัลแกเรีย','บัลกาเรีย','บาริสตา','บาริสต้า','บีทาเก้น','บูด','ปริมาณ','ปลอดเชื้อ','ปวดท้อง','ปั่น','ผลไม้','ผสม','ผู้จัดจำหน่าย','ผู้ผลิต','ฝา'\n",
    "               ,'พกพา','พนักงานขายนม','พลังงาน','พาราไดซ์','พารากอน','พาสเจอร์ไรส์','ฟรอยด์','ฟอง','ฟาร์ม','มอลต์','ยอดขาย','รสกลมกล่อม','รกล้วย','รสกาแฟ'\n",
    "               ,'รสจืด','รสชาติ','รสหวาน','ราคาแพง','ราคาสูง','ร่างกาย','ร้านกาแฟ','รีวิว','ลดความอ้วน','ลดน้ำหนัก','ลดราคา','ลูก','ลูกชาย','ลูกสาว','วันหมดอายุ'\n",
    "               ,'วานิลลา','วานิลล่า','วานิลา','วิ่ง','วิตามิน','สตรอเบอร์รี่','สตรอเบอรี','สตรอว์เบอร์รี','สต็อก','สต๊อก','สต็อค','สตาร์บัค','สยามพารากอน','สยามสแควร์'\n",
    "               ,'สละ','ส่วนผสม','สะอาด','สัปปะรด','สารอาหาร','สำนักงานคณะกรรมการอาหารและยา','สิ่งเจือปน','สูง','สูงวัย','สูตร','หญ้า','หนองโพ','หมอ','หลอด'\n",
    "               ,'หวาน','หอม','หางจระเข้','ห้างร้าน','อ้วน','ออกกำลังกาย','ออร์แกนิก','อะเมซอน','อาหาร','อาหารเสริม','อุณหภูมิ']\n",
    "\n",
    "stores = ['tops','makro','lotus','bigc','7-Eleven']\n",
    "\n",
    "#products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "#                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "#                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ']\n",
    "#milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "#                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์']\n",
    "\n",
    "#  EDA ใน Excel ได้ flavor 68 ตัว (ถ้าดึงยี่ห้ออื่นก็เพิ่มอีก)\n",
    "#avai_flavs = ['เมจิเมจิโกลด์','เมจิเมล่อน','เมจิไขมัน 0%','เมจิไขมันต่ำ','เมจิไฮโปรตีน','เมจิช็อกโกแลต','เมจิชาเขียวมัจฉะ','เมจิดาร์คช็อกโกแลต'\n",
    "# ,'เมจินมฟรีแลคโตส','เมจิบัลแกเรีย','เมจิมอลต์','เมจิรสกลมกล่อม','เมจิรสกล้วย','เมจิรกาแฟ','เมจิรสจืด','เมจิรสธรรมชาติ','เมจิรสหวาน'\n",
    "# ,'เมจิสตรอว์เบอร์รี','เมจิอัลมอนด์','เอ็มมิลค์นมฟรีแลคโตส','เอ็มมิลค์รสจืด','แดรี่โฮมgrass fed','แดรี่โฮมเบดไทม์','แดรี่โฮมช็อกโกแลต'\n",
    "# ,'แดรี่โฮมรสกล้วย','แดโฮมรสจืด','แดรี่โฮมรสหวาน','แดรี่โฮมสตรอว์เบอร์รี','แมคโนเลียไขมันต่ำ','แมคโนเลียช็อกโกแลต','แมคโนเลียรสจืด'\n",
    "# ,'โชคชัยไขมันต่ำ','โชคชัยช็อกโกแลต','โชคชัยรสกาแฟ','โชคชัยรสจืด','โชคชัยสตรอว์เบอร์รี','ฟร์โมสต์ไขมัน 0%','โฟร์โมสต์ไขมันต่ำ'\n",
    "# ,'โฟร์โมสต์คาราเมล','โฟร์โมสต์ช็อกโกแลต','โฟร์โมสต์รสกาแฟ','โฟร์โมสต์รสจืด','โฟร์โมสต์สตรอว์เบอร์รี','ไทยเดนมาร์คช็อกโกแลต'\n",
    "# ,'ไทยเดนมาร์ครสกาแฟ','ไทยเดนมาร์ครสจืด','ไทยเดนมาร์ครสหวาน','ไทยเดนมาร์คสตรอว์เบอร์รี','คาเนชั่นรสจืด','จิตรลดาช็อกโกแลต'\n",
    "# ,'จิตรลดารสจืด','จิตรลดารสหวาน','จิตรลดาสตรอว์เบอร์รี','ดัชมิลล์ไขมัน 0%','ดัชมิลล์ไขมันต่ำ','ดัชมิลล์ไฮโปรตีน','ดัชลล์อกกแลต'\n",
    "# ,'ดัชมิลล์มอลต์','ดัชมิลล์รสกาแฟ','ดัชมิลล์รสจืด','ดัชมิลล์สตรอว์เบอร์รี','หนองโพไขมัน 0%','หนองโพไขมันต่ำ','หนองโพช็อกโกแลต'\n",
    "# ,'หนองโพรสกาแฟ','หนองโพรสจืด','หนองโพรสหวาน','หนองโพสตรอว์เบอร์รี']\n",
    "\n",
    "reduceCol = attrributes + stores \n",
    "#reduceCol_all = attrributes + stores + milk_kind + products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_keyword(wtkn,redCol):\n",
    "    del_list = []\n",
    "    ret_wtkn = wtkn\n",
    "    for each in ret_wtkn:\n",
    "        if each not in redCol:\n",
    "            del_list.append(each)\n",
    "    ret_wtkn = [x for x in ret_wtkn if x not in del_list]\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def freq_brand(x):\n",
    "    #e = eval(x)\n",
    "    e = x\n",
    "    e.sort()\n",
    "    f = [(k,len(list(g))) for k, g in groupby(e)]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_flavor(x,y):\n",
    "    listflav = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            listflav.append(i+j)\n",
    "    return listflav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKW--A73mzli"
   },
   "source": [
    "### 5.สร้าง (Reduce) Bag of word ด้วย dictionary.doc2bow จัดลง dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คัด headline ที่พูดถึง domain นม\n",
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เมื่อ join กันแล้ว คอมเม้นทุกคอมเม้นจะอยู่ใน domain นมทั้งหมด\n",
    "df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['_id_x','_id_y','headline_y'],inplace=True)\n",
    "df_join_url.rename(columns={\"headline_x\":\"headline\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง QAP mathod case2,4\n",
    "df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol))\n",
    "\n",
    "# ทดลอง QAP mathod  case1,5\n",
    "#df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_join_url.set_index('commentId',inplace=True)\n",
    "df_join_url.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text_reduce'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dictionary_tfidf = gensim.corpora.Dictionary(df_join_url['token_text_reduce_tfidf'])\n",
    "gensim_corpus = [dictionary_tfidf.doc2bow(text, allow_update=True) for text in df_join_url['token_text_reduce_tfidf']]\n",
    "tfidf_model = TfidfModel(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['reduce_bow'] = df_join_url[\"token_text_reduce\"].map(dictionary.doc2bow)\n",
    "df_join_url['reduce_bow_txt'] = df_join_url[\"reduce_bow\"].apply(lambda x:[(dictionary[id_], frequence) for id_, frequence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['Retrived_date','reduce_bow'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.insert(3,'mention_domain',value=None)\n",
    "df_join_url.insert(4,'mention_product',value=None)\n",
    "df_join_url.insert(5,'mention_brand',value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute brand & product เข้า comment และสรุปก่อนเข้า BoW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Impute จากหัวกระทู้\n",
    "\n",
    "# 1.headline มี comment มี เอา comment\n",
    "# 2.headline มี comment ไม่มี เอา headline\n",
    "# 3.headline ไม่มี comment มี เอา comment\n",
    "# 4.ไม่มีทั้งคู่ ปล่อยไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.t_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) == 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_domain'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.t_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) == 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_brand'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.t_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) == 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_product'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['t_mention_dairy','t_mention_product','t_mention_brand'\n",
    "                          ,'cmt_mention_dairy','cmt_mention_product','cmt_mention_brand'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf_list = []\n",
    "for doc in tfidf_model[gensim_corpus]:\n",
    "    tfidf_list.append([(dictionary_tfidf[id], np.around(freq, decimals=4)) for id, freq in doc])\n",
    "df_join_url.insert(11,'reduce_tfidf',value=tfidf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat Brand + Product มาต่อกันเพื่อระบุตราและยี่ห้อ เพื่อลงระดับ flavor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_join_url['mention_domain_count'] = df_join_url['mention_domain'].apply(lambda x: 0 if x is None else len(x))\n",
    "df_join_url['mention_product_count'] = df_join_url['mention_product'].apply(lambda x: 0 if x is None else len(x))\n",
    "df_join_url['mention_brand_count'] = df_join_url['mention_brand'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor = df_join_url[(df_join_url['mention_brand_count']>0)&(df_join_url['mention_product_count']>0)]\n",
    "df_withOutFlavor = df_join_url[(df_join_url['mention_brand_count']<=0)|(df_join_url['mention_product_count']<=0)]\n",
    "df_withFlavor['concat_domain'] = df_withFlavor['mention_domain'].apply(lambda x: x if x is None else list(set(x)))\n",
    "df_withFlavor['concat_brand'] = df_withFlavor['mention_brand'].apply(lambda x: x if x is None else list(set(x)))\n",
    "df_withFlavor['concat_product'] = df_withFlavor['mention_product'].apply(lambda x: x if x is None else list(set(x)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor['mention_product'] = df_withFlavor.apply(lambda x: concat_flavor(x.concat_brand,x.concat_product), axis=1)\n",
    "df_withFlavor['mention_product'] = df_withFlavor['mention_product'] .apply(lambda x: x if x is None else reduced_keyword(x,avai_flavs))\n",
    "df_withFlavor['mention_product'] = df_withFlavor['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withFlavor['mention_brand'] = df_withFlavor['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withFlavor['mention_domain'] = df_withFlavor['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withOutFlavor['mention_product'] = df_withOutFlavor['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withOutFlavor['mention_brand'] = df_withOutFlavor['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withOutFlavor['mention_domain'] = df_withOutFlavor['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor.drop(columns=['mention_domain_count','mention_product_count','mention_brand_count'\n",
    "                          ,'concat_domain','concat_brand','concat_product'],inplace=True)\n",
    "df_withOutFlavor.drop(columns=['mention_domain_count','mention_product_count','mention_brand_count'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_final = pd.concat([df_withFlavor,df_withOutFlavor], axis=0, sort=False)\n",
    "df_final.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cooccurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment ออกเมื่อไม่ concat brand+flavor\n",
    "df_final = df_join_url.copy()\n",
    "df_final.set_index('commentId',inplace=True)\n",
    "df_final['mention_product'] = df_final['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_final['mention_brand'] = df_final['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_final['mention_domain'] = df_final['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brand_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_brand\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "#df_prd_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_product\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "df_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"reduce_bow_txt\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TF-IDF Matrix\n",
    "df_tfidf_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"reduce_tfidf\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)\n",
    "df_tfidf_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brand_cooc.reset_index(inplace=True)\n",
    "#df_prd_cooc.reset_index(inplace=True)\n",
    "df_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง  QAP mathod case2,4: Brand vs Product vs Attribute (ไม่เอาแล้ว)\n",
    "#join_df = pd.merge(df_brand_cooc, df_prd_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "#join_df = pd.merge(join_df, df_cooc, on='commentId', how='inner')\n",
    "\n",
    "# ทดลอง  QAP mathod case3: Product vs Attribute (ไม่เอาแล้ว)\n",
    "#join_df = pd.merge(df_prd_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ทดลอง  QAP mathod case1,5: Brand vs Attribute กรณีแยก ยี่ห้อ และ ผลิตภัณฑ์ จาก reduce_bow_txt\n",
    "#join_df = pd.merge(df_brand_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ไม่ Join ทำในกรณีไม่แยก ยี่ห้อ และ ผลิตภัณฑ์ ออกจาก reduce_bow_txt\n",
    "join_df = df_cooc.copy()\n",
    "\n",
    "join_df.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export ข้อมูล เพื่อนำไปสุ่มแถวทำ QAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.to_csv(root_output_path+\"/cooc_bow_all.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source for graph generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBBA36fDTCfZ"
   },
   "source": [
    "### 1.Create frequency co-occurrence matrix จาก Bag of word<br>\n",
    "* ใช้สำหรับทำ MDS และโยนเข้า R (ทำ normalized บน R) ในลักษณะ Term-Term Cross tabulation<br> \n",
    "(คนละอย่างกับ TF-IDF cooc matrix ที่เป็น Word-word ซึ่งต้องรัน bigram เป็นราย document)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "LgE1okejTCfZ"
   },
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cnt_Grpby(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    cooc = slice_df[(slice_df.A>0)&(slice_df.B>0)]\n",
    "    return cooc.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1jhFte5eTCfd"
   },
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        if i != j:\n",
    "            item_item_matrix.iloc[i,j] = cnt_Grpby(join_df,i,j)\n",
    "        else:\n",
    "            item_item_matrix.iloc[i,j] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "OhtvLfMXTCfg"
   },
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "bsbsqduDTCfh"
   },
   "source": [
    "item_item_matrix.to_excel(comment_cooc_freq_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Create co-occurrence matrix with Jaccard Distance สำหรับสร้างกราฟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)]\n",
    "    a_occur = slice_df[(slice_df.A>0)]\n",
    "    b_occur = slice_df[(slice_df.B>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        item_item_matrix.iloc[i,j] = jaccard_index(join_df,i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_jacc_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del item_item_matrix,join_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source for Robustness Check & Cross Validation (7x7 brands matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### คำนวณ Index ของยี่ห้อต่อยี่ห้อ จากทุกๆ Attributes แสดงผลเป็น Matrix ขนาด 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_freq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)\n",
    "#cooc_matrix_freq = pd.read_excel(comment_cooc_freq_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = ['เมจิ','ดัชมิลล์','โฟร์โมสต์','แดรี่โฮม','โชคชัย','เอ็มมิลค์','ไทยเดนมาร์ค']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_freq_brand = matrix_freq[brands]\n",
    "matrix_freq_unbrand = matrix_freq.drop(labels=brands,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose frequency into Attribute Rating Format for precompute MDS\n",
    "#cooc_matrix_freq = cooc_matrix_freq[brands]\n",
    "#cooc_matrix_freq.drop(brands, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# จำนวน Attributes = 330, brands = 7\n",
    "#cooc_matrix_freq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### 1.Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF: Lee Soojung,(2017). Improving Jaccard Index for Measuring Similarity in Collaborative Filtering\n",
    "# Information Science and Applications 2017, 124.\n",
    "def jaccard_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "jacc = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "jacc = jacc.append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                jacc.iloc[0,k] = jaccard_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                jacc.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = jacc.mean(axis=1)[0]\n",
    "        jacc = jacc.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_jaccard, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### 2.Lift normalization (Netzer et al., 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def lift_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    p_a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)].shape[0]/slice_df.shape[0]\n",
    "    p_a_occur = slice_df[(slice_df.A>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_occur = slice_df[(slice_df.B>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_comprem_occur = slice_df[(slice_df.B==0)].shape[0]/slice_df.shape[0]\n",
    "    lift = p_a_in_b/(p_a_occur*p_b_comprem_occur)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "# Follow style of Lee Soojung,(2017)\n",
    "def lift_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    p_a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_comprem_occur = (slice_df.shape[0]-p_b_occur)/slice_df.shape[0]\n",
    "    lift = p_a_in_b/(p_a_occur*p_b_comprem_occur)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "#item_item_matrix = pd.DataFrame(index=cooc_matrix_freq.columns,columns=cooc_matrix_freq.columns).fillna(0)\n",
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "lift = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "lift = lift.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                lift.iloc[0,k] = lift_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                lift.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = lift.mean(axis=1)[0]\n",
    "        lift = lift.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qG7pCYfTCfu"
   },
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_lift, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inclusion Index (Qin He, 1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def inclu_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)].shape[0]\n",
    "    a_occur = slice_df[(slice_df.A>0)].shape[0]\n",
    "    b_occur = slice_df[(slice_df.B>0)].shape[0]\n",
    "    inclu = a_in_b/min(a_occur,b_occur)\n",
    "    return inclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def inclu_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)].shape[0]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)].shape[0]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)].shape[0]\n",
    "    inclu = a_in_b/min(a_occur,b_occur)\n",
    "    return inclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "inclu = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "inclu = inclu.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                inclu.iloc[0,k] = inclu_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                inclu.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = inclu.mean(axis=1)[0]\n",
    "        inclu = inclu.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_incur, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.cosine similarity correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "# ต้องใช้ 1 เป็นตัวตั้งลบเสมอถ้าใช้ cosine จาก scipy.spatial.distance หากจะเอาค่า dissimliarity\n",
    "\n",
    "def cosine_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = a_in_b.iloc[:,0]\n",
    "    b_occur = a_in_b.iloc[:,2]\n",
    "    cosin = 1-cosine(a_occur,b_occur)\n",
    "    return cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "cosin = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "cosin = cosin.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Similarity (1-cosine-1)\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                cosin.iloc[0,k] = cosine_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                cosin.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = cosin.mean(axis=1)[0]\n",
    "        cosin = cosin.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_cosine, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.สุ่มตัดจำนวน Row-Col เพื่อนำไปทำ QAP Test (with Jaccard Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุ่ม Document 1/16, 1/8, 1/4, 1/2 เอามาทำ Cooc-matrix แล้วไล่ทำ QAP เทียบ 9000 doc กับ 4 ชุด dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "df_cooc_frq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)\n",
    "brands = ['เมจิ','ดัชมิลล์','โฟร์โมสต์','แดรี่โฮม','โชคชัย','เอ็มมิลค์','ไทยเดนมาร์ค']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rand1 = df_cooc_frq.sample(frac=(1/16))\n",
    "df_rand2 = df_cooc_frq.sample(frac=(1/8))\n",
    "df_rand3 = df_cooc_frq.sample(frac=(1/4))\n",
    "df_rand4 = df_cooc_frq.sample(frac=(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rand1_brand = df_rand1[brands]\n",
    "matrix_rand1_unbrand = df_rand1.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand2_brand = df_rand2[brands]\n",
    "matrix_rand2_unbrand = df_rand2.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand3_brand = df_rand3[brands]\n",
    "matrix_rand3_unbrand = df_rand3.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand4_brand = df_rand4[brands]\n",
    "matrix_rand4_unbrand = df_rand4.drop(labels=brands,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rand1.shape[0],df_rand2.shape[0],df_rand3.shape[0],df_rand4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "def create_Random_Poportion(df_b, df_attr):\n",
    "    precomputed_matrix = pd.DataFrame(index=df_b.columns,columns=df_b.columns).fillna(0)\n",
    "    \n",
    "    jacc = pd.DataFrame(columns=df_attr.columns)\n",
    "    jacc = jacc.append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)\n",
    "    \n",
    "    for i in range(0,len(precomputed_matrix.columns)):\n",
    "        for j in range(0,len(precomputed_matrix.columns)):\n",
    "            for k in range(0,len(df_attr.columns)): # 0 to 329\n",
    "                try:\n",
    "                    jacc.iloc[0,k] = jaccard_index(df_b, df_attr,i, j, k)\n",
    "                except Exception:\n",
    "                    jacc.iloc[0,k] = None\n",
    "                    continue\n",
    "            precomputed_matrix.iloc[i,j] = jacc.mean(axis=1)[0]\n",
    "            jacc = jacc.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)\n",
    "    return precomputed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand1_brand,matrix_rand1_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion1.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand2_brand,matrix_rand2_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion2.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand3_brand,matrix_rand3_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion3.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand4_brand,matrix_rand4_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion4.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "การเทียบ QAP - matrix จะต้องเป็น sim หรือ dissim เหมือนกันทั้งสองฝั่ง (ในที่นี้ใช้ sim)<br>\n",
    "การออกกราฟ - matrix ใช้ Similarity<br>\n",
    "การทำ MDS - matrix ใช้ Dissimilarity (distance) เท่านั้น<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EpwX95XlTCdl",
    "_Q9pU1J6TCe5",
    "NKW--A73mzli",
    "uBBA36fDTCfZ",
    "O8nlNNE4TCfj"
   ],
   "name": "EDA_Token_CoocMat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
