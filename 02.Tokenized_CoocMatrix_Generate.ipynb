{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoY8sy40TCb5"
   },
   "source": [
    "### IS - Brand position\n",
    "Finding Product position on Semantic Network (PPSN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28353,
     "status": "ok",
     "timestamp": 1604024868503,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "GkBEUBUqTGuf",
    "outputId": "cb22db45-820a-48fd-c11a-a0568439778f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1604024868819,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_5mrzpx3TH9K",
    "outputId": "129bb192-4ac2-4b03-bc89-7ee7a65d5032"
   },
   "source": [
    "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Master_PJ_DRMABS/Datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity: 1 คือเหมือน 0 คือต่าง<br>\n",
    "dissimilarity 1 คือต่าง 0 คือเหมือน : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1604024879769,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cC0cBdCdTCb6"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import pymongo\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\types\\oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\builtins\\misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1604024879770,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "1kqXURiiTCb-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1604028167896,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "weEcXSD8TCcI",
    "outputId": "1219680e-0d54-4649-a26e-535e112f0650"
   },
   "outputs": [],
   "source": [
    "# PyThaiNLP v2.3.0-beta1 is The first beta release of PyThaiNLP 2.3\n",
    "\n",
    "from pythainlp.util import normalize\n",
    "#from newnewthaicut import word_tokenize  # IOB Tagging tokenized\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.spell import correct\n",
    "\n",
    "from pythainlp.util import dict_trie\n",
    "from pythainlp.corpus.common import thai_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from sklearn.metrics import jaccard_score\n",
    "#from mlxtend.evaluate import lift_score\n",
    "#from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1604027698593,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "sna_e7nATCch"
   },
   "outputs": [],
   "source": [
    "# Files definition\n",
    "root_input_path = 'Datasource'\n",
    "root_output_path = 'output'\n",
    "\n",
    "comment_nlp_file = root_output_path+\"/comment_nlpToken.csv\"\n",
    "comment_cooc_freq_file = root_output_path+\"/comment_cooc_freq.xlsx\"\n",
    "comment_cooc_jacc_file = root_output_path+\"/comment_cooc_jacc.xlsx\"\n",
    "\n",
    "comment_robust_jaccard = root_output_path+\"/comment_robust_jaccard.xlsx\"\n",
    "comment_robust_lift = root_output_path+\"/comment_robust_lift.xlsx\"\n",
    "comment_robust_incur = root_output_path+\"/comment_robust_incur.xlsx\"\n",
    "comment_robust_cosine = root_output_path+\"/comment_robust_cosine.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"NIDA_PPSN_PRD\"]\n",
    "col_thread = mydb[\"NIDA_PPSN_THREAD\"]\n",
    "col_comment = mydb[\"NIDA_PPSN_COMMENT\"]\n",
    "col_scrape = mydb[\"NIDA_PPSN_SCRAPE\"]\n",
    "col_claen = mydb[\"NIDA_PPSN_CLEANED_DATA\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlnotsqqTCcl"
   },
   "source": [
    "### 1.Clean data & NLP Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_corpus = col_scrape.find()\n",
    "df_Corpus = pd.DataFrame(cursor_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2677,
     "status": "ok",
     "timestamp": 1604027704431,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "VXYRZDubTCcm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6058a2fe8fb21a3a76d2d5de</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6058a2fe8fb21a3a76d2d5df</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เบาหวานครับ แฮ่ๆ</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6058a2fe8fb21a3a76d2d5e0</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6058a2fe8fb21a3a76d2d5e1</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6058a2fe8fb21a3a76d2d5e2</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                               URLs  \\\n",
       "0  6058a2fe8fb21a3a76d2d5de  https://pantip.com/topic/39868603   \n",
       "1  6058a2fe8fb21a3a76d2d5df  https://pantip.com/topic/39868603   \n",
       "2  6058a2fe8fb21a3a76d2d5e0  https://pantip.com/topic/39868603   \n",
       "3  6058a2fe8fb21a3a76d2d5e1  https://pantip.com/topic/39868603   \n",
       "4  6058a2fe8fb21a3a76d2d5e2  https://pantip.com/topic/39868603   \n",
       "\n",
       "                     headline  \\\n",
       "0  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "2  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "3  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "4  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "\n",
       "                                                text        article_date  \\\n",
       "0  เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา... 2020-05-05 13:22:59   \n",
       "1                                   เบาหวานครับ แฮ่ๆ 2020-05-05 13:22:59   \n",
       "2  หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย... 2020-05-05 13:22:59   \n",
       "3  เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย... 2020-05-05 13:22:59   \n",
       "4  ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย... 2020-05-05 13:22:59   \n",
       "\n",
       "            Retrived_date  \n",
       "0 2021-03-22 21:00:24.737  \n",
       "1 2021-03-22 21:00:24.737  \n",
       "2 2021-03-22 21:00:24.737  \n",
       "3 2021-03-22 21:00:24.737  \n",
       "4 2021-03-22 21:00:24.737  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1604027718134,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "Xf0_nwz8TCdB",
    "outputId": "d39ed4de-8549-4488-d8c5-04e62e8a4dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All comment: 225360\n",
      "All URLs ก่อนตัด: 4995\n"
     ]
    }
   ],
   "source": [
    "print('All comment:',df_Corpus.shape[0])\n",
    "print('All URLs ก่อนตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1604027719151,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "vRH0T2gLTCdE",
    "outputId": "0722d375-5945-44d8-bc71-f39dcc58a0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id              0\n",
      "URLs             0\n",
      "headline         0\n",
      "text             0\n",
      "article_date     0\n",
      "Retrived_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1604027721340,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "LXg1m0eoTCdK",
    "outputId": "567e2a04-8322-4104-9f68-6d509815fd24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225355</th>\n",
       "      <td>605c03f52f6c7bb657e87ed0</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>สรุปว่าควรเวทก่อนแล้วค่อย Cardio ใช่มั้ยคะ</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225356</th>\n",
       "      <td>605c03f52f6c7bb657e87ed1</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225357</th>\n",
       "      <td>605c03f52f6c7bb657e87ed2</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225358</th>\n",
       "      <td>605c03f52f6c7bb657e87ed3</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>^^</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225359</th>\n",
       "      <td>605c03f52f6c7bb657e87ed4</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>ดีครับ ขอบคุณ จขกท และสมาชิกอื่นๆที่มาช่วยแชร์...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             _id                               URLs  \\\n",
       "225355  605c03f52f6c7bb657e87ed0  https://pantip.com/topic/30062751   \n",
       "225356  605c03f52f6c7bb657e87ed1  https://pantip.com/topic/30062751   \n",
       "225357  605c03f52f6c7bb657e87ed2  https://pantip.com/topic/30062751   \n",
       "225358  605c03f52f6c7bb657e87ed3  https://pantip.com/topic/30062751   \n",
       "225359  605c03f52f6c7bb657e87ed4  https://pantip.com/topic/30062751   \n",
       "\n",
       "                                                headline  \\\n",
       "225355  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225356  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225357  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225358  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225359  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "\n",
       "                                                     text        article_date  \\\n",
       "225355         สรุปว่าควรเวทก่อนแล้วค่อย Cardio ใช่มั้ยคะ 2013-10-09 11:22:34   \n",
       "225356  กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร... 2013-10-09 11:22:34   \n",
       "225357  กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร... 2013-10-09 11:22:34   \n",
       "225358                                                 ^^ 2013-10-09 11:22:34   \n",
       "225359  ดีครับ ขอบคุณ จขกท และสมาชิกอื่นๆที่มาช่วยแชร์... 2013-10-09 11:22:34   \n",
       "\n",
       "                 Retrived_date  \n",
       "225355 2021-03-25 10:30:08.736  \n",
       "225356 2021-03-25 10:30:08.736  \n",
       "225357 2021-03-25 10:30:08.736  \n",
       "225358 2021-03-25 10:30:08.736  \n",
       "225359 2021-03-25 10:30:08.736  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Corpus.drop('_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1604027723160,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_O0BSe9ETCdO"
   },
   "outputs": [],
   "source": [
    "seqNum = list(range(1,df_Corpus.shape[0]+1))\n",
    "df_Corpus.insert(0,'commentId',seqNum)\n",
    "df_Corpus.columns = ['commentId','URLs','headline','text','article_date','Retrived_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1604027724691,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "w-muagoxTCdR",
    "outputId": "a8afe33d-943b-422e-838d-ba8514e9497d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225355</th>\n",
       "      <td>225356</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>สรุปว่าควรเวทก่อนแล้วค่อย Cardio ใช่มั้ยคะ</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225356</th>\n",
       "      <td>225357</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225357</th>\n",
       "      <td>225358</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225358</th>\n",
       "      <td>225359</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>^^</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225359</th>\n",
       "      <td>225360</td>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>ดีครับ ขอบคุณ จขกท และสมาชิกอื่นๆที่มาช่วยแชร์...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        commentId                               URLs  \\\n",
       "225355     225356  https://pantip.com/topic/30062751   \n",
       "225356     225357  https://pantip.com/topic/30062751   \n",
       "225357     225358  https://pantip.com/topic/30062751   \n",
       "225358     225359  https://pantip.com/topic/30062751   \n",
       "225359     225360  https://pantip.com/topic/30062751   \n",
       "\n",
       "                                                headline  \\\n",
       "225355  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225356  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225357  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225358  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225359  ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "\n",
       "                                                     text        article_date  \\\n",
       "225355         สรุปว่าควรเวทก่อนแล้วค่อย Cardio ใช่มั้ยคะ 2013-10-09 11:22:34   \n",
       "225356  กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร... 2013-10-09 11:22:34   \n",
       "225357  กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร... 2013-10-09 11:22:34   \n",
       "225358                                                 ^^ 2013-10-09 11:22:34   \n",
       "225359  ดีครับ ขอบคุณ จขกท และสมาชิกอื่นๆที่มาช่วยแชร์... 2013-10-09 11:22:34   \n",
       "\n",
       "                 Retrived_date  \n",
       "225355 2021-03-25 10:30:08.736  \n",
       "225356 2021-03-25 10:30:08.736  \n",
       "225357 2021-03-25 10:30:08.736  \n",
       "225358 2021-03-25 10:30:08.736  \n",
       "225359 2021-03-25 10:30:08.736  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1604027727940,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "jZFN_aTsTCdU"
   },
   "outputs": [],
   "source": [
    "# Drop NA & banned comments\n",
    "df_Corpus = df_Corpus.dropna()\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('ความคิดเห็นนี้ถูกลบ')!= 0]\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('แก้ไขข้อความเมื่อ')!= 0]\n",
    "df_Corpus = df_Corpus.set_index('commentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1604027727941,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "ki-qD4YMTCdX",
    "outputId": "3102d8b3-3251-463e-f3e2-50a119fe787b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs             0\n",
      "headline         0\n",
      "text             0\n",
      "article_date     0\n",
      "Retrived_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1604027730567,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "c0J7GD3ATCda",
    "outputId": "f8748ddd-9aab-40d2-ee9e-38ba742906b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน comment หลังตัด: 221841\n",
      "จำนวนกระทู้หลังตัด: 4994\n"
     ]
    }
   ],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027730892,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "PKvz8tQpTCdd",
    "outputId": "62e2d990-0240-4a01-cef5-515147c6750c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>token_text</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225356</th>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>สรุปว่าควรเวทก่อนแล้วค่อย Cardio ใช่มั้ยคะ</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225357</th>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225358</th>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225359</th>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>^^</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225360</th>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>ดีครับ ขอบคุณ จขกท และสมาชิกอื่นๆที่มาช่วยแชร์...</td>\n",
       "      <td>2013-10-09 11:22:34</td>\n",
       "      <td>None</td>\n",
       "      <td>2021-03-25 10:30:08.736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        URLs  \\\n",
       "commentId                                      \n",
       "225356     https://pantip.com/topic/30062751   \n",
       "225357     https://pantip.com/topic/30062751   \n",
       "225358     https://pantip.com/topic/30062751   \n",
       "225359     https://pantip.com/topic/30062751   \n",
       "225360     https://pantip.com/topic/30062751   \n",
       "\n",
       "                                                   headline  \\\n",
       "commentId                                                     \n",
       "225356     ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225357     ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225358     ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225359     ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "225360     ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ   \n",
       "\n",
       "                                                        text  \\\n",
       "commentId                                                      \n",
       "225356            สรุปว่าควรเวทก่อนแล้วค่อย Cardio ใช่มั้ยคะ   \n",
       "225357     กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...   \n",
       "225358     กระทู้นี้ไม่เห็นด้วยเรื่ิองเวย์ ที่บอกว่าอันตร...   \n",
       "225359                                                    ^^   \n",
       "225360     ดีครับ ขอบคุณ จขกท และสมาชิกอื่นๆที่มาช่วยแชร์...   \n",
       "\n",
       "                 article_date token_text           Retrived_date  \n",
       "commentId                                                         \n",
       "225356    2013-10-09 11:22:34       None 2021-03-25 10:30:08.736  \n",
       "225357    2013-10-09 11:22:34       None 2021-03-25 10:30:08.736  \n",
       "225358    2013-10-09 11:22:34       None 2021-03-25 10:30:08.736  \n",
       "225359    2013-10-09 11:22:34       None 2021-03-25 10:30:08.736  \n",
       "225360    2013-10-09 11:22:34       None 2021-03-25 10:30:08.736  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.insert(4,'token_text',None)\n",
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็ควันเวลา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กระทู้เก่าที่สุด : 2013-01-03 09:20:18\n",
      "กระทู้ใหม่ที่สุด : 2021-03-20 16:56:47\n"
     ]
    }
   ],
   "source": [
    "print('กระทู้เก่าที่สุด :',min(df_Corpus.article_date))\n",
    "print('กระทู้ใหม่ที่สุด :',max(df_Corpus.article_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เก็บเฉพาะหัวกระทู้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>mention_product</th>\n",
       "      <th>mention_brand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>225076</th>\n",
       "      <td>https://pantip.com/topic/30038478</td>\n",
       "      <td>แนะนำด้วยคะ ไปฮ่องกงกับลูกสาวอายุขวบสี่เดือน</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225080</th>\n",
       "      <td>https://pantip.com/topic/30149550</td>\n",
       "      <td>นมกล่อง uht เจาะแล้วอยู่ได้นานแค่ไหน และนมเปรี...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225085</th>\n",
       "      <td>https://pantip.com/topic/30023475</td>\n",
       "      <td>นมถุง ที่ขายในโรงเรียน มีขายที่อื่นในกทม.อีกไห...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225120</th>\n",
       "      <td>https://pantip.com/topic/30022399</td>\n",
       "      <td>ถามหาที่ขายนมแพะค่ะ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225126</th>\n",
       "      <td>https://pantip.com/topic/30062751</td>\n",
       "      <td>ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        URLs  \\\n",
       "commentId                                      \n",
       "225076     https://pantip.com/topic/30038478   \n",
       "225080     https://pantip.com/topic/30149550   \n",
       "225085     https://pantip.com/topic/30023475   \n",
       "225120     https://pantip.com/topic/30022399   \n",
       "225126     https://pantip.com/topic/30062751   \n",
       "\n",
       "                                                    headline token_headline  \\\n",
       "commentId                                                                     \n",
       "225076          แนะนำด้วยคะ ไปฮ่องกงกับลูกสาวอายุขวบสี่เดือน           None   \n",
       "225080     นมกล่อง uht เจาะแล้วอยู่ได้นานแค่ไหน และนมเปรี...           None   \n",
       "225085     นมถุง ที่ขายในโรงเรียน มีขายที่อื่นในกทม.อีกไห...           None   \n",
       "225120                                   ถามหาที่ขายนมแพะค่ะ           None   \n",
       "225126      ใครที่คิดจะไปออกกำลังกายที่ฟิตเนส  มีคำแนะนำครับ           None   \n",
       "\n",
       "          mention_product mention_brand  \n",
       "commentId                                \n",
       "225076               None          None  \n",
       "225080               None          None  \n",
       "225085               None          None  \n",
       "225120               None          None  \n",
       "225126               None          None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread = df_Corpus.copy()\n",
    "df_thread = df_thread[['URLs','headline']]\n",
    "df_thread.drop_duplicates(subset =\"URLs\", keep = 'first', inplace = True)\n",
    "df_thread.insert(2,'token_headline',None)\n",
    "df_thread.insert(3,'mention_product',None)\n",
    "df_thread.insert(4,'mention_brand',None)\n",
    "df_thread.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpwX95XlTCdl"
   },
   "source": [
    "## 2.ตัดคำและเก็บลง MongoDB (ใช้ insight จาก jupyter งานก่อน)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U__d4agTCdl"
   },
   "source": [
    "https://www.thainlp.org/pythainlp/tutorials/notebooks/pythainlp-get-started.html#Thai-Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1604028299778,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cr_O7hE5htx2"
   },
   "outputs": [],
   "source": [
    "def normThai(w):\n",
    "    returnList = []\n",
    "    for i in w:\n",
    "        returnList.append(normalize(i))\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_list = ['ดัชมิลล์','ดัชมิล','ดัชมิว','dutch mill','dutch milk','ดัชชี่','เมจิ','ซีพีเมจิ','ซีพี เมจิ','cp meiji','betagen','บีทาเก้น','บีทาเกน'\n",
    "               ,'โฟร์โมสต์','โฟร์โมส','โฟโมสต์','โฟโมต','โฟโมส','โฟโม้ส','โฟรโมสต์','โฟรโมสต','โชคชัย','แดรี่โฮม','dairy home','เดรี่โฮม','เดลี่โฮม'\n",
    "               ,'อืมม มิลค์','umm milk','เอ็มมิลค์','m milk','mmilk','เอ็มมิ้ลค์','เอ็มมิลล์','แมคโนเลีย','นมฟาร์มโชคชัย','ไทยเดนมาร์ค','ไทยเดนมาร์ก'\n",
    "               ,'นมวัวแดง','หนองโพ','คาเนชั่น'\n",
    "               ,'สตอเบอร์รี่','สตรอว์เบอร์รี','รสสตรอเบอรี่','สตรอเบอรี่','สตรอวเบอรี่','สตอเบอรี่','สตรอเบอรี่','สตรอเบอร์รี่','สตรอเบอรี'\n",
    "               ,'ชอคโกแล็ต','ช็อกโกแลต','ช็อคโกแลต','ช๊อกโกแลต','ช็อคโกแล็ต','ช็อกโกเลต','มิ้นท์ชอค','มิ้นต์ช้อก','รสกล้วย'\n",
    "               ,'รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','low fat','0% fat','ขาดมันเนย','พร่องมันเนย','ไฮแคลเซียม'\n",
    "               ,'high protein','whey formula','วานิลลา','วิปครีม','สูตรลดน้ำตาล'\n",
    "               ,'ไฮโปรตีน','เวย์โปรตีน','whey','เวย์','อัลมอนด์','ซีเล็ค','ซีเล็คท์','กล้วยหอม','ไวท์คอฟฟี่','คาปูชิโน่','อเมริกาโน่'\n",
    "               ,'grass fed','free lactose','lactose free','พาสเจอไรซ์','พาสเจอร์ไรซ์','พาสเจอร์ไรส์','พาซเจอไรซ์','พาสเจอร์ไลท์'\n",
    "               ,'เมจิโกลด์ แม็กซ์','เมจิโกลด์','เมจิ โกลด์','เมจิโกล์ดแม็กซ์','เมจิ บัลแกเรีย','เมจิบัลแกเรีย','นมเปรี้ยว','รสธรรมชาติ','รสกลมกล่อม','ไพเกน'\n",
    "               ,'โยเกิต','โยเกิรต','โยเกิร์ตพร้อมดื่ม','น้ำตาลมะพร้าว','นมฮอกไกโด','เบดไทม์','ฟรีแลคโตส','แลคโตสฟรี','ริชเอสเพสโซ่'\n",
    "               ,'bedtime','bed time','เบดไทม์','ดาร์คช็อกโกแลต','ดาร์กช็อก','ดาร์กช็อกโกแลต'\n",
    "               ,'คาราเมล','ช็อกโกมอลต์','เมล่อน','ชาเขียวมัจฉะ','ชาไทย','ฝาน้ำเงิน','ผลิตภันท์นม','เต้าฮวยนมสด','nondairy','non dairy'\n",
    "               ,'7 eleven','เซเว่น อีเลฟเว่น','เซเว่นอีเลฟเว่น','เซเว่น','เซเวน','7 11','สตาร์บัค','อเมซอน'\n",
    "               ,'ท็อปส์','ทอปส์','ท้อปส์','ท๊อปส์','แมคโคร','แม็คโคร','โลตัส','บิ๊กซี','bigc','golden place','big c','พนักงานขายนม'\n",
    "               ,'ขายไม่ดี','แพคคู่','ค่าจัดส่ง','shelf life','พนักงานขายนม','ซื้อประจำ','หายาก','หาซื้อ','ของแถม','ราคาสูง','น้ำนมโค','นมโค','นมโคแท้','นมแพะ'\n",
    "               ,'นมโรงเรียน','แพ้นม','แพ้นมวัว','นมอัดเม็ด','นมวัว','ตัวเตี้ย','ตัวสูง','แจกของ','ราคาถูก','ราคาแพง','นมแม่','ครีมเทียม','นมข้นหวาน','นมขวด'\n",
    "               ,'เล่นเวท','นำ้หนัก','คุณแม่มือใหม่','นมอุ่น','ชานม','กินนม','ดื่มนม','ท้องเสีย','ขี้แตก','คุมอาหาร','นักวิ่ง','ร้านนมสด','ดูแลสุขภาพ','คนท้อง','มวลกระดูก'\n",
    "               ,'คีเฟอร์นม','พันทิป','ร้านนม','เหมียวน้อย','ลูกสุนัข','ลูกหมา','คายทิ้ง','เจมส์ จิ','เจมส์จิ','ณเดช','ณเดชน์','สตอรี่' ,'อยากสูง','ส่วนสูง','สูงขึ้น','รักษามะเร็ง'\n",
    "               ,'รักษาเบาหวาน','กระดูกพัง','กระดูกหัก','กระดูกแตก','กระดูกแข็งแรง','กระดูกยาว','กระดูกพรุน','ไม่ชอบ','ไม่ได้','ไม่อร่อย','ชาไข่มุก','ชานมไข่มุก'\n",
    "               ,'นมข้น','อเมซอน','นมเมจิสีฟ้า','ทำฟอง','ตีฟอง','โฟมนม','มื้อเช้า','ไขมันทรานส์','ดาราเดลี่','แดรี่ฟาร์ม','แดรี่ควีน','ควบคุมอาหาร','เสริมสร้างร่างกาย'\n",
    "               ,'ซ่อมแซมส่วนที่สึกหรอ','เสริมสร้างกระดูก','แอนตี้ไบโอติก','แพ็ก','แพกเกจ','แพ็กเกจ','แพ็ค','แพ๊ค','แพคเกจ','แพ็คเกจ','แคลเซี่ยม','เพิ่มน้ำหนัก'\n",
    "               ,'ฟองนม','ไม่คุ้มค่า','ราคาที่จ่าย']\n",
    "words = set(thai_words()).union(set(custom_list))\n",
    "trie = dict_trie(dict_source=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1604030224171,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "rAcuuoYiTCdu"
   },
   "outputs": [],
   "source": [
    "garbage_char = ['ไม่','','.','..','...','มกราคม', 'กุมภาพันธ์','มีนาคม', 'เมษายน','พฤษภาคม', 'มิถุนายน', 'กรกฎาคม','สิงหาคม','กันยายน'\n",
    "                ,'ตุลาคม','พฤศจิกายน', 'ธันวาคม','วันจันทร์','วันอังคาร','วันพุธ','วันพฤหัสบดี','วันศุกร์','วันเสาร์','วันอาทิตย์','กก'\n",
    "                ,'เมนู','Menu','Net','net','สาขา','บาท','ราคา','ฯ','ๆ','กก','อันนี้','😆', '🤣','😢','😏','😂','😿','🥺','ววว','xx','อิอิ','แย้ววว']\n",
    "naka = ['นะคะ','นะค่ะ','น่ะค่ะ','น่ะคะ','ฮ้าฟ','ค้าบ','คร้าบ']\n",
    "\n",
    "stopwords = set(thai_stopwords()).union(set(naka))\n",
    "stopwords.remove('ไม่')\n",
    "stopwords.remove('สูง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1604027849933,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "mAwAGA5ITCdx",
    "outputId": "d95e59bb-b35e-4592-f16e-0915a7975f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน comment หลังตัด: 221841\n",
      "จำนวนกระทู้หลังตัด: 4994\n"
     ]
    }
   ],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_custom(x):\n",
    "    custom_punc = '!.—-\"$#&฿/&\\'()*+,:;<=>?@[\\\\]^_`{|}~'\n",
    "    x = x.translate(str.maketrans('', '', custom_punc)).strip()\n",
    "    x = x.translate(str.maketrans({\"\\t\":None,\"\\n\": None})).strip()\n",
    "    x = x.lower()\n",
    "    wtkn = word_tokenize(x, custom_dict=trie, engine='newmm')\n",
    "    #wtkn = word_tokenize(x, engine='nercut') # if using custom dict, modify named_entity.py\n",
    "    wtkn = [j for j in wtkn if j not in stopwords]\n",
    "    wtkn = [w for w in wtkn if len(w) >= 2]\n",
    "    wtkn = [y for y in wtkn if y not in garbage_char]\n",
    "    wtkn = [s for s in wtkn if not s.isdigit()]\n",
    "    wtkn = normThai(wtkn)\n",
    "    return wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize_custom('มานีมีลูกแมวดัชมิวเหมียวจริงๆ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_Thread(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"URLs\": lx,\n",
    "            \"headline\": df.headline[c],\n",
    "            \"token_headline\":df.token_headline[c],\n",
    "            \"t_mention_dairy\":df.t_mention_dairy[c],\n",
    "            \"t_mention_product\": df.t_mention_product[c],\n",
    "            \"t_mention_brand\": df.t_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_comments(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"commentId\":int(df.commentId[c]),\n",
    "            \"URLs\": lx,\n",
    "            \"headline\":df.headline[c],\n",
    "            \"text\": df.text[c],\n",
    "            \"Retrived_date\": df.Retrived_date[c],\n",
    "            \"token_text\":df.token_text[c],\n",
    "            \"cmt_mention_dairy\": df.cmt_mention_dairy[c],\n",
    "            \"cmt_mention_product\": df.cmt_mention_product[c],\n",
    "            \"cmt_mention_brand\": df.cmt_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_keyword(wtkn):  \n",
    "    ret_wtkn = wtkn\n",
    "    for i,each in enumerate(ret_wtkn,0):\n",
    "        if each in ['ดัชมิลล์','ดัชมิล','ดัชมิว','dutchmill','dutch mill','dutch milk','dutchmilk','duchmill','duchie-bio','ดัชชี่']:\n",
    "            ret_wtkn[i] = 'ดัชมิลล์'\n",
    "        elif each  in ['เมจิ','ซีพีเมจิ','ซีพี เมจิ','cp meiji','meiji','meji','miji','cpmeijicom','cpmeijitensai','cpmeijithailand']:\n",
    "            ret_wtkn[i] = 'เมจิ'\n",
    "        elif each  in ['โฟร์โมสต์','โฟร์โมสท์','โฟร์โมส','โฟโมสต์','โฟโมต','โฟรโมสต์','โฟรโมสต','foremost']:\n",
    "            ret_wtkn[i] = 'โฟร์โมสต์'\n",
    "        elif each  in ['แดรี่โฮม','dairy home','dairyhome','เดรี่โฮม','เดลี่โฮม']:\n",
    "            ret_wtkn[i] = 'แดรี่โฮม'\n",
    "        elif each  in ['โชคชัย','อืมม มิลค์','umm milk','นมฟาร์มโชคชัย']:\n",
    "            ret_wtkn[i] = 'โชคชัย'\n",
    "        elif each  in ['เอ็มมิลค์','mmilk','เอ็มมิ้ลค์','เอ็มมิลล์','m milk']:\n",
    "            ret_wtkn[i] = 'เอ็มมิลค์'\n",
    "        elif each  in ['ไทยเดนมาร์ค','ไทยเดนมาร์ก','ไทย เดนมาร์ค','ไทย เดนมาร์ก','นมวัวแดง']:\n",
    "            ret_wtkn[i] = 'ไทยเดนมาร์ค'\n",
    "        elif each  in ['สตอเบอร์รี่','สตรอว์เบอร์รี','รสสตรอเบอรี่','สตรอเบอรี่','สตรอวเบอรี่','สตอเบอรี่','สตรอเบอรี่','สตรอเบอร์รี่','สตรอเบอรี']:\n",
    "            ret_wtkn[i] = 'สตรอว์เบอร์รี'\n",
    "        elif each  in ['ชอคโกแล็ต','ช็อกโกแลต','ช็อคโกแลต','ช๊อกโกแลต','ช็อคโกแล็ต','ช็อกโกเลต','ช็อค']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลต'\n",
    "        elif each  in ['มิ้นท์ชอค','มิ้นต์ช้อก','ช็อคโกแลตมินต์','มินต์ช็อคโกแลต']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลตมินต์'\n",
    "        elif each  in ['ไขมันต่ำ','low fat','พร่องมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมันต่ำ'\n",
    "        elif each  in ['ไขมัน 0','ไขมัน 0%','0 fat','0% fat','ขาดมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมัน 0%'\n",
    "        elif each  in ['high protein','hi protein','ไฮโปรตีน']:\n",
    "            ret_wtkn[i] = 'ไฮโปรตีน'\n",
    "        elif each  in ['free lactose','lactose free','ฟรีแลคโตส','แลคโตสฟรี']:\n",
    "            ret_wtkn[i] = 'นมฟรีแลคโตส'\n",
    "        elif each  in ['พาส','พาสเจอไรซ์','พาสเจอร์ไรซ์','พาสเจอร์ไรส์','พาซเจอไรซ์','พาสเจอร์ไลท์']:\n",
    "            ret_wtkn[i] = 'พาสเจอร์ไรส์'\n",
    "        elif each  in ['เมจิโกลด์ แม็กซ์','เมจิโกลด์','เมจิ โกลด์','เมจิโกล์ดแม็กซ์','gold','gold max']:\n",
    "            ret_wtkn[i] = 'เมจิโกลด์'\n",
    "        elif each  in ['ฝาน้ำเงิน','รสจืด']:\n",
    "            ret_wtkn[i] = 'รสจืด'\n",
    "        elif each  in ['ท็อปส์','ทอปส์','ท้อปส์','ท๊อปส์','tops']:\n",
    "            ret_wtkn[i] = 'tops'\n",
    "        elif each  in ['แมคโคร','แม็คโคร','makro']:\n",
    "            ret_wtkn[i] = 'makro'\n",
    "        elif each  in ['โลตัส','lotus']:\n",
    "            ret_wtkn[i] = 'lotus'\n",
    "        elif each  in ['บิ๊กซี','bigc','big c']:\n",
    "            ret_wtkn[i] = 'bigc'\n",
    "        elif each in ['ดาร์คช็อกโกแลต','ดาร์กช็อก','ดาร์กช็อกโกแลต']:\n",
    "            ret_wtkn[i] = 'ดาร์คช็อกโกแลต'\n",
    "        elif each in ['bedtime','bed time','เบดไทม์']:\n",
    "            ret_wtkn[i] = 'เบดไทม์'\n",
    "        elif each in ['เมจิ บัลแกเรีย','เมจิบัลแกเรีย','บัลแกเรีย','bulgaria']:\n",
    "            ret_wtkn[i] = 'เมจิบัลแกเรีย'\n",
    "        elif each in ['โยเกิร์ต','โยเกิต','โยเกิรต','โยเกิร์ตพร้อมดื่ม','yoghurt']:\n",
    "            ret_wtkn[i] = 'โยเกิร์ต'\n",
    "        elif each in ['7 Eleven','7 eleven','เซเว่น อีเลฟเว่น','เซเว่นอีเลฟเว่น','เซเว่น','เซเวน','7 11']:\n",
    "            ret_wtkn[i] = '7-Eleven'\n",
    "        elif each in ['บีทาเก้น','บีทาเกน']:\n",
    "            ret_wtkn[i] = 'บีทาเก้น'\n",
    "        elif each in ['โปร','โปรโมชั่น']:\n",
    "            ret_wtkn[i] = 'โปรโมชั่น'\n",
    "        elif each in ['นมวัว','นมโค','นมโคสด','น้ำนมโค']:\n",
    "            ret_wtkn[i] = 'นมโค'\n",
    "        elif each in ['แลกโตส','แล็กโต๊ส','แลคโตส','lactose']:\n",
    "            ret_wtkn[i] = 'แลคโตส' \n",
    "        elif each in ['แพ็ก','แพกเกจ','แพ็กเกจ','แพ็ค','แพ๊ค','แพคเกจ','แพ็คเกจ','บรรจุภัณฑ์']:\n",
    "            ret_wtkn[i] = 'บรรจุภัณฑ์'\n",
    "        elif each in ['แคลเซียม','แคลเซี่ยม','calcium']:\n",
    "            ret_wtkn[i] = 'แคลเซียม'\n",
    "        elif each in ['nondairy','non dairy']:\n",
    "            ret_wtkn[i] = 'nondairy'\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_brands_product(x,catType):\n",
    "    ret_wtkn = []\n",
    "    brands = ['ดัชมิลล์','เมจิ','โฟร์โมสต์','โชคชัย','แดรี่โฮม','เอ็มมิลค์','แมคโนเลีย','ไทยเดนมาร์ค','หนองโพ','คาเนชั่น','บีทาเก้น','จิตรลดา']\n",
    "    products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ','วิปครีม']\n",
    "    milk_kind=['นม','นมข้น','นมจืด','นมสด','นมโค','นมแพะ','นมวัว','นมแม่','หย่านม','กินนม','ดื่มนม','นมขวด','ขวดนม','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์','nondairy','นมโรงเรียน']\n",
    "    \n",
    "    choiceList = []\n",
    "    if catType == 'b':\n",
    "        choiceList = brands\n",
    "    elif catType == 'm':\n",
    "        choiceList = milk_kind\n",
    "    elif catType == 'p':\n",
    "        choiceList = products\n",
    "        \n",
    "    for i,each in enumerate(x,0):\n",
    "        if each in choiceList:\n",
    "            ret_wtkn.append(each)\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy ชุดคำจาก File มา Process ก่อนลง MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment = df_Corpus.reset_index().copy()\n",
    "df_process_thread = df_thread.reset_index().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Tokenize comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['text'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>token_text</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[ปี, เซเว่น, ยังมี, นม, เมจิ, รสหวาน, ขาย, อยู...</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เบาหวานครับ แฮ่ๆ</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[เบาหวาน, แฮ่]</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[หาซื้อ, ไม่ได้, คิดได้, , คน, กินกัน, ทำ, คน,...</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[รส, ขายไม่ดี, รส, พื้นฐาน, จืด, แบ่ง, low fat...</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[ขายไม่ดี, เค้า, shelf life, เวลา, หมดอายุ, ค่...</td>\n",
       "      <td>2021-03-22 21:00:24.737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                               URLs                    headline  \\\n",
       "0          1  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1          2  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "2          3  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "3          4  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "4          5  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "\n",
       "                                                text        article_date  \\\n",
       "0  เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา... 2020-05-05 13:22:59   \n",
       "1                                   เบาหวานครับ แฮ่ๆ 2020-05-05 13:22:59   \n",
       "2  หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย... 2020-05-05 13:22:59   \n",
       "3  เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย... 2020-05-05 13:22:59   \n",
       "4  ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย... 2020-05-05 13:22:59   \n",
       "\n",
       "                                          token_text           Retrived_date  \n",
       "0  [ปี, เซเว่น, ยังมี, นม, เมจิ, รสหวาน, ขาย, อยู... 2021-03-22 21:00:24.737  \n",
       "1                                     [เบาหวาน, แฮ่] 2021-03-22 21:00:24.737  \n",
       "2  [หาซื้อ, ไม่ได้, คิดได้, , คน, กินกัน, ทำ, คน,... 2021-03-22 21:00:24.737  \n",
       "3  [รส, ขายไม่ดี, รส, พื้นฐาน, จืด, แบ่ง, low fat... 2021-03-22 21:00:24.737  \n",
       "4  [ขายไม่ดี, เค้า, shelf life, เวลา, หมดอายุ, ค่... 2021-03-22 21:00:24.737  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process_comment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['token_text'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['cmt_mention_dairy'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_comment['cmt_mention_brand'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_comment['cmt_mention_product'] = None\n",
    "#df_process_comment['cmt_mention_product'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Insert comments to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hunm5MT7TCd2",
    "outputId": "15710375-8df1-46f0-85a2-04c66e1de5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1afd7875e48>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_comment.delete_many({})\n",
    "process_data = create_InsertMany_comments(df_process_comment)\n",
    "col_comment.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Tokenize head of thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['headline'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['token_headline'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6) Mark domain/entity mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['t_mention_dairy'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_thread['t_mention_brand'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_thread['t_mention_product'] = None\n",
    "#df_process_thread['t_mention_product'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>mention_product</th>\n",
       "      <th>mention_brand</th>\n",
       "      <th>t_mention_dairy</th>\n",
       "      <th>t_mention_brand</th>\n",
       "      <th>t_mention_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>https://pantip.com/topic/39747201</td>\n",
       "      <td>ทำไมนมเมจิขวดใหญ่ 2 ลิตร ไม่มีซีลที่ปากแบบขวดเล็ก</td>\n",
       "      <td>[นม, เมจิ, ขวด, ลิตร, ซีล, ปาก, ขวด]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>https://pantip.com/topic/39597709</td>\n",
       "      <td>ระหว่างนมเมจิต้มกับนมเมจิที่ไม่ได้ต้ม เมื่อนำไ...</td>\n",
       "      <td>[นม, เมจิ, ต้ม, นม, เมจิ, ไม่ได้, ต้ม, ทำ, เคร...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม, นม]</td>\n",
       "      <td>[เมจิ, เมจิ]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>https://pantip.com/topic/39928742</td>\n",
       "      <td>ติดนมมาก ทำยังไงดี?</td>\n",
       "      <td>[ติด, นม, ทำ, ดี]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>https://pantip.com/topic/40190870</td>\n",
       "      <td>สูง 147 ม.1 มีสิทธิสูงเพิ่มไหมครับ</td>\n",
       "      <td>[สูง, สิทธิ, สูง, ไหม]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                               URLs  \\\n",
       "0          1  https://pantip.com/topic/39868603   \n",
       "1          8  https://pantip.com/topic/39747201   \n",
       "2          9  https://pantip.com/topic/39597709   \n",
       "3         15  https://pantip.com/topic/39928742   \n",
       "4         26  https://pantip.com/topic/40190870   \n",
       "\n",
       "                                            headline  \\\n",
       "0                         นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1  ทำไมนมเมจิขวดใหญ่ 2 ลิตร ไม่มีซีลที่ปากแบบขวดเล็ก   \n",
       "2  ระหว่างนมเมจิต้มกับนมเมจิที่ไม่ได้ต้ม เมื่อนำไ...   \n",
       "3                                ติดนมมาก ทำยังไงดี?   \n",
       "4                 สูง 147 ม.1 มีสิทธิสูงเพิ่มไหมครับ   \n",
       "\n",
       "                                      token_headline mention_product  \\\n",
       "0                          [นม, เมจิ, รสหวาน, หายาก]            None   \n",
       "1               [นม, เมจิ, ขวด, ลิตร, ซีล, ปาก, ขวด]            None   \n",
       "2  [นม, เมจิ, ต้ม, นม, เมจิ, ไม่ได้, ต้ม, ทำ, เคร...            None   \n",
       "3                                  [ติด, นม, ทำ, ดี]            None   \n",
       "4                             [สูง, สิทธิ, สูง, ไหม]            None   \n",
       "\n",
       "  mention_brand t_mention_dairy t_mention_brand t_mention_product  \n",
       "0          None            [นม]          [เมจิ]              None  \n",
       "1          None            [นม]          [เมจิ]              None  \n",
       "2          None        [นม, นม]    [เมจิ, เมจิ]              None  \n",
       "3          None            [นม]              []              None  \n",
       "4          None              []              []              None  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process_thread.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7) Insert thread to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x1afd7a67248>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_thread.delete_many({})\n",
    "process_data = create_InsertMany_Thread(df_process_thread)\n",
    "col_thread.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027734766,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "J30GMUlJTCdh"
   },
   "outputs": [],
   "source": [
    "del df_thread,df_Corpus,df_process_comment,df_process_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.สรุป Term & reduced_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrributes = ['เก็บรักษา','เข้มข้น','เค้ก','เจมส์','เจมส์ จิ','เจมส์จิ','เจลลาติน','เจือจาง','เชื้อ','เชื้อโรค','เชื้อจุลินทรีย์','เชื้อรา','เด็ก','เด็กเล็ก','เด็กแรกเกิด'\n",
    "               ,'เด็กโต','เด็กชาย','เด็กทารก','เด็กน้อย','เด็กวัยรุ่น','เด็กอ่อน','เติบโต','เตี้ย','เนย','เนยแข็ง','เนยสด','เนสเล่','เนสกาแฟ','เนสท์เล่','เน่า','เน่าเสีย'\n",
    "               ,'เบาหวาน','เมจิ','เมจิโกลด์','เมจิบัลแกเรีย','เมล่อน','เย็น','เล่นเวท','เล่นกล้าม','เลี้ยง','เลี้ยงเด็ก','เลี้ยงดู','เลี้ยงลูก','เลี้ยงสัตว์','เวย์','เวย์โปรตีน'\n",
    "               ,'เหม็นเขียว','เหม็นเปรี้ยว','เหม็นคาว','เหม็นบูด','เอนไซม์','เอ็นไซม์','เอนฟาโกร','เอ็มมิลค์','เอสเปรสโซ','เอสเปรสโซ่','เอสเพรสโซ','เอสเพรสโซ่'\n",
    "               ,'แข็งแรง','แคนตาลูป','แคลเซียม','แคลเซี่ยม','แคลอรี','แคลอรี่','แจก','แช่เย็น','แชร์','แดรี่โฮม','แตงโม','แถม','แบคทีเรีย','แบบสอบถาม','แพ็ก'\n",
    "               ,'แพกเกจ','แพ็กเกจ','แพ็ค','แพ๊ค','แพคเกจ','แพ็คเกจ','แพคคู่','แพ้ท้อง','แพ้นม','แพ้นมวัว','แม่','แมกนีเซียม','แมคโนเลีย','แม่ลูกอ่อน','แร่ธาตุ'\n",
    "               ,'แลกโตส','แล็กโต๊ส','แลคโตส','แลคติก','แอโรบิค','แอนตี้ไบโอติก','แอปเปิล','แอปเปิ้ล','โกโก้','โฆษณา','โชคชัย','โซเดียม','โด้บ','โด๊บ','โด้ป'\n",
    "               ,'โด๊ป','โด้ปนม','โปรโมชั่น','โปรตีน','โพแทสเซียม','โฟเลต','โฟร์โมสต์','โฟลิค','โภชนาการ','โยเกิร์ต','โยเกิร์ท','โรคเบาหวาน','โรคกระเพาะ'\n",
    "               ,'โรคขาดอาหาร','โรคท้องร่วง','โรคประจำตัว','โรคภัยไข้เจ็บ','โรคภูมิแพ้','โรคมะเร็ง','โรคหัวใจ','โรงเรียน','โรงงาน','โอวัลติน','ให้นม','ให้อาหาร'\n",
    "               ,'ไขมัน','ไขมัน 0%','ไขมันต่ำ','ไทยเดนมาร์ค','ไอติม','ไอศกรีม','ไอศครีม','ไฮโปรตีน','กรดไขมัน','กรดอะมิโน','กระดูกพรุน','กระบวนการผลิต'\n",
    "               ,'กระป๋อง','กล้วย','กล้วหอม','กล่อง','กลิ่น','กลิ่นคาว','กลิ่นหอม','กลูโคส','กาเฟอีน','กาแฟ','กาแฟเย็น','กาแฟร้อน','กาแฟสด','การบรรจุ'\n",
    "               ,'การผลิต','การย่อยอาหาร','การลดน้ำหนัก','การลดราคา','การออกกำลังกาย','ข้น','ขนม','ขนมเค้ก','ขนมปัง','ขนมปังแผ่น','ขนมหวาน','ขนส่ง'\n",
    "               ,'ขวดโหล','ขวดนม','ขวบ','ขาดตลาด','ขายไม่ดี','ขายไม่ออก','ขายปลีก','ขายส่ง','ข้าว','ข้าวโพด','ข้าวโอ๊ต','ข้าวกล้อง','คนรุ่นใหม่','คนวัยหนุ่มสาว'\n",
    "               ,'คนสูงอายุ','ครรภ์','คลอเรสเตอรอล','คลอเลสเตอรอล','คลอโรฟิล','คลอดลูก','ความคุ้มค่า','ความมัน','ความร้อน','คอเลสเตอรอล','คาเฟอีน','ค่าขนส่ง'\n",
    "               ,'คาปูชิโน','คาปูชิน่','คาร์โบไฮเดรต','คาราเมล','คาว','คุณแม่','คุณแม่มือใหม่','คุณค่า','คุณประโยชน์','คุณภาพ','คุณภาพดี','ฆ่าเชื้อ','จิตรลดา','จืด'\n",
    "               ,'จุลินทรีย์','ฉลาก','ชง','ชงนม','ช็อกโกแลต','ช่องแช่แข็ง','ชอบ','ชา','ชาเขียว','ชาเขียวมัจฉะ','ชาเย็น','ชิม','ซื้อ','ซุปเปอร์มาร์เกต','ซุปเปอร์มาร์เก็ต'\n",
    "               ,'ดัชมิลล์','ดาร์คช็อกโกแลต','ต้ม','ตลาด','ตัวแทนจำหน่าย','ตู้เย็น','ท้องเสีย','ท้องตลาด','ท้องร่วง','ท้องว่าง','ท้องอืด','ทุเรียน','ธรรมชาติ','ธัญญาหาร'\n",
    "               ,'ธัญพืช','ธาตุเหล็ก','นม','นมเปรี้ยว','นมกล่อง','นมข้น','นมข้นหวาน','นมควาย','นมถั่วเหลือง','นมผง','นมฟรีแลคโตส','นมยูเอชที','นมวัว','นมสด'\n",
    "               ,'นมฮอกไกโด','นอน','น้ำ','นำเข้า','น้ำเชื่อม','น้ำเต้าหู้','น้ำตาล','น้ำตาลเทียม','น้ำตาลทราย','น้ำตาลทรายแดง','น้ำนม','น้ำผึ้ง','น้ำหนัก','บรรจุขวด'\n",
    "               ,'บลูเบอร์รี่','บัลแกเรีย','บัลกาเรีย','บาริสตา','บาริสต้า','บีทาเก้น','บูด','ปริมาณ','ปลอดเชื้อ','ปวดท้อง','ปั่น','ผลไม้','ผสม','ผู้จัดจำหน่าย','ผู้ผลิต','ฝา'\n",
    "               ,'พกพา','พนักงานขายนม','พลังงาน','พาราไดซ์','พารากอน','พาสเจอร์ไรส์','ฟรอยด์','ฟอง','ฟาร์ม','มอลต์','ยอดขาย','รสกลมกล่อม','รกล้วย','รสกาแฟ'\n",
    "               ,'รสจืด','รสชาติ','รสหวาน','ราคาแพง','ราคาสูง','ร่างกาย','ร้านกาแฟ','รีวิว','ลดความอ้วน','ลดน้ำหนัก','ลดราคา','ลูก','ลูกชาย','ลูกสาว','วันหมดอายุ'\n",
    "               ,'วานิลลา','วานิลล่า','วานิลา','วิ่ง','วิตามิน','สตรอเบอร์รี่','สตรอเบอรี','สตรอว์เบอร์รี','สต็อก','สต๊อก','สต็อค','สตาร์บัค','สยามพารากอน','สยามสแควร์'\n",
    "               ,'สละ','ส่วนผสม','สะอาด','สัปปะรด','สารอาหาร','สำนักงานคณะกรรมการอาหารและยา','สิ่งเจือปน','สูง','สูงวัย','สูตร','หญ้า','หนองโพ','หมอ','หลอด'\n",
    "               ,'หวาน','หอม','หางจระเข้','ห้างร้าน','อ้วน','ออกกำลังกาย','ออร์แกนิก','อะเมซอน','อาหาร','อาหารเสริม','อุณหภูมิ']\n",
    "\n",
    "stores = ['tops','makro','lotus','bigc','7-Eleven']\n",
    "\n",
    "#products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "#                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "#                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ']\n",
    "#milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "#                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์']\n",
    "\n",
    "#  EDA ใน Excel ได้ flavor 68 ตัว (ถ้าดึงยี่ห้ออื่นก็เพิ่มอีก)\n",
    "#avai_flavs = ['เมจิเมจิโกลด์','เมจิเมล่อน','เมจิไขมัน 0%','เมจิไขมันต่ำ','เมจิไฮโปรตีน','เมจิช็อกโกแลต','เมจิชาเขียวมัจฉะ','เมจิดาร์คช็อกโกแลต'\n",
    "# ,'เมจินมฟรีแลคโตส','เมจิบัลแกเรีย','เมจิมอลต์','เมจิรสกลมกล่อม','เมจิรสกล้วย','เมจิรกาแฟ','เมจิรสจืด','เมจิรสธรรมชาติ','เมจิรสหวาน'\n",
    "# ,'เมจิสตรอว์เบอร์รี','เมจิอัลมอนด์','เอ็มมิลค์นมฟรีแลคโตส','เอ็มมิลค์รสจืด','แดรี่โฮมgrass fed','แดรี่โฮมเบดไทม์','แดรี่โฮมช็อกโกแลต'\n",
    "# ,'แดรี่โฮมรสกล้วย','แดโฮมรสจืด','แดรี่โฮมรสหวาน','แดรี่โฮมสตรอว์เบอร์รี','แมคโนเลียไขมันต่ำ','แมคโนเลียช็อกโกแลต','แมคโนเลียรสจืด'\n",
    "# ,'โชคชัยไขมันต่ำ','โชคชัยช็อกโกแลต','โชคชัยรสกาแฟ','โชคชัยรสจืด','โชคชัยสตรอว์เบอร์รี','ฟร์โมสต์ไขมัน 0%','โฟร์โมสต์ไขมันต่ำ'\n",
    "# ,'โฟร์โมสต์คาราเมล','โฟร์โมสต์ช็อกโกแลต','โฟร์โมสต์รสกาแฟ','โฟร์โมสต์รสจืด','โฟร์โมสต์สตรอว์เบอร์รี','ไทยเดนมาร์คช็อกโกแลต'\n",
    "# ,'ไทยเดนมาร์ครสกาแฟ','ไทยเดนมาร์ครสจืด','ไทยเดนมาร์ครสหวาน','ไทยเดนมาร์คสตรอว์เบอร์รี','คาเนชั่นรสจืด','จิตรลดาช็อกโกแลต'\n",
    "# ,'จิตรลดารสจืด','จิตรลดารสหวาน','จิตรลดาสตรอว์เบอร์รี','ดัชมิลล์ไขมัน 0%','ดัชมิลล์ไขมันต่ำ','ดัชมิลล์ไฮโปรตีน','ดัชลล์อกกแลต'\n",
    "# ,'ดัชมิลล์มอลต์','ดัชมิลล์รสกาแฟ','ดัชมิลล์รสจืด','ดัชมิลล์สตรอว์เบอร์รี','หนองโพไขมัน 0%','หนองโพไขมันต่ำ','หนองโพช็อกโกแลต'\n",
    "# ,'หนองโพรสกาแฟ','หนองโพรสจืด','หนองโพรสหวาน','หนองโพสตรอว์เบอร์รี']\n",
    "\n",
    "reduceCol = attrributes + stores \n",
    "#reduceCol_all = attrributes + stores + milk_kind + products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_keyword(wtkn,redCol):\n",
    "    del_list = []\n",
    "    ret_wtkn = wtkn\n",
    "    for each in ret_wtkn:\n",
    "        if each not in redCol:\n",
    "            del_list.append(each)\n",
    "    ret_wtkn = [x for x in ret_wtkn if x not in del_list]\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def freq_brand(x):\n",
    "    #e = eval(x)\n",
    "    e = x\n",
    "    e.sort()\n",
    "    f = [(k,len(list(g))) for k, g in groupby(e)]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_flavor(x,y):\n",
    "    listflav = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            listflav.append(i+j)\n",
    "    return listflav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKW--A73mzli"
   },
   "source": [
    "### 5.สร้าง (Reduce) Bag of word ด้วย dictionary.doc2bow จัดลง dataframe<br>\n",
    "คัดเลือกกระทู้และความเห็นที่เกี่ยวกับนมในไฟล์ 03.EDA_Headline_Comment ก่อน จัดเก็บลง MongoDB แล้วจึงทำส่วนนี้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_clean = col_claen.find()\n",
    "df_join_url = pd.DataFrame(cursor_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text_reduce'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['reduce_bow'] = df_join_url[\"token_text_reduce\"].map(dictionary.doc2bow)\n",
    "df_join_url['token_text_reduce_cnt'] = df_join_url[\"reduce_bow\"].apply(lambda x:[(dictionary[id_], frequence) for id_, frequence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['article_date','reduce_bow'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cooccurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment ออกเมื่อไม่ concat brand+flavor\n",
    "df_final = df_join_url.copy()\n",
    "df_final.set_index('commentId',inplace=True)\n",
    "#df_final['mention_product'] = df_final['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "#df_final['mention_brand'] = df_final['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "#df_final['mention_domain'] = df_final['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brand_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_brand\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "#df_prd_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_product\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "df_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"token_text_reduce_cnt\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brand_cooc.reset_index(inplace=True)\n",
    "#df_prd_cooc.reset_index(inplace=True)\n",
    "df_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cooc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง  QAP mathod case2,4: Brand vs Product vs Attribute (ไม่เอาแล้ว)\n",
    "#join_df = pd.merge(df_brand_cooc, df_prd_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "#join_df = pd.merge(join_df, df_cooc, on='commentId', how='inner')\n",
    "\n",
    "# ทดลอง  QAP mathod case3: Product vs Attribute (ไม่เอาแล้ว)\n",
    "#join_df = pd.merge(df_prd_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ทดลอง  QAP mathod case1,5: Brand vs Attribute กรณีแยก ยี่ห้อ และ ผลิตภัณฑ์ จาก reduce_bow_txt\n",
    "#join_df = pd.merge(df_brand_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ไม่ Join ทำในกรณีไม่แยก ยี่ห้อ และ ผลิตภัณฑ์ ออกจาก reduce_bow_txt\n",
    "join_df = df_cooc.copy()\n",
    "\n",
    "join_df.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export ข้อมูล เพื่อนำไปสุ่มแถวทำ QAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.to_csv(root_output_path+\"/cooc_bow_all.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source for graph generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBBA36fDTCfZ"
   },
   "source": [
    "### 1.Create frequency co-occurrence matrix จาก Bag of word<br>\n",
    "* ใช้สำหรับทำ MDS และโยนเข้า R (ทำ normalized บน R) ในลักษณะ Term-Term Cross tabulation<br> \n",
    "(คนละอย่างกับ TF-IDF cooc matrix ที่เป็น Word-word ซึ่งต้องรัน bigram เป็นราย document)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "LgE1okejTCfZ"
   },
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def cnt_Grpby(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    cooc = slice_df[(slice_df.A>0)&(slice_df.B>0)]\n",
    "    return cooc.shape[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "1jhFte5eTCfd"
   },
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        if i != j:\n",
    "            item_item_matrix.iloc[i,j] = cnt_Grpby(join_df,i,j)\n",
    "        else:\n",
    "            item_item_matrix.iloc[i,j] = 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "OhtvLfMXTCfg"
   },
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "id": "bsbsqduDTCfh"
   },
   "source": [
    "item_item_matrix.to_excel(comment_cooc_freq_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Create co-occurrence matrix with Jaccard Distance สำหรับสร้างกราฟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)]\n",
    "    a_occur = slice_df[(slice_df.A>0)]\n",
    "    b_occur = slice_df[(slice_df.B>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        item_item_matrix.iloc[i,j] = jaccard_index(join_df,i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_jacc_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del item_item_matrix,join_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source for Robustness Check & Cross Validation (7x7 brands matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### คำนวณ Index ของยี่ห้อต่อยี่ห้อ จากทุกๆ Attributes แสดงผลเป็น Matrix ขนาด 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_freq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)\n",
    "#cooc_matrix_freq = pd.read_excel(comment_cooc_freq_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = ['เมจิ','ดัชมิลล์','โฟร์โมสต์','แดรี่โฮม','โชคชัย','เอ็มมิลค์','ไทยเดนมาร์ค']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_freq_brand = matrix_freq[brands]\n",
    "matrix_freq_unbrand = matrix_freq.drop(labels=brands,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose frequency into Attribute Rating Format for precompute MDS\n",
    "#cooc_matrix_freq = cooc_matrix_freq[brands]\n",
    "#cooc_matrix_freq.drop(brands, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# จำนวน Attributes = 330, brands = 7\n",
    "#cooc_matrix_freq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### 1.Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF: Lee Soojung,(2017). Improving Jaccard Index for Measuring Similarity in Collaborative Filtering\n",
    "# Information Science and Applications 2017, 124.\n",
    "def jaccard_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "jacc = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "jacc = jacc.append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                jacc.iloc[0,k] = jaccard_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                jacc.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = jacc.mean(axis=1)[0]\n",
    "        jacc = jacc.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_jaccard, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### 2.Lift normalization (Netzer et al., 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def lift_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    p_a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)].shape[0]/slice_df.shape[0]\n",
    "    p_a_occur = slice_df[(slice_df.A>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_occur = slice_df[(slice_df.B>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_comprem_occur = slice_df[(slice_df.B==0)].shape[0]/slice_df.shape[0]\n",
    "    lift = p_a_in_b/(p_a_occur*p_b_comprem_occur)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "# Follow style of Lee Soojung,(2017)\n",
    "def lift_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    p_a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_comprem_occur = (slice_df.shape[0]-p_b_occur)/slice_df.shape[0]\n",
    "    lift = p_a_in_b/(p_a_occur*p_b_comprem_occur)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "#item_item_matrix = pd.DataFrame(index=cooc_matrix_freq.columns,columns=cooc_matrix_freq.columns).fillna(0)\n",
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "lift = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "lift = lift.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                lift.iloc[0,k] = lift_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                lift.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = lift.mean(axis=1)[0]\n",
    "        lift = lift.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qG7pCYfTCfu"
   },
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_lift, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inclusion Index (Qin He, 1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def inclu_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)].shape[0]\n",
    "    a_occur = slice_df[(slice_df.A>0)].shape[0]\n",
    "    b_occur = slice_df[(slice_df.B>0)].shape[0]\n",
    "    inclu = a_in_b/min(a_occur,b_occur)\n",
    "    return inclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def inclu_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)].shape[0]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)].shape[0]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)].shape[0]\n",
    "    inclu = a_in_b/min(a_occur,b_occur)\n",
    "    return inclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "inclu = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "inclu = inclu.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                inclu.iloc[0,k] = inclu_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                inclu.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = inclu.mean(axis=1)[0]\n",
    "        inclu = inclu.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_incur, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.cosine similarity correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "# ต้องใช้ 1 เป็นตัวตั้งลบเสมอถ้าใช้ cosine จาก scipy.spatial.distance หากจะเอาค่า dissimliarity\n",
    "\n",
    "def cosine_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = a_in_b.iloc[:,0]\n",
    "    b_occur = a_in_b.iloc[:,2]\n",
    "    cosin = 1-cosine(a_occur,b_occur)\n",
    "    return cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "cosin = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "cosin = cosin.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Similarity (1-cosine-1)\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                cosin.iloc[0,k] = cosine_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                cosin.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = cosin.mean(axis=1)[0]\n",
    "        cosin = cosin.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_cosine, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.สุ่มตัดจำนวน Row-Col เพื่อนำไปทำ QAP Test (with Jaccard Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุ่ม Document 1/16, 1/8, 1/4, 1/2 เอามาทำ Cooc-matrix แล้วไล่ทำ QAP เทียบ 9000 doc กับ 4 ชุด dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "df_cooc_frq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)\n",
    "brands = ['เมจิ','ดัชมิลล์','โฟร์โมสต์','แดรี่โฮม','โชคชัย','เอ็มมิลค์','ไทยเดนมาร์ค']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rand1 = df_cooc_frq.sample(frac=(1/16))\n",
    "df_rand2 = df_cooc_frq.sample(frac=(1/8))\n",
    "df_rand3 = df_cooc_frq.sample(frac=(1/4))\n",
    "df_rand4 = df_cooc_frq.sample(frac=(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rand1_brand = df_rand1[brands]\n",
    "matrix_rand1_unbrand = df_rand1.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand2_brand = df_rand2[brands]\n",
    "matrix_rand2_unbrand = df_rand2.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand3_brand = df_rand3[brands]\n",
    "matrix_rand3_unbrand = df_rand3.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand4_brand = df_rand4[brands]\n",
    "matrix_rand4_unbrand = df_rand4.drop(labels=brands,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rand1.shape[0],df_rand2.shape[0],df_rand3.shape[0],df_rand4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "def create_Random_Poportion(df_b, df_attr):\n",
    "    precomputed_matrix = pd.DataFrame(index=df_b.columns,columns=df_b.columns).fillna(0)\n",
    "    \n",
    "    jacc = pd.DataFrame(columns=df_attr.columns)\n",
    "    jacc = jacc.append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)\n",
    "    \n",
    "    for i in range(0,len(precomputed_matrix.columns)):\n",
    "        for j in range(0,len(precomputed_matrix.columns)):\n",
    "            for k in range(0,len(df_attr.columns)): # 0 to 329\n",
    "                try:\n",
    "                    jacc.iloc[0,k] = jaccard_index(df_b, df_attr,i, j, k)\n",
    "                except Exception:\n",
    "                    jacc.iloc[0,k] = None\n",
    "                    continue\n",
    "            precomputed_matrix.iloc[i,j] = jacc.mean(axis=1)[0]\n",
    "            jacc = jacc.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)\n",
    "    return precomputed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand1_brand,matrix_rand1_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion1.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand2_brand,matrix_rand2_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion2.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand3_brand,matrix_rand3_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion3.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand4_brand,matrix_rand4_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion4.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "การเทียบ QAP - matrix จะต้องเป็น sim หรือ dissim เหมือนกันทั้งสองฝั่ง (ในที่นี้ใช้ sim)<br>\n",
    "การออกกราฟ - matrix ใช้ Similarity<br>\n",
    "การทำ MDS - matrix ใช้ Dissimilarity (distance) เท่านั้น<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EpwX95XlTCdl",
    "_Q9pU1J6TCe5",
    "NKW--A73mzli",
    "uBBA36fDTCfZ",
    "O8nlNNE4TCfj"
   ],
   "name": "EDA_Token_CoocMat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
