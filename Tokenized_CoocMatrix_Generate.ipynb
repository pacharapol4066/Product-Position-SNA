{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoY8sy40TCb5"
   },
   "source": [
    "### IS - Brand position\n",
    "Finding Product position on Semantic Network (PPSN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28353,
     "status": "ok",
     "timestamp": 1604024868503,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "GkBEUBUqTGuf",
    "outputId": "cb22db45-820a-48fd-c11a-a0568439778f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1604024868819,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_5mrzpx3TH9K",
    "outputId": "129bb192-4ac2-4b03-bc89-7ee7a65d5032"
   },
   "source": [
    "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Master_PJ_DRMABS/Datasource"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity: 1 คือเหมือน 0 คือต่าง<br>\n",
    "dissimilarity 1 คือต่าง 0 คือเหมือน : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1604024879769,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cC0cBdCdTCb6"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import pymongo\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\types\\oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\_pytest\\mark\\structures.py:378: DeprecationWarning: The usage of `cmp` is deprecated and will be removed on or after 2021-06-01.  Please use `eq` and `order` instead.\n",
      "  @attr.s(cmp=False, hash=False)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1604024879770,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "1kqXURiiTCb-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1604028167896,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "weEcXSD8TCcI",
    "outputId": "1219680e-0d54-4649-a26e-535e112f0650"
   },
   "outputs": [],
   "source": [
    "from pythainlp.util import normalize\n",
    "from newnewthaicut import word_tokenize  # IOB Tagging tokenized\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.spell import correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "#from sklearn.metrics.pairwise import cosine_similarity\n",
    "#from sklearn.metrics import jaccard_score\n",
    "#from mlxtend.evaluate import lift_score\n",
    "#from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1604027698593,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "sna_e7nATCch"
   },
   "outputs": [],
   "source": [
    "# Files definition\n",
    "root_input_path = 'Datasource'\n",
    "root_output_path = 'output'\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(root_input_path+\"/comment_meiji.csv\")\n",
    "#comment_file.append(root_input_path+\"/comment_DDCF.csv\")\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(\"comment_meiji.csv\")\n",
    "#comment_file.append(\"comment_DDCF.csv\")\n",
    "\n",
    "comment_nlp_file = root_output_path+\"/comment_nlpToken.csv\"\n",
    "comment_cooc_freq_file = root_output_path+\"/comment_cooc_freq.xlsx\"\n",
    "comment_cooc_jacc_file = root_output_path+\"/comment_cooc_jacc.xlsx\"\n",
    "\n",
    "comment_robust_jaccard = root_output_path+\"/comment_robust_jaccard.xlsx\"\n",
    "comment_robust_lift = root_output_path+\"/comment_robust_lift.xlsx\"\n",
    "comment_robust_incur = root_output_path+\"/comment_robust_incur.xlsx\"\n",
    "comment_robust_cosine = root_output_path+\"/comment_robust_cosine.xlsx\"\n",
    "\n",
    "#comment_nlp_file = \"comment_nlpToken.csv\"\n",
    "#comment_cooc_nlp_file = \"comment_cooc.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"NIDA_PPSN_PRD\"]\n",
    "col_thread = mydb[\"NIDA_PPSN_THREAD\"]\n",
    "col_comment = mydb[\"NIDA_PPSN_COMMENT\"]\n",
    "col_scrape = mydb[\"NIDA_PPSN_SCRAPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlnotsqqTCcl"
   },
   "source": [
    "### 1.Clean data & NLP Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_corpus = col_scrape.find()\n",
    "df_Corpus = pd.DataFrame(cursor_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2677,
     "status": "ok",
     "timestamp": 1604027704431,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "VXYRZDubTCcm"
   },
   "outputs": [],
   "source": [
    "df_Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1604027718134,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "Xf0_nwz8TCdB",
    "outputId": "d39ed4de-8549-4488-d8c5-04e62e8a4dfd"
   },
   "outputs": [],
   "source": [
    "print('All comment:',df_Corpus.shape[0])\n",
    "print('All URLs ก่อนตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1604027719151,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "vRH0T2gLTCdE",
    "outputId": "0722d375-5945-44d8-bc71-f39dcc58a0e9"
   },
   "outputs": [],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1604027721340,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "LXg1m0eoTCdK",
    "outputId": "567e2a04-8322-4104-9f68-6d509815fd24"
   },
   "outputs": [],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Corpus.drop('_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1604027723160,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_O0BSe9ETCdO"
   },
   "outputs": [],
   "source": [
    "seqNum = list(range(1,df_Corpus.shape[0]+1))\n",
    "df_Corpus.insert(0,'commentId',seqNum)\n",
    "df_Corpus.columns = ['commentId','URLs','headline','text','article_date','Retrived_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1604027724691,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "w-muagoxTCdR",
    "outputId": "a8afe33d-943b-422e-838d-ba8514e9497d"
   },
   "outputs": [],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1604027727940,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "jZFN_aTsTCdU"
   },
   "outputs": [],
   "source": [
    "# Drop NA & banned comments\n",
    "df_Corpus = df_Corpus.dropna()\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('ความคิดเห็นนี้ถูกลบ')!= 0]\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('แก้ไขข้อความเมื่อ')!= 0]\n",
    "df_Corpus = df_Corpus.set_index('commentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1604027727941,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "ki-qD4YMTCdX",
    "outputId": "3102d8b3-3251-463e-f3e2-50a119fe787b"
   },
   "outputs": [],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1604027730567,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "c0J7GD3ATCda",
    "outputId": "f8748ddd-9aab-40d2-ee9e-38ba742906b7"
   },
   "outputs": [],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027730892,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "PKvz8tQpTCdd",
    "outputId": "62e2d990-0240-4a01-cef5-515147c6750c"
   },
   "outputs": [],
   "source": [
    "df_Corpus.insert(4,'token_text',None)\n",
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็ควันเวลา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('กระทู้เก่าที่สุด :',min(df_Corpus.article_date))\n",
    "print('กระทู้ใหม่ที่สุด :',max(df_Corpus.article_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เก็บเฉพาะหัวกระทู้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thread = df_Corpus.copy()\n",
    "df_thread = df_thread[['URLs','headline']]\n",
    "df_thread.drop_duplicates(subset =\"URLs\", keep = 'first', inplace = True)\n",
    "df_thread.insert(2,'token_headline',None)\n",
    "df_thread.insert(3,'mention_product',None)\n",
    "df_thread.insert(4,'mention_brand',None)\n",
    "df_thread.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpwX95XlTCdl"
   },
   "source": [
    "## 2.ตัดคำและเก็บลง MongoDB (ใช้ insight จาก jupyter งานก่อน)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U__d4agTCdl"
   },
   "source": [
    "https://www.thainlp.org/pythainlp/tutorials/notebooks/pythainlp-get-started.html#Thai-Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1604028299778,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cr_O7hE5htx2"
   },
   "outputs": [],
   "source": [
    "def normThai(w):\n",
    "    returnList = []\n",
    "    for i in w:\n",
    "        returnList.append(normalize(i))\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1604030224171,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "rAcuuoYiTCdu"
   },
   "outputs": [],
   "source": [
    "garbage_char = ['ไม่','','.','..','...','มกราคม', 'กุมภาพันธ์','มีนาคม', 'เมษายน','พฤษภาคม', 'มิถุนายน', 'กรกฎาคม','สิงหาคม','กันยายน'\n",
    "                ,'ตุลาคม','พฤศจิกายน', 'ธันวาคม','วันจันทร์','วันอังคาร','วันพุธ','วันพฤหัสบดี','วันศุกร์','วันเสาร์','วันอาทิตย์','กก'\n",
    "                ,'เมนู','Menu','Net','net','สาขา','บาท','ราคา','ฯ','ๆ','กก','อันนี้','😆', '🤣','😢','😏','😂','😿','🥺','ววว','xx','อิอิ','แย้ววว']\n",
    "naka = ['นะคะ','นะค่ะ','น่ะค่ะ','น่ะคะ','ฮ้าฟ','ค้าบ','คร้าบ']\n",
    "\n",
    "stopwords = set(thai_stopwords()).union(set(naka))\n",
    "stopwords.remove('ไม่')\n",
    "stopwords.remove('สูง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1604027849933,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "mAwAGA5ITCdx",
    "outputId": "d95e59bb-b35e-4592-f16e-0915a7975f84"
   },
   "outputs": [],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_custom(x):\n",
    "    custom_punc = '!.—-\"$#&฿/&\\'()*+,:;<=>?@[\\\\]^_`{|}~'\n",
    "    x = x.translate(str.maketrans('', '', custom_punc)).strip()\n",
    "    x = x.translate(str.maketrans({\"\\t\":None,\"\\n\": None})).strip()\n",
    "    x = x.lower()\n",
    "    wtkn = word_tokenize(x)\n",
    "    wtkn = [j for j in wtkn if j not in stopwords]\n",
    "    wtkn = [w for w in wtkn if len(w) >= 2]\n",
    "    wtkn = [y for y in wtkn if y not in garbage_char]\n",
    "    wtkn = [s for s in wtkn if not s.isdigit()]\n",
    "    wtkn = normThai(wtkn)\n",
    "    return wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_Thread(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"URLs\": lx,\n",
    "            \"headline\": df.headline[c],\n",
    "            \"token_headline\":df.token_headline[c],\n",
    "            \"t_mention_dairy\":df.t_mention_dairy[c],\n",
    "            \"t_mention_product\": df.t_mention_product[c],\n",
    "            \"t_mention_brand\": df.t_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_comments(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"commentId\":int(df.commentId[c]),\n",
    "            \"URLs\": lx,\n",
    "            \"headline\":df.headline[c],\n",
    "            \"text\": df.text[c],\n",
    "            \"Retrived_date\": df.Retrived_date[c],\n",
    "            \"token_text\":df.token_text[c],\n",
    "            \"cmt_mention_dairy\": df.cmt_mention_dairy[c],\n",
    "            \"cmt_mention_product\": df.cmt_mention_product[c],\n",
    "            \"cmt_mention_brand\": df.cmt_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_keyword(wtkn):  \n",
    "    ret_wtkn = wtkn\n",
    "    for i,each in enumerate(ret_wtkn,0):\n",
    "        if each in ['ดัชมิลล์','ดัชมิล','ดัชมิว','dutchmill','dutch mill','dutch milk','dutchmilk','duchmill','duchie-bio','ดัชชี่']:\n",
    "            ret_wtkn[i] = 'ดัชมิลล์'\n",
    "        elif each  in ['เมจิ','ซีพีเมจิ','ซีพี เมจิ','cp meiji','meiji','meji','miji','cpmeijicom','cpmeijitensai','cpmeijithailand']:\n",
    "            ret_wtkn[i] = 'เมจิ'\n",
    "        elif each  in ['โฟร์โมสต์','โฟร์โมสท์','โฟร์โมส','โฟโมสต์','โฟโมต','โฟรโมสต์','โฟรโมสต','foremost']:\n",
    "            ret_wtkn[i] = 'โฟร์โมสต์'\n",
    "        elif each  in ['แดรี่โฮม','dairy home','dairyhome','เดรี่โฮม','เดลี่โฮม']:\n",
    "            ret_wtkn[i] = 'แดรี่โฮม'\n",
    "        elif each  in ['โชคชัย','อืมม มิลค์','umm milk','นมฟาร์มโชคชัย']:\n",
    "            ret_wtkn[i] = 'โชคชัย'\n",
    "        elif each  in ['เอ็มมิลค์','mmilk','เอ็มมิ้ลค์','เอ็มมิลล์','m milk']:\n",
    "            ret_wtkn[i] = 'เอ็มมิลค์'\n",
    "        elif each  in ['ไทยเดนมาร์ค','ไทยเดนมาร์ก','ไทย เดนมาร์ค','ไทย เดนมาร์ก','วัวแดง']:\n",
    "            ret_wtkn[i] = 'ไทยเดนมาร์ค'\n",
    "        elif each  in ['สตอเบอร์รี่','สตรอว์เบอร์รี','รสสตรอเบอรี่','สตอเบอรี่','สตรอเบอรี่','สตรอวเบอรี่','สตรอเบอร์รี่']:\n",
    "            ret_wtkn[i] = 'สตรอว์เบอร์รี'\n",
    "        elif each  in ['ชอคโกแล็ต','ช็อกโกแลต','ช็อคโกแลต','ช๊อกโกแลต','ช็อคโกแล็ต','ช็อกโกเลต','ช็อค']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลต'\n",
    "        elif each  in ['มิ้นท์ชอค','มิ้นต์ช้อก','ช็อคโกแลตมินต์','มินต์ช็อคโกแลต']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลตมินต์'\n",
    "        elif each  in ['ไขมันต่ำ','low fat','พร่องมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมันต่ำ'\n",
    "        elif each  in ['ไขมัน 0','ไขมัน 0%','0 fat','0% fat','ขาดมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมัน 0%'\n",
    "        elif each  in ['high protein','hi protein','ไฮโปรตีน']:\n",
    "            ret_wtkn[i] = 'ไฮโปรตีน'\n",
    "        elif each  in ['free lactose','lactose free','ฟรีแลคโตส','แลคโตสฟรี']:\n",
    "            ret_wtkn[i] = 'นมฟรีแลคโตส'\n",
    "        elif each  in ['พาส','พาสเจอไรซ์','พาสเจอร์ไรซ์','พาสเจอร์ไรส์','พาซเจอไรซ์','พาสเจอร์ไลท์']:\n",
    "            ret_wtkn[i] = 'พาสเจอร์ไรส์'\n",
    "        elif each  in ['เมจิโกลด์ แม็กซ์','เมจิโกลด์','เมจิ โกลด์','เมจิโกล์ดแม็กซ์','gold','gold max']:\n",
    "            ret_wtkn[i] = 'เมจิโกลด์'\n",
    "        elif each  in ['ฝาน้ำเงิน','รสจืด']:\n",
    "            ret_wtkn[i] = 'รสจืด'\n",
    "        elif each  in ['ท็อปส์','ทอปส์','ท้อปส์','ท๊อปส์','tops']:\n",
    "            ret_wtkn[i] = 'tops'\n",
    "        elif each  in ['แมคโคร','แม็คโคร','makro']:\n",
    "            ret_wtkn[i] = 'makro'\n",
    "        elif each  in ['โลตัส','lotus']:\n",
    "            ret_wtkn[i] = 'lotus'\n",
    "        elif each  in ['บิ๊กซี','bigc','big c']:\n",
    "            ret_wtkn[i] = 'bigc'\n",
    "        elif each in ['ดาร์คช็อกโกแลต','ดาร์กช็อก','ดาร์กช็อกโกแลต']:\n",
    "            ret_wtkn[i] = 'ดาร์คช็อกโกแลต'\n",
    "        elif each in ['bedtime','bed time','เบดไทม์']:\n",
    "            ret_wtkn[i] = 'เบดไทม์'\n",
    "        elif each in ['เมจิ บัลแกเรีย','เมจิบัลแกเรีย','บัลแกเรีย','bulgaria']:\n",
    "            ret_wtkn[i] = 'เมจิบัลแกเรีย'\n",
    "        elif each in ['โยเกิร์ต','โยเกิต','โยเกิรต','โยเกิร์ตพร้อมดื่ม']:\n",
    "            ret_wtkn[i] = 'โยเกิร์ต'\n",
    "        elif each in ['7 Eleven','7 eleven','เซเว่น อีเลฟเว่น','เซเว่นอีเลฟเว่น','เซเว่น','เซเวน','7 11']:\n",
    "            ret_wtkn[i] = '7-Eleven'\n",
    "        elif each in ['บีทาเก้น','บีทาเกน']:\n",
    "            ret_wtkn[i] = 'บีทาเก้น'\n",
    "        elif each in ['โปร','โปรโมชั่น']:\n",
    "            ret_wtkn[i] = 'โปรโมชั่น'\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_brands_product(x,catType):\n",
    "    ret_wtkn = []\n",
    "    brands = ['ดัชมิลล์','เมจิ','โฟร์โมสต์','โชคชัย','แดรี่โฮม','เอ็มมิลค์','แมคโนเลีย','ไทยเดนมาร์ค','หนองโพ','คาเนชั่น','บีทาเก้น','จิตรลดา']\n",
    "    products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ','วิปครีม']\n",
    "    milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์','nondairy','non dairy']\n",
    "    \n",
    "    choiceList = []\n",
    "    if catType == 'b':\n",
    "        choiceList = brands\n",
    "    elif catType == 'm':\n",
    "        choiceList = milk_kind\n",
    "    elif catType == 'p':\n",
    "        choiceList = products\n",
    "        \n",
    "    for i,each in enumerate(x,0):\n",
    "        if each in choiceList:\n",
    "            ret_wtkn.append(each)\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy ชุดคำจาก File มา Process ก่อนลง MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment = df_Corpus.reset_index().copy()\n",
    "df_process_thread = df_thread.reset_index().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Tokenize comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['text'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['token_text'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['cmt_mention_dairy'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_comment['cmt_mention_brand'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_comment['cmt_mention_product'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Insert comments to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hunm5MT7TCd2",
    "outputId": "15710375-8df1-46f0-85a2-04c66e1de5d9"
   },
   "outputs": [],
   "source": [
    "col_comment.delete_many({})\n",
    "process_data = create_InsertMany_comments(df_process_comment)\n",
    "col_comment.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Tokenize head of thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['headline'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['token_headline'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6) Mark domain/entity mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['t_mention_dairy'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_thread['t_mention_brand'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_thread['t_mention_product'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7) Insert thread to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_thread.delete_many({})\n",
    "process_data = create_InsertMany_Thread(df_process_thread)\n",
    "col_thread.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027734766,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "J30GMUlJTCdh"
   },
   "outputs": [],
   "source": [
    "del df_thread,df_Corpus,df_process_comment,df_process_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Process หัวกระทู้ เพื่อทำ Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เคสหลุดเงื่อนไข แต่ต้องใช้\n",
    "1. https://pantip.com/topic/30833944\n",
    "2. https://pantip.com/topic/30105850\n",
    "4. https://pantip.com/topic/35439062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]\n",
    "df_urls_milk['t_mention_dairy'] = df_urls_milk['t_mention_dairy'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_brand'] = df_urls_milk['t_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_product'] = df_urls_milk['t_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_urls_milk = df_cmt_process[(df_cmt_process.cmt_mention_dairy.str.len() != 0) | (df_cmt_process.URLs.isin(execption_urls))]\n",
    "df_c_urls_milk['cmt_mention_dairy'] = df_c_urls_milk['cmt_mention_dairy'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_brand'] = df_c_urls_milk['cmt_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_product'] = df_c_urls_milk['cmt_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('จำนวนกระทู้ที่มีการพูดถึงนม:',df_urls_milk.shape[0])\n",
    "print('%จำนวนกระทู้ที่มีการพูดถึงนมเทียบทั้งหมด:',round((df_urls_milk.shape[0]/df_thr_process.shape[0])*100,2))\n",
    "print('จำนวน comment ที่มีการพูดถึงนม:',df_c_urls_milk.shape[0])\n",
    "print('%จำนวน comment ที่มีการพูดถึงนมเทียบทั้งหมด:',round((df_c_urls_milk.shape[0]/df_cmt_process.shape[0])*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* จำนวน comment ที่มีการพูดถึงนม ไม่ได้ impute มาจากหัวกระทู้ ถ้า impute จะมีเยอะกว่านี้อีก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA#2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุ domain ของนม บนหัวกระทู้"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_dairy']]\n",
    "df_view.column = ['URLs','t_mention_dairy']\n",
    "df_view_count = df_view.groupby('t_mention_dairy').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]\n",
    "\n",
    "# set() ในเคสนี้คือกระทู้ที่พูดถึงนมแต่ไม่มี domain ในหัวกระทู้ ต้องดึง custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ Product บนหัวกระทู้ (Headline)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_product']]\n",
    "df_view.column = ['URLs','t_mention_product']\n",
    "df_view_count = df_view.groupby('t_mention_product').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]\n",
    "\n",
    "# set() หมายถึง กระทู้นั้นอยู่ใน domain นม แต่ไม่ระบุ product flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ Product ใน comment ทั้งใต้หัวกระทู้ ที่มี domain ของนม และส่วน comment<br>\n",
    "อย่างไรก็ตามยังไม่ได้ impute domain จากหัวกระทู้เข้าไป"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_c_urls_milk[['URLs','cmt_mention_product']]\n",
    "df_view.column = ['URLs','cmt_mention_product']\n",
    "df_view_count = df_view.groupby('cmt_mention_product').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ brand ใน comment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_c_urls_milk[['URLs','cmt_mention_brand']]\n",
    "df_view.column = ['URLs','cmt_mention_brand']\n",
    "df_view_count = df_view.groupby('cmt_mention_brand').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.สรุป Term & reduced_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrributes = ['เก็บรักษา','เข้มข้น','เค้ก','เจมส์','เจมส์ จิ','เจมส์จิ','เจลลาติน','เจือจาง','เชื้อ','เชื้อโรค','เชื้อจุลินทรีย์','เชื้อรา','เด็ก','เด็กเล็ก','เด็กแรกเกิด'\n",
    "               ,'เด็กโต','เด็กชาย','เด็กทารก','เด็กน้อย','เด็กวัยรุ่น','เด็กอ่อน','เติบโต','เตี้ย','เนย','เนยแข็ง','เนยสด','เนสเล่','เนสกาแฟ','เนสท์เล่','เน่า','เน่าเสีย'\n",
    "               ,'เบาหวาน','เมจิ','เมจิโกลด์','เมจิบัลแกเรีย','เมล่อน','เย็น','เล่นเวท','เล่นกล้าม','เลี้ยง','เลี้ยงเด็ก','เลี้ยงดู','เลี้ยงลูก','เลี้ยงสัตว์','เวย์','เวย์โปรตีน'\n",
    "               ,'เหม็นเขียว','เหม็นเปรี้ยว','เหม็นคาว','เหม็นบูด','เอนไซม์','เอ็นไซม์','เอนฟาโกร','เอ็มมิลค์','เอสเปรสโซ','เอสเปรสโซ่','เอสเพรสโซ','เอสเพรสโซ่'\n",
    "               ,'แข็งแรง','แคนตาลูป','แคลเซียม','แคลเซี่ยม','แคลอรี','แคลอรี่','แจก','แช่เย็น','แชร์','แดรี่โฮม','แตงโม','แถม','แบคทีเรีย','แบบสอบถาม','แพ็ก'\n",
    "               ,'แพกเกจ','แพ็กเกจ','แพ็ค','แพ๊ค','แพคเกจ','แพ็คเกจ','แพคคู่','แพ้ท้อง','แพ้นม','แพ้นมวัว','แม่','แมกนีเซียม','แมคโนเลีย','แม่ลูกอ่อน','แร่ธาตุ'\n",
    "               ,'แลกโตส','แล็กโต๊ส','แลคโตส','แลคติก','แอโรบิค','แอนตี้ไบโอติก','แอปเปิล','แอปเปิ้ล','โกโก้','โฆษณา','โชคชัย','โซเดียม','โด้บ','โด๊บ','โด้ป'\n",
    "               ,'โด๊ป','โด้ปนม','โปรโมชั่น','โปรตีน','โพแทสเซียม','โฟเลต','โฟร์โมสต์','โฟลิค','โภชนาการ','โยเกิร์ต','โยเกิร์ท','โรคเบาหวาน','โรคกระเพาะ'\n",
    "               ,'โรคขาดอาหาร','โรคท้องร่วง','โรคประจำตัว','โรคภัยไข้เจ็บ','โรคภูมิแพ้','โรคมะเร็ง','โรคหัวใจ','โรงเรียน','โรงงาน','โอวัลติน','ให้นม','ให้อาหาร'\n",
    "               ,'ไขมัน','ไขมัน 0%','ไขมันต่ำ','ไทยเดนมาร์ค','ไอติม','ไอศกรีม','ไอศครีม','ไฮโปรตีน','กรดไขมัน','กรดอะมิโน','กระดูกพรุน','กระบวนการผลิต'\n",
    "               ,'กระป๋อง','กล้วย','กล้วหอม','กล่อง','กลิ่น','กลิ่นคาว','กลิ่นหอม','กลูโคส','กาเฟอีน','กาแฟ','กาแฟเย็น','กาแฟร้อน','กาแฟสด','การบรรจุ'\n",
    "               ,'การผลิต','การย่อยอาหาร','การลดน้ำหนัก','การลดราคา','การออกกำลังกาย','ข้น','ขนม','ขนมเค้ก','ขนมปัง','ขนมปังแผ่น','ขนมหวาน','ขนส่ง'\n",
    "               ,'ขวดโหล','ขวดนม','ขวบ','ขาดตลาด','ขายไม่ดี','ขายไม่ออก','ขายปลีก','ขายส่ง','ข้าว','ข้าวโพด','ข้าวโอ๊ต','ข้าวกล้อง','คนรุ่นใหม่','คนวัยหนุ่มสาว'\n",
    "               ,'คนสูงอายุ','ครรภ์','คลอเรสเตอรอล','คลอเลสเตอรอล','คลอโรฟิล','คลอดลูก','ความคุ้มค่า','ความมัน','ความร้อน','คอเลสเตอรอล','คาเฟอีน','ค่าขนส่ง'\n",
    "               ,'คาปูชิโน','คาปูชิน่','คาร์โบไฮเดรต','คาราเมล','คาว','คุณแม่','คุณแม่มือใหม่','คุณค่า','คุณประโยชน์','คุณภาพ','คุณภาพดี','ฆ่าเชื้อ','จิตรลดา','จืด'\n",
    "               ,'จุลินทรีย์','ฉลาก','ชง','ชงนม','ช็อกโกแลต','ช่องแช่แข็ง','ชอบ','ชา','ชาเขียว','ชาเขียวมัจฉะ','ชาเย็น','ชิม','ซื้อ','ซุปเปอร์มาร์เกต','ซุปเปอร์มาร์เก็ต'\n",
    "               ,'ดัชมิลล์','ดาร์คช็อกโกแลต','ต้ม','ตลาด','ตัวแทนจำหน่าย','ตู้เย็น','ท้องเสีย','ท้องตลาด','ท้องร่วง','ท้องว่าง','ท้องอืด','ทุเรียน','ธรรมชาติ','ธัญญาหาร'\n",
    "               ,'ธัญพืช','ธาตุเหล็ก','นม','นมเปรี้ยว','นมกล่อง','นมข้น','นมข้นหวาน','นมควาย','นมถั่วเหลือง','นมผง','นมฟรีแลคโตส','นมยูเอชที','นมวัว','นมสด'\n",
    "               ,'นมฮอกไกโด','นอน','น้ำ','นำเข้า','น้ำเชื่อม','น้ำเต้าหู้','น้ำตาล','น้ำตาลเทียม','น้ำตาลทราย','น้ำตาลทรายแดง','น้ำนม','น้ำผึ้ง','น้ำหนัก','บรรจุขวด'\n",
    "               ,'บลูเบอร์รี่','บัลแกเรีย','บัลกาเรีย','บาริสตา','บาริสต้า','บีทาเก้น','บูด','ปริมาณ','ปลอดเชื้อ','ปวดท้อง','ปั่น','ผลไม้','ผสม','ผู้จัดจำหน่าย','ผู้ผลิต','ฝา'\n",
    "               ,'พกพา','พนักงานขายนม','พลังงาน','พาราไดซ์','พารากอน','พาสเจอร์ไรส์','ฟรอยด์','ฟอง','ฟาร์ม','มอลต์','ยอดขาย','รสกลมกล่อม','รกล้วย','รสกาแฟ'\n",
    "               ,'รสจืด','รสชาติ','รสหวาน','ราคาแพง','ราคาสูง','ร่างกาย','ร้านกาแฟ','รีวิว','ลดความอ้วน','ลดน้ำหนัก','ลดราคา','ลูก','ลูกชาย','ลูกสาว','วันหมดอายุ'\n",
    "               ,'วานิลลา','วานิลล่า','วานิลา','วิ่ง','วิตามิน','สตรอเบอร์รี่','สตรอเบอรี','สตรอว์เบอร์รี','สต็อก','สต๊อก','สต็อค','สตาร์บัค','สยามพารากอน','สยามสแควร์'\n",
    "               ,'สละ','ส่วนผสม','สะอาด','สัปปะรด','สารอาหาร','สำนักงานคณะกรรมการอาหารและยา','สิ่งเจือปน','สูง','สูงวัย','สูตร','หญ้า','หนองโพ','หมอ','หลอด'\n",
    "               ,'หวาน','หอม','หางจระเข้','ห้างร้าน','อ้วน','ออกกำลังกาย','ออร์แกนิก','อะเมซอน','อาหาร','อาหารเสริม','อุณหภูมิ']\n",
    "\n",
    "stores = ['tops','makro','lotus','bigc','7-Eleven']\n",
    "\n",
    "#products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "#                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "#                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ']\n",
    "#milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "#                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์']\n",
    "\n",
    "#  EDA ใน Excel ได้ flavor 68 ตัว (ถ้าดึงยี่ห้ออื่นก็เพิ่มอีก)\n",
    "#avai_flavs = ['เมจิเมจิโกลด์','เมจิเมล่อน','เมจิไขมัน 0%','เมจิไขมันต่ำ','เมจิไฮโปรตีน','เมจิช็อกโกแลต','เมจิชาเขียวมัจฉะ','เมจิดาร์คช็อกโกแลต'\n",
    "# ,'เมจินมฟรีแลคโตส','เมจิบัลแกเรีย','เมจิมอลต์','เมจิรสกลมกล่อม','เมจิรสกล้วย','เมจิรกาแฟ','เมจิรสจืด','เมจิรสธรรมชาติ','เมจิรสหวาน'\n",
    "# ,'เมจิสตรอว์เบอร์รี','เมจิอัลมอนด์','เอ็มมิลค์นมฟรีแลคโตส','เอ็มมิลค์รสจืด','แดรี่โฮมgrass fed','แดรี่โฮมเบดไทม์','แดรี่โฮมช็อกโกแลต'\n",
    "# ,'แดรี่โฮมรสกล้วย','แดโฮมรสจืด','แดรี่โฮมรสหวาน','แดรี่โฮมสตรอว์เบอร์รี','แมคโนเลียไขมันต่ำ','แมคโนเลียช็อกโกแลต','แมคโนเลียรสจืด'\n",
    "# ,'โชคชัยไขมันต่ำ','โชคชัยช็อกโกแลต','โชคชัยรสกาแฟ','โชคชัยรสจืด','โชคชัยสตรอว์เบอร์รี','ฟร์โมสต์ไขมัน 0%','โฟร์โมสต์ไขมันต่ำ'\n",
    "# ,'โฟร์โมสต์คาราเมล','โฟร์โมสต์ช็อกโกแลต','โฟร์โมสต์รสกาแฟ','โฟร์โมสต์รสจืด','โฟร์โมสต์สตรอว์เบอร์รี','ไทยเดนมาร์คช็อกโกแลต'\n",
    "# ,'ไทยเดนมาร์ครสกาแฟ','ไทยเดนมาร์ครสจืด','ไทยเดนมาร์ครสหวาน','ไทยเดนมาร์คสตรอว์เบอร์รี','คาเนชั่นรสจืด','จิตรลดาช็อกโกแลต'\n",
    "# ,'จิตรลดารสจืด','จิตรลดารสหวาน','จิตรลดาสตรอว์เบอร์รี','ดัชมิลล์ไขมัน 0%','ดัชมิลล์ไขมันต่ำ','ดัชมิลล์ไฮโปรตีน','ดัชลล์อกกแลต'\n",
    "# ,'ดัชมิลล์มอลต์','ดัชมิลล์รสกาแฟ','ดัชมิลล์รสจืด','ดัชมิลล์สตรอว์เบอร์รี','หนองโพไขมัน 0%','หนองโพไขมันต่ำ','หนองโพช็อกโกแลต'\n",
    "# ,'หนองโพรสกาแฟ','หนองโพรสจืด','หนองโพรสหวาน','หนองโพสตรอว์เบอร์รี']\n",
    "\n",
    "reduceCol = attrributes + stores \n",
    "#reduceCol_all = attrributes + stores + milk_kind + products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_keyword(wtkn,redCol):\n",
    "    del_list = []\n",
    "    ret_wtkn = wtkn\n",
    "    for each in ret_wtkn:\n",
    "        if each not in redCol:\n",
    "            del_list.append(each)\n",
    "    ret_wtkn = [x for x in ret_wtkn if x not in del_list]\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def freq_brand(x):\n",
    "    #e = eval(x)\n",
    "    e = x\n",
    "    e.sort()\n",
    "    f = [(k,len(list(g))) for k, g in groupby(e)]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_flavor(x,y):\n",
    "    listflav = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            listflav.append(i+j)\n",
    "    return listflav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKW--A73mzli"
   },
   "source": [
    "### 5.สร้าง (Reduce) Bag of word ด้วย dictionary.doc2bow จัดลง dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คัด headline ที่พูดถึง domain นม\n",
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เมื่อ join กันแล้ว คอมเม้นทุกคอมเม้นจะอยู่ใน domain นมทั้งหมด\n",
    "df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['_id_x','_id_y','headline_y'],inplace=True)\n",
    "df_join_url.rename(columns={\"headline_x\":\"headline\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง QAP mathod case2,4\n",
    "df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol))\n",
    "\n",
    "# ทดลอง QAP mathod  case1,5\n",
    "#df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>t_mention_dairy</th>\n",
       "      <th>t_mention_product</th>\n",
       "      <th>t_mention_brand</th>\n",
       "      <th>commentId</th>\n",
       "      <th>text</th>\n",
       "      <th>Retrived_date</th>\n",
       "      <th>token_text</th>\n",
       "      <th>cmt_mention_dairy</th>\n",
       "      <th>cmt_mention_product</th>\n",
       "      <th>cmt_mention_brand</th>\n",
       "      <th>token_text_reduce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[รสหวาน]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>1</td>\n",
       "      <td>เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "      <td>[ปี, 7-Eleven, ยังมี, นม, เมจิ, รสหวาน, ขาย, อ...</td>\n",
       "      <td>[นม, นม]</td>\n",
       "      <td>[รสหวาน, รสหวาน]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>[7-Eleven, นม, เมจิ, รสหวาน, tops, นม, รสหวาน,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[รสหวาน]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>2</td>\n",
       "      <td>เบาหวานครับ แฮ่ๆ</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "      <td>[เบาหวาน, แฮ่]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[เบาหวาน]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                URLs                    headline  \\\n",
       "0  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "\n",
       "              token_headline t_mention_dairy t_mention_product  \\\n",
       "0  [นม, เมจิ, รสหวาน, หายาก]            [นม]          [รสหวาน]   \n",
       "1  [นม, เมจิ, รสหวาน, หายาก]            [นม]          [รสหวาน]   \n",
       "\n",
       "  t_mention_brand  commentId  \\\n",
       "0          [เมจิ]          1   \n",
       "1          [เมจิ]          2   \n",
       "\n",
       "                                                text           Retrived_date  \\\n",
       "0  เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา... 2020-11-29 00:13:26.571   \n",
       "1                                   เบาหวานครับ แฮ่ๆ 2020-11-29 00:13:26.571   \n",
       "\n",
       "                                          token_text cmt_mention_dairy  \\\n",
       "0  [ปี, 7-Eleven, ยังมี, นม, เมจิ, รสหวาน, ขาย, อ...          [นม, นม]   \n",
       "1                                     [เบาหวาน, แฮ่]                []   \n",
       "\n",
       "  cmt_mention_product cmt_mention_brand  \\\n",
       "0    [รสหวาน, รสหวาน]            [เมจิ]   \n",
       "1                  []                []   \n",
       "\n",
       "                                   token_text_reduce  \n",
       "0  [7-Eleven, นม, เมจิ, รสหวาน, tops, นม, รสหวาน,...  \n",
       "1                                          [เบาหวาน]  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_join_url.set_index('commentId',inplace=True)\n",
    "df_join_url.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text_reduce'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dictionary_tfidf = gensim.corpora.Dictionary(df_join_url['token_text_reduce_tfidf'])\n",
    "gensim_corpus = [dictionary_tfidf.doc2bow(text, allow_update=True) for text in df_join_url['token_text_reduce_tfidf']]\n",
    "tfidf_model = TfidfModel(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['reduce_bow'] = df_join_url[\"token_text_reduce\"].map(dictionary.doc2bow)\n",
    "df_join_url['reduce_bow_txt'] = df_join_url[\"reduce_bow\"].apply(lambda x:[(dictionary[id_], frequence) for id_, frequence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['Retrived_date','reduce_bow'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.insert(3,'mention_domain',value=None)\n",
    "df_join_url.insert(4,'mention_product',value=None)\n",
    "df_join_url.insert(5,'mention_brand',value=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>mention_domain</th>\n",
       "      <th>mention_product</th>\n",
       "      <th>mention_brand</th>\n",
       "      <th>t_mention_dairy</th>\n",
       "      <th>t_mention_product</th>\n",
       "      <th>t_mention_brand</th>\n",
       "      <th>commentId</th>\n",
       "      <th>text</th>\n",
       "      <th>token_text</th>\n",
       "      <th>cmt_mention_dairy</th>\n",
       "      <th>cmt_mention_product</th>\n",
       "      <th>cmt_mention_brand</th>\n",
       "      <th>token_text_reduce</th>\n",
       "      <th>reduce_bow_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8427</th>\n",
       "      <td>https://pantip.com/topic/30020409</td>\n",
       "      <td>ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...</td>\n",
       "      <td>[ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[ดื่มนม, uht]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>63573</td>\n",
       "      <td>มาแอบดูข้อมูลเพราะเดี๋ยวจะลองให้ญาญี๋กินนมUHTบ...</td>\n",
       "      <td>[แอบดู, ข้อมูล, เดี๋ยว, ลอง, ญาญี๋, กินนม, uht...</td>\n",
       "      <td>[กินนม, uht]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8428</th>\n",
       "      <td>https://pantip.com/topic/30020409</td>\n",
       "      <td>ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...</td>\n",
       "      <td>[ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[ดื่มนม, uht]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>63574</td>\n",
       "      <td>อร๊ายยยย ฝึกญาญี๋ได้แล้วมาบอกด้วยน้าาา เนฟวี่ไ...</td>\n",
       "      <td>[อร๊ายยยย, ฝึก, ญาญี๋, น้า, า, เนฟวี่, กล่อง, ...</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[กล่อง, นม, แม่]</td>\n",
       "      <td>[(นม, 1), (กล่อง, 1), (แม่, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8429</th>\n",
       "      <td>https://pantip.com/topic/30020409</td>\n",
       "      <td>ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...</td>\n",
       "      <td>[ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[ดื่มนม, uht]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>63575</td>\n",
       "      <td>แนะนำเพิ่มเติม นอกจากลองเปลี่ยนยี่ห้อเพื่อหายี...</td>\n",
       "      <td>[แนะนำ, ลอง, ยี่ห้อ, หา, ยี่ห้อ, เค้า, ถูกใจ, ...</td>\n",
       "      <td>[นมกล่อง]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ลูก, นมกล่อง, เด็ก, ชอบ]</td>\n",
       "      <td>[(ชอบ, 1), (เด็ก, 1), (ลูก, 1), (นมกล่อง, 1)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8430</th>\n",
       "      <td>https://pantip.com/topic/30020409</td>\n",
       "      <td>ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...</td>\n",
       "      <td>[ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[ดื่มนม, uht]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>63576</td>\n",
       "      <td>อ่ะ น่าสน เห็นด้วยค่ะ ขอบคุณมากนะคะ</td>\n",
       "      <td>[อ่ะ, น่าสน, เห็นด้วย, ขอบคุณ]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8431</th>\n",
       "      <td>https://pantip.com/topic/30020409</td>\n",
       "      <td>ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...</td>\n",
       "      <td>[ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[ดื่มนม, uht]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>63577</td>\n",
       "      <td>ของเราให้กินนมชงของดูเมกถ้าชงอ่ะกินแต่ซื้อแบบก...</td>\n",
       "      <td>[กินนม, ชง, ดู, เม, ชง, อ่ะ, กิน, ซื้อ, กล่อง,...</td>\n",
       "      <td>[กินนม, นม]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ชง, ชง, ซื้อ, กล่อง, ผสม, นม, ชง, ขวบ]</td>\n",
       "      <td>[(นม, 1), (ซื้อ, 1), (ชง, 3), (กล่อง, 1), (ผสม...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   URLs  \\\n",
       "8427  https://pantip.com/topic/30020409   \n",
       "8428  https://pantip.com/topic/30020409   \n",
       "8429  https://pantip.com/topic/30020409   \n",
       "8430  https://pantip.com/topic/30020409   \n",
       "8431  https://pantip.com/topic/30020409   \n",
       "\n",
       "                                               headline  \\\n",
       "8427  ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...   \n",
       "8428  ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...   \n",
       "8429  ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...   \n",
       "8430  ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...   \n",
       "8431  ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...   \n",
       "\n",
       "                                         token_headline mention_domain  \\\n",
       "8427  [ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...           None   \n",
       "8428  [ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...           None   \n",
       "8429  [ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...           None   \n",
       "8430  [ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...           None   \n",
       "8431  [ฝึกสอน, ลูก, ดื่มนม, uht, กล่อง, สำเร็จ, แชร์...           None   \n",
       "\n",
       "     mention_product mention_brand t_mention_dairy t_mention_product  \\\n",
       "8427            None          None   [ดื่มนม, uht]                []   \n",
       "8428            None          None   [ดื่มนม, uht]                []   \n",
       "8429            None          None   [ดื่มนม, uht]                []   \n",
       "8430            None          None   [ดื่มนม, uht]                []   \n",
       "8431            None          None   [ดื่มนม, uht]                []   \n",
       "\n",
       "     t_mention_brand  commentId  \\\n",
       "8427              []      63573   \n",
       "8428              []      63574   \n",
       "8429              []      63575   \n",
       "8430              []      63576   \n",
       "8431              []      63577   \n",
       "\n",
       "                                                   text  \\\n",
       "8427  มาแอบดูข้อมูลเพราะเดี๋ยวจะลองให้ญาญี๋กินนมUHTบ...   \n",
       "8428  อร๊ายยยย ฝึกญาญี๋ได้แล้วมาบอกด้วยน้าาา เนฟวี่ไ...   \n",
       "8429  แนะนำเพิ่มเติม นอกจากลองเปลี่ยนยี่ห้อเพื่อหายี...   \n",
       "8430                อ่ะ น่าสน เห็นด้วยค่ะ ขอบคุณมากนะคะ   \n",
       "8431  ของเราให้กินนมชงของดูเมกถ้าชงอ่ะกินแต่ซื้อแบบก...   \n",
       "\n",
       "                                             token_text cmt_mention_dairy  \\\n",
       "8427  [แอบดู, ข้อมูล, เดี๋ยว, ลอง, ญาญี๋, กินนม, uht...      [กินนม, uht]   \n",
       "8428  [อร๊ายยยย, ฝึก, ญาญี๋, น้า, า, เนฟวี่, กล่อง, ...              [นม]   \n",
       "8429  [แนะนำ, ลอง, ยี่ห้อ, หา, ยี่ห้อ, เค้า, ถูกใจ, ...         [นมกล่อง]   \n",
       "8430                     [อ่ะ, น่าสน, เห็นด้วย, ขอบคุณ]                []   \n",
       "8431  [กินนม, ชง, ดู, เม, ชง, อ่ะ, กิน, ซื้อ, กล่อง,...       [กินนม, นม]   \n",
       "\n",
       "     cmt_mention_product cmt_mention_brand  \\\n",
       "8427                  []                []   \n",
       "8428                  []                []   \n",
       "8429                  []                []   \n",
       "8430                  []                []   \n",
       "8431                  []                []   \n",
       "\n",
       "                            token_text_reduce  \\\n",
       "8427                                       []   \n",
       "8428                         [กล่อง, นม, แม่]   \n",
       "8429                [ลูก, นมกล่อง, เด็ก, ชอบ]   \n",
       "8430                                       []   \n",
       "8431  [ชง, ชง, ซื้อ, กล่อง, ผสม, นม, ชง, ขวบ]   \n",
       "\n",
       "                                         reduce_bow_txt  \n",
       "8427                                                 []  \n",
       "8428                    [(นม, 1), (กล่อง, 1), (แม่, 1)]  \n",
       "8429      [(ชอบ, 1), (เด็ก, 1), (ลูก, 1), (นมกล่อง, 1)]  \n",
       "8430                                                 []  \n",
       "8431  [(นม, 1), (ซื้อ, 1), (ชง, 3), (กล่อง, 1), (ผสม...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_join_url.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute brand & product เข้า comment และสรุปก่อนเข้า BoW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Impute จากหัวกระทู้\n",
    "\n",
    "# 1.headline มี comment มี เอา comment\n",
    "# 2.headline มี comment ไม่มี เอา headline\n",
    "# 3.headline ไม่มี comment มี เอา comment\n",
    "# 4.ไม่มีทั้งคู่ ปล่อยไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.t_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) == 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_domain'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.t_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) == 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_brand'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.t_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) == 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_product'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['t_mention_dairy','t_mention_product','t_mention_brand'\n",
    "                          ,'cmt_mention_dairy','cmt_mention_product','cmt_mention_brand'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf_list = []\n",
    "for doc in tfidf_model[gensim_corpus]:\n",
    "    tfidf_list.append([(dictionary_tfidf[id], np.around(freq, decimals=4)) for id, freq in doc])\n",
    "df_join_url.insert(11,'reduce_tfidf',value=tfidf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat Brand + Product มาต่อกันเพื่อระบุตราและยี่ห้อ เพื่อลงระดับ flavor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_join_url['mention_domain_count'] = df_join_url['mention_domain'].apply(lambda x: 0 if x is None else len(x))\n",
    "df_join_url['mention_product_count'] = df_join_url['mention_product'].apply(lambda x: 0 if x is None else len(x))\n",
    "df_join_url['mention_brand_count'] = df_join_url['mention_brand'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor = df_join_url[(df_join_url['mention_brand_count']>0)&(df_join_url['mention_product_count']>0)]\n",
    "df_withOutFlavor = df_join_url[(df_join_url['mention_brand_count']<=0)|(df_join_url['mention_product_count']<=0)]\n",
    "df_withFlavor['concat_domain'] = df_withFlavor['mention_domain'].apply(lambda x: x if x is None else list(set(x)))\n",
    "df_withFlavor['concat_brand'] = df_withFlavor['mention_brand'].apply(lambda x: x if x is None else list(set(x)))\n",
    "df_withFlavor['concat_product'] = df_withFlavor['mention_product'].apply(lambda x: x if x is None else list(set(x)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor['mention_product'] = df_withFlavor.apply(lambda x: concat_flavor(x.concat_brand,x.concat_product), axis=1)\n",
    "df_withFlavor['mention_product'] = df_withFlavor['mention_product'] .apply(lambda x: x if x is None else reduced_keyword(x,avai_flavs))\n",
    "df_withFlavor['mention_product'] = df_withFlavor['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withFlavor['mention_brand'] = df_withFlavor['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withFlavor['mention_domain'] = df_withFlavor['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withOutFlavor['mention_product'] = df_withOutFlavor['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withOutFlavor['mention_brand'] = df_withOutFlavor['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withOutFlavor['mention_domain'] = df_withOutFlavor['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor.drop(columns=['mention_domain_count','mention_product_count','mention_brand_count'\n",
    "                          ,'concat_domain','concat_brand','concat_product'],inplace=True)\n",
    "df_withOutFlavor.drop(columns=['mention_domain_count','mention_product_count','mention_brand_count'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_final = pd.concat([df_withFlavor,df_withOutFlavor], axis=0, sort=False)\n",
    "df_final.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cooccurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment ออกเมื่อไม่ concat brand+flavor\n",
    "df_final = df_join_url.copy()\n",
    "df_final.set_index('commentId',inplace=True)\n",
    "df_final['mention_product'] = df_final['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_final['mention_brand'] = df_final['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_final['mention_domain'] = df_final['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brand_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_brand\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "#df_prd_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_product\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "df_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"reduce_bow_txt\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TF-IDF Matrix\n",
    "df_tfidf_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"reduce_tfidf\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)\n",
    "df_tfidf_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_brand_cooc.reset_index(inplace=True)\n",
    "#df_prd_cooc.reset_index(inplace=True)\n",
    "df_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง  QAP mathod case2,4: Brand vs Product vs Attribute (ไม่เอาแล้ว)\n",
    "#join_df = pd.merge(df_brand_cooc, df_prd_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "#join_df = pd.merge(join_df, df_cooc, on='commentId', how='inner')\n",
    "\n",
    "# ทดลอง  QAP mathod case3: Product vs Attribute (ไม่เอาแล้ว)\n",
    "#join_df = pd.merge(df_prd_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ทดลอง  QAP mathod case1,5: Brand vs Attribute กรณีแยก ยี่ห้อ และ ผลิตภัณฑ์ จาก reduce_bow_txt\n",
    "#join_df = pd.merge(df_brand_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ไม่ Join ทำในกรณีไม่แยก ยี่ห้อ และ ผลิตภัณฑ์ ออกจาก reduce_bow_txt\n",
    "join_df = df_cooc.copy()\n",
    "\n",
    "join_df.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7-Eleven</th>\n",
       "      <th>tops</th>\n",
       "      <th>ขายไม่ดี</th>\n",
       "      <th>นม</th>\n",
       "      <th>รสหวาน</th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>เบาหวาน</th>\n",
       "      <th>ซื้อ</th>\n",
       "      <th>กาแฟ</th>\n",
       "      <th>จืด</th>\n",
       "      <th>...</th>\n",
       "      <th>แมกนีเซียม</th>\n",
       "      <th>โรคท้องร่วง</th>\n",
       "      <th>สยามพารากอน</th>\n",
       "      <th>ห้างร้าน</th>\n",
       "      <th>โรคขาดอาหาร</th>\n",
       "      <th>ช่องแช่แข็ง</th>\n",
       "      <th>โยเกิร์ท</th>\n",
       "      <th>พารากอน</th>\n",
       "      <th>พาราไดซ์</th>\n",
       "      <th>โด๊บ</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           7-Eleven  tops  ขายไม่ดี   นม  รสหวาน  เมจิ  เบาหวาน  ซื้อ  กาแฟ  \\\n",
       "commentId                                                                     \n",
       "1               1.0   1.0       1.0  2.0     2.0   1.0      0.0   0.0   0.0   \n",
       "2               0.0   0.0       0.0  0.0     0.0   0.0      1.0   0.0   0.0   \n",
       "3               0.0   0.0       0.0  0.0     1.0   0.0      0.0   1.0   0.0   \n",
       "4               0.0   0.0       1.0  0.0     1.0   0.0      0.0   0.0   1.0   \n",
       "5               0.0   0.0       2.0  0.0     0.0   0.0      0.0   1.0   0.0   \n",
       "\n",
       "           จืด  ...  แมกนีเซียม  โรคท้องร่วง  สยามพารากอน  ห้างร้าน  \\\n",
       "commentId       ...                                                   \n",
       "1          0.0  ...         0.0          0.0          0.0       0.0   \n",
       "2          0.0  ...         0.0          0.0          0.0       0.0   \n",
       "3          0.0  ...         0.0          0.0          0.0       0.0   \n",
       "4          1.0  ...         0.0          0.0          0.0       0.0   \n",
       "5          0.0  ...         0.0          0.0          0.0       0.0   \n",
       "\n",
       "           โรคขาดอาหาร  ช่องแช่แข็ง  โยเกิร์ท  พารากอน  พาราไดซ์  โด๊บ  \n",
       "commentId                                                               \n",
       "1                  0.0          0.0       0.0      0.0       0.0   0.0  \n",
       "2                  0.0          0.0       0.0      0.0       0.0   0.0  \n",
       "3                  0.0          0.0       0.0      0.0       0.0   0.0  \n",
       "4                  0.0          0.0       0.0      0.0       0.0   0.0  \n",
       "5                  0.0          0.0       0.0      0.0       0.0   0.0  \n",
       "\n",
       "[5 rows x 338 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export ข้อมูล เพื่อนำไปสุ่มแถวทำ QAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.to_csv(root_output_path+\"/cooc_bow_all.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source for graph generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBBA36fDTCfZ"
   },
   "source": [
    "### 1.Create frequency co-occurrence matrix จาก Bag of word<br>\n",
    "* ใช้สำหรับทำ MDS และโยนเข้า R (ทำ normalized บน R) ในลักษณะ Term-Term Cross tabulation<br> \n",
    "(คนละอย่างกับ TF-IDF cooc matrix ที่เป็น Word-word ซึ่งต้องรัน bigram เป็นราย document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "LgE1okejTCfZ"
   },
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_Grpby(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    cooc = slice_df[(slice_df.A>0)&(slice_df.B>0)]\n",
    "    return cooc.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "1jhFte5eTCfd"
   },
   "outputs": [],
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        if i != j:\n",
    "            item_item_matrix.iloc[i,j] = cnt_Grpby(join_df,i,j)\n",
    "        else:\n",
    "            item_item_matrix.iloc[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "OhtvLfMXTCfg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7-Eleven</th>\n",
       "      <th>tops</th>\n",
       "      <th>ขายไม่ดี</th>\n",
       "      <th>นม</th>\n",
       "      <th>รสหวาน</th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>เบาหวาน</th>\n",
       "      <th>ซื้อ</th>\n",
       "      <th>กาแฟ</th>\n",
       "      <th>จืด</th>\n",
       "      <th>...</th>\n",
       "      <th>แมกนีเซียม</th>\n",
       "      <th>โรคท้องร่วง</th>\n",
       "      <th>สยามพารากอน</th>\n",
       "      <th>ห้างร้าน</th>\n",
       "      <th>โรคขาดอาหาร</th>\n",
       "      <th>ช่องแช่แข็ง</th>\n",
       "      <th>โยเกิร์ท</th>\n",
       "      <th>พารากอน</th>\n",
       "      <th>พาราไดซ์</th>\n",
       "      <th>โด๊บ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7-Eleven</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>5</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tops</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ขายไม่ดี</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>นม</th>\n",
       "      <td>63</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>398</td>\n",
       "      <td>14</td>\n",
       "      <td>367</td>\n",
       "      <td>145</td>\n",
       "      <td>265</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>รสหวาน</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          7-Eleven  tops  ขายไม่ดี  นม  รสหวาน  เมจิ  เบาหวาน  ซื้อ  กาแฟ  \\\n",
       "7-Eleven         0     3         1  63       5    31        1    51     4   \n",
       "tops             3     0         1   8       1     5        0     6     0   \n",
       "ขายไม่ดี         1     1         0   2       3     3        0     1     1   \n",
       "นม              63     8         2   0      64   398       14   367   145   \n",
       "รสหวาน           5     1         3  64       0    22        0    18     7   \n",
       "\n",
       "          จืด  ...  แมกนีเซียม  โรคท้องร่วง  สยามพารากอน  ห้างร้าน  \\\n",
       "7-Eleven   11  ...           0            0            0         0   \n",
       "tops        0  ...           0            0            0         0   \n",
       "ขายไม่ดี    1  ...           0            0            0         0   \n",
       "นม        265  ...           0            0            1         2   \n",
       "รสหวาน     24  ...           0            0            0         0   \n",
       "\n",
       "          โรคขาดอาหาร  ช่องแช่แข็ง  โยเกิร์ท  พารากอน  พาราไดซ์  โด๊บ  \n",
       "7-Eleven            0            0         0        0         0     0  \n",
       "tops                0            0         0        0         0     0  \n",
       "ขายไม่ดี            0            0         0        0         0     0  \n",
       "นม                  1            1         1        1         1     0  \n",
       "รสหวาน              0            0         0        0         0     0  \n",
       "\n",
       "[5 rows x 338 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "bsbsqduDTCfh"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_freq_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Create co-occurrence matrix with Jaccard Distance สำหรับสร้างกราฟ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)]\n",
    "    a_occur = slice_df[(slice_df.A>0)]\n",
    "    b_occur = slice_df[(slice_df.B>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        item_item_matrix.iloc[i,j] = jaccard_index(join_df,i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7-Eleven</th>\n",
       "      <th>tops</th>\n",
       "      <th>ขายไม่ดี</th>\n",
       "      <th>นม</th>\n",
       "      <th>รสหวาน</th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>เบาหวาน</th>\n",
       "      <th>ซื้อ</th>\n",
       "      <th>กาแฟ</th>\n",
       "      <th>จืด</th>\n",
       "      <th>...</th>\n",
       "      <th>แมกนีเซียม</th>\n",
       "      <th>โรคท้องร่วง</th>\n",
       "      <th>สยามพารากอน</th>\n",
       "      <th>ห้างร้าน</th>\n",
       "      <th>โรคขาดอาหาร</th>\n",
       "      <th>ช่องแช่แข็ง</th>\n",
       "      <th>โยเกิร์ท</th>\n",
       "      <th>พารากอน</th>\n",
       "      <th>พาราไดซ์</th>\n",
       "      <th>โด๊บ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7-Eleven</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017964</td>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.024101</td>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.035632</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.057175</td>\n",
       "      <td>0.010283</td>\n",
       "      <td>0.022088</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tops</th>\n",
       "      <td>0.017964</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.006527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ขายไม่ดี</th>\n",
       "      <td>0.006494</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001255</td>\n",
       "      <td>0.004049</td>\n",
       "      <td>0.002755</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>นม</th>\n",
       "      <td>0.024101</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>0.138194</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.124280</td>\n",
       "      <td>0.055238</td>\n",
       "      <td>0.101106</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>รสหวาน</th>\n",
       "      <td>0.017921</td>\n",
       "      <td>0.006536</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.024644</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.025492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019802</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.051173</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 338 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          7-Eleven      tops  ขายไม่ดี        นม    รสหวาน      เมจิ  \\\n",
       "7-Eleven  1.000000  0.017964  0.006494  0.024101  0.017921  0.035632   \n",
       "tops      0.017964  1.000000  0.041667  0.003151  0.006536  0.006527   \n",
       "ขายไม่ดี  0.006494  0.041667  1.000000  0.000791  0.022059  0.003984   \n",
       "นม        0.024101  0.003151  0.000791  1.000000  0.024644  0.138194   \n",
       "รสหวาน    0.017921  0.006536  0.022059  0.024644  1.000000  0.025492   \n",
       "\n",
       "           เบาหวาน      ซื้อ      กาแฟ       จืด  ...  แมกนีเซียม  \\\n",
       "7-Eleven  0.005495  0.057175  0.010283  0.022088  ...         0.0   \n",
       "tops      0.000000  0.007435  0.000000  0.000000  ...         0.0   \n",
       "ขายไม่ดี  0.000000  0.001255  0.004049  0.002755  ...         0.0   \n",
       "นม        0.005499  0.124280  0.055238  0.101106  ...         0.0   \n",
       "รสหวาน    0.000000  0.019802  0.018919  0.051173  ...         0.0   \n",
       "\n",
       "          โรคท้องร่วง  สยามพารากอน  ห้างร้าน  โรคขาดอาหาร  ช่องแช่แข็ง  \\\n",
       "7-Eleven          0.0     0.000000  0.000000     0.000000     0.000000   \n",
       "tops              0.0     0.000000  0.000000     0.000000     0.000000   \n",
       "ขายไม่ดี          0.0     0.000000  0.000000     0.000000     0.000000   \n",
       "นม                0.0     0.000396  0.000791     0.000396     0.000396   \n",
       "รสหวาน            0.0     0.000000  0.000000     0.000000     0.000000   \n",
       "\n",
       "          โยเกิร์ท   พารากอน  พาราไดซ์  โด๊บ  \n",
       "7-Eleven  0.000000  0.000000  0.000000   0.0  \n",
       "tops      0.000000  0.000000  0.000000   0.0  \n",
       "ขายไม่ดี  0.000000  0.000000  0.000000   0.0  \n",
       "นม        0.000396  0.000396  0.000396   0.0  \n",
       "รสหวาน    0.000000  0.000000  0.000000   0.0  \n",
       "\n",
       "[5 rows x 338 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_jacc_file, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "del item_item_matrix,join_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source for Robustness Check & Cross Validation (7x7 brands matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### คำนวณ Index ของยี่ห้อต่อยี่ห้อ จากทุกๆ Attributes แสดงผลเป็น Matrix ขนาด 7x7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_freq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)\n",
    "#cooc_matrix_freq = pd.read_excel(comment_cooc_freq_file,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "brands = ['เมจิ','ดัชมิลล์','โฟร์โมสต์','แดรี่โฮม','โชคชัย','เอ็มมิลค์','ไทยเดนมาร์ค']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_freq_brand = matrix_freq[brands]\n",
    "matrix_freq_unbrand = matrix_freq.drop(labels=brands,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transpose frequency into Attribute Rating Format for precompute MDS\n",
    "#cooc_matrix_freq = cooc_matrix_freq[brands]\n",
    "#cooc_matrix_freq.drop(brands, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# จำนวน Attributes = 330, brands = 7\n",
    "#cooc_matrix_freq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### 1.Jaccard Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REF: Lee Soojung,(2017). Improving Jaccard Index for Measuring Similarity in Collaborative Filtering\n",
    "# Information Science and Applications 2017, 124.\n",
    "def jaccard_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "jacc = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "jacc = jacc.append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                jacc.iloc[0,k] = jaccard_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                jacc.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = jacc.mean(axis=1)[0]\n",
    "        jacc = jacc.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <th>โชคชัย</th>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>เมจิ</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.110803</td>\n",
       "      <td>0.094467</td>\n",
       "      <td>0.019563</td>\n",
       "      <td>0.029646</td>\n",
       "      <td>0.040171</td>\n",
       "      <td>0.050040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <td>0.110803</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.124672</td>\n",
       "      <td>0.021893</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.111411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <td>0.094467</td>\n",
       "      <td>0.124672</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035470</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.117421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <td>0.019563</td>\n",
       "      <td>0.021893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.042660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โชคชัย</th>\n",
       "      <td>0.029646</td>\n",
       "      <td>0.041735</td>\n",
       "      <td>0.035470</td>\n",
       "      <td>0.013464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.024876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <td>0.040171</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "      <td>0.050040</td>\n",
       "      <td>0.111411</td>\n",
       "      <td>0.117421</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 เมจิ  ดัชมิลล์  โฟร์โมสต์  แดรี่โฮม    โชคชัย  เอ็มมิลค์  \\\n",
       "เมจิ         1.000000  0.110803   0.094467  0.019563  0.029646   0.040171   \n",
       "ดัชมิลล์     0.110803  1.000000   0.124672  0.021893  0.041735   0.000455   \n",
       "โฟร์โมสต์    0.094467  0.124672   1.000000  0.000000  0.035470   0.000258   \n",
       "แดรี่โฮม     0.019563  0.021893   0.000000  1.000000  0.013464   0.003788   \n",
       "โชคชัย       0.029646  0.041735   0.035470  0.013464  1.000000   0.000000   \n",
       "เอ็มมิลค์    0.040171  0.000455   0.000258  0.003788  0.000000   1.000000   \n",
       "ไทยเดนมาร์ค  0.050040  0.111411   0.117421  0.042660  0.024876   0.000048   \n",
       "\n",
       "             ไทยเดนมาร์ค  \n",
       "เมจิ            0.050040  \n",
       "ดัชมิลล์        0.111411  \n",
       "โฟร์โมสต์       0.117421  \n",
       "แดรี่โฮม        0.042660  \n",
       "โชคชัย          0.024876  \n",
       "เอ็มมิลค์       0.000048  \n",
       "ไทยเดนมาร์ค     1.000000  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_jaccard, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### 2.Lift normalization (Netzer et al., 2011)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def lift_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    p_a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)].shape[0]/slice_df.shape[0]\n",
    "    p_a_occur = slice_df[(slice_df.A>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_occur = slice_df[(slice_df.B>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_comprem_occur = slice_df[(slice_df.B==0)].shape[0]/slice_df.shape[0]\n",
    "    lift = p_a_in_b/(p_a_occur*p_b_comprem_occur)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "# Follow style of Lee Soojung,(2017)\n",
    "def lift_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    p_a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)].shape[0]/slice_df.shape[0]\n",
    "    p_b_comprem_occur = (slice_df.shape[0]-p_b_occur)/slice_df.shape[0]\n",
    "    lift = p_a_in_b/(p_a_occur*p_b_comprem_occur)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "#item_item_matrix = pd.DataFrame(index=cooc_matrix_freq.columns,columns=cooc_matrix_freq.columns).fillna(0)\n",
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "lift = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "lift = lift.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                lift.iloc[0,k] = lift_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                lift.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = lift.mean(axis=1)[0]\n",
    "        lift = lift.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "8qG7pCYfTCfu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <th>โชคชัย</th>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>เมจิ</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.141917</td>\n",
       "      <td>0.128428</td>\n",
       "      <td>0.020900</td>\n",
       "      <td>0.036244</td>\n",
       "      <td>0.040195</td>\n",
       "      <td>0.084652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <td>0.401348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.248499</td>\n",
       "      <td>0.030217</td>\n",
       "      <td>0.056068</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.246553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <td>0.305966</td>\n",
       "      <td>0.205819</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.047334</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.212382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <td>0.200110</td>\n",
       "      <td>0.110058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042428</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.258560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โชคชัย</th>\n",
       "      <td>0.274438</td>\n",
       "      <td>0.168540</td>\n",
       "      <td>0.131893</td>\n",
       "      <td>0.021400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.027006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "      <td>0.173248</td>\n",
       "      <td>0.184674</td>\n",
       "      <td>0.189140</td>\n",
       "      <td>0.056846</td>\n",
       "      <td>0.034192</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 เมจิ  ดัชมิลล์  โฟร์โมสต์  แดรี่โฮม    โชคชัย  เอ็มมิลค์  \\\n",
       "เมจิ         1.000000  0.141917   0.128428  0.020900  0.036244   0.040195   \n",
       "ดัชมิลล์     0.401348  1.000000   0.248499  0.030217  0.056068   0.000466   \n",
       "โฟร์โมสต์    0.305966  0.205819   1.000000  0.000000  0.047334   0.000271   \n",
       "แดรี่โฮม     0.200110  0.110058   0.000000  1.000000  0.042428   0.004654   \n",
       "โชคชัย       0.274438  0.168540   0.131893  0.021400  1.000000   0.000000   \n",
       "เอ็มมิลค์    0.900463  0.018519   0.018519  0.027006  0.000000   1.000000   \n",
       "ไทยเดนมาร์ค  0.173248  0.184674   0.189140  0.056846  0.034192   0.000049   \n",
       "\n",
       "             ไทยเดนมาร์ค  \n",
       "เมจิ            0.084652  \n",
       "ดัชมิลล์        0.246553  \n",
       "โฟร์โมสต์       0.212382  \n",
       "แดรี่โฮม        0.258560  \n",
       "โชคชัย          0.166167  \n",
       "เอ็มมิลค์       0.018519  \n",
       "ไทยเดนมาร์ค     1.000000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_lift, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Inclusion Index (Qin He, 1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def inclu_index(df,i,j):\n",
    "    a = pd.DataFrame(df.iloc[:,i])\n",
    "    b = pd.DataFrame(df.iloc[:,j])\n",
    "    slice_df = pd.concat([a,b], axis=1, join=\"inner\")\n",
    "    slice_df.columns = ['A','B']\n",
    "    a_in_b = slice_df[(slice_df.A>0)&(slice_df.B>0)].shape[0]\n",
    "    a_occur = slice_df[(slice_df.A>0)].shape[0]\n",
    "    b_occur = slice_df[(slice_df.B>0)].shape[0]\n",
    "    inclu = a_in_b/min(a_occur,b_occur)\n",
    "    return inclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def inclu_index_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)].shape[0]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)].shape[0]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)].shape[0]\n",
    "    inclu = a_in_b/min(a_occur,b_occur)\n",
    "    return inclu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "inclu = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "inclu = inclu.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                inclu.iloc[0,k] = inclu_index_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                inclu.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = inclu.mean(axis=1)[0]\n",
    "        inclu = inclu.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <th>โชคชัย</th>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>เมจิ</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.441097</td>\n",
       "      <td>0.360788</td>\n",
       "      <td>0.212238</td>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.225875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <td>0.441097</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.351729</td>\n",
       "      <td>0.136605</td>\n",
       "      <td>0.204359</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.344371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <td>0.360788</td>\n",
       "      <td>0.351729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.152746</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.295059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <td>0.212238</td>\n",
       "      <td>0.136605</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.067499</td>\n",
       "      <td>0.038377</td>\n",
       "      <td>0.288396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โชคชัย</th>\n",
       "      <td>0.290323</td>\n",
       "      <td>0.204359</td>\n",
       "      <td>0.152746</td>\n",
       "      <td>0.067499</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.196872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <td>0.900463</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.038377</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "      <td>0.225875</td>\n",
       "      <td>0.344371</td>\n",
       "      <td>0.295059</td>\n",
       "      <td>0.288396</td>\n",
       "      <td>0.196872</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 เมจิ  ดัชมิลล์  โฟร์โมสต์  แดรี่โฮม    โชคชัย  เอ็มมิลค์  \\\n",
       "เมจิ         1.000000  0.441097   0.360788  0.212238  0.290323   0.900463   \n",
       "ดัชมิลล์     0.441097  1.000000   0.351729  0.136605  0.204359   0.020000   \n",
       "โฟร์โมสต์    0.360788  0.351729   1.000000  0.000000  0.152746   0.022727   \n",
       "แดรี่โฮม     0.212238  0.136605   0.000000  1.000000  0.067499   0.038377   \n",
       "โชคชัย       0.290323  0.204359   0.152746  0.067499  1.000000   0.000000   \n",
       "เอ็มมิลค์    0.900463  0.020000   0.022727  0.038377  0.000000   1.000000   \n",
       "ไทยเดนมาร์ค  0.225875  0.344371   0.295059  0.288396  0.196872   0.020833   \n",
       "\n",
       "             ไทยเดนมาร์ค  \n",
       "เมจิ            0.225875  \n",
       "ดัชมิลล์        0.344371  \n",
       "โฟร์โมสต์       0.295059  \n",
       "แดรี่โฮม        0.288396  \n",
       "โชคชัย          0.196872  \n",
       "เอ็มมิลค์       0.020833  \n",
       "ไทยเดนมาร์ค     1.000000  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_incur, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.cosine similarity correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "# ต้องใช้ 1 เป็นตัวตั้งลบเสมอถ้าใช้ cosine จาก scipy.spatial.distance หากจะเอาค่า dissimliarity\n",
    "\n",
    "def cosine_aggregate(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = a_in_b.iloc[:,0]\n",
    "    b_occur = a_in_b.iloc[:,2]\n",
    "    cosin = 1-cosine(a_occur,b_occur)\n",
    "    return cosin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "cosin = pd.DataFrame(columns=matrix_freq_unbrand.columns)\n",
    "cosin = cosin.append(pd.Series(), ignore_index=True).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=matrix_freq_brand.columns,columns=matrix_freq_brand.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Similarity (1-cosine-1)\n",
    "for i in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "    for j in range(0,len(matrix_freq_brand.columns)): # 0 to 6\n",
    "        for k in range(0,len(matrix_freq_unbrand.columns)): # 0 to 329\n",
    "            try:\n",
    "                warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "                cosin.iloc[0,k] = cosine_aggregate(matrix_freq_brand, matrix_freq_unbrand,i, j, k)\n",
    "            except Exception:\n",
    "                cosin.iloc[0,k] = None\n",
    "                continue\n",
    "        item_item_matrix.iloc[i,j] = cosin.mean(axis=1)[0]\n",
    "        cosin = cosin.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>เมจิ</th>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <th>โชคชัย</th>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>เมจิ</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.945161</td>\n",
       "      <td>0.921691</td>\n",
       "      <td>0.989210</td>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.99923</td>\n",
       "      <td>0.968369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ดัชมิลล์</th>\n",
       "      <td>0.945161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956716</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>0.974600</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.976883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โฟร์โมสต์</th>\n",
       "      <td>0.921691</td>\n",
       "      <td>0.956716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.948996</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.964087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>แดรี่โฮม</th>\n",
       "      <td>0.989210</td>\n",
       "      <td>0.996199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990136</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.987395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>โชคชัย</th>\n",
       "      <td>0.994664</td>\n",
       "      <td>0.974600</td>\n",
       "      <td>0.948996</td>\n",
       "      <td>0.990136</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.952392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>เอ็มมิลค์</th>\n",
       "      <td>0.999230</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ไทยเดนมาร์ค</th>\n",
       "      <td>0.968369</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.964087</td>\n",
       "      <td>0.987395</td>\n",
       "      <td>0.952392</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 เมจิ  ดัชมิลล์  โฟร์โมสต์  แดรี่โฮม    โชคชัย  เอ็มมิลค์  \\\n",
       "เมจิ         1.000000  0.945161   0.921691  0.989210  0.994664    0.99923   \n",
       "ดัชมิลล์     0.945161  1.000000   0.956716  0.996199  0.974600    1.00000   \n",
       "โฟร์โมสต์    0.921691  0.956716   1.000000       NaN  0.948996    1.00000   \n",
       "แดรี่โฮม     0.989210  0.996199        NaN  1.000000  0.990136    1.00000   \n",
       "โชคชัย       0.994664  0.974600   0.948996  0.990136  1.000000        NaN   \n",
       "เอ็มมิลค์    0.999230  1.000000   1.000000  1.000000       NaN    1.00000   \n",
       "ไทยเดนมาร์ค  0.968369  0.976883   0.964087  0.987395  0.952392    1.00000   \n",
       "\n",
       "             ไทยเดนมาร์ค  \n",
       "เมจิ            0.968369  \n",
       "ดัชมิลล์        0.976883  \n",
       "โฟร์โมสต์       0.964087  \n",
       "แดรี่โฮม        0.987395  \n",
       "โชคชัย          0.952392  \n",
       "เอ็มมิลค์       1.000000  \n",
       "ไทยเดนมาร์ค     1.000000  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_robust_cosine, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.สุ่มตัดจำนวน Row-Col เพื่อนำไปทำ QAP Test (with Jaccard Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุ่ม Document 1/16, 1/8, 1/4, 1/2 เอามาทำ Cooc-matrix แล้วไล่ทำ QAP เทียบ 9000 doc กับ 4 ชุด dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "df_cooc_frq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)\n",
    "brands = ['เมจิ','ดัชมิลล์','โฟร์โมสต์','แดรี่โฮม','โชคชัย','เอ็มมิลค์','ไทยเดนมาร์ค']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rand1 = df_cooc_frq.sample(frac=(1/16))\n",
    "df_rand2 = df_cooc_frq.sample(frac=(1/8))\n",
    "df_rand3 = df_cooc_frq.sample(frac=(1/4))\n",
    "df_rand4 = df_cooc_frq.sample(frac=(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_rand1_brand = df_rand1[brands]\n",
    "matrix_rand1_unbrand = df_rand1.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand2_brand = df_rand2[brands]\n",
    "matrix_rand2_unbrand = df_rand2.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand3_brand = df_rand3[brands]\n",
    "matrix_rand3_unbrand = df_rand3.drop(labels=brands,axis=1,inplace=False)\n",
    "\n",
    "matrix_rand4_brand = df_rand4[brands]\n",
    "matrix_rand4_unbrand = df_rand4.drop(labels=brands,axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527 1054 2108 4216\n"
     ]
    }
   ],
   "source": [
    "print(df_rand1.shape[0],df_rand2.shape[0],df_rand3.shape[0],df_rand4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_index(df_b, df_attr , i, j, k):\n",
    "    brand1 = pd.DataFrame(df_b.iloc[:,i])\n",
    "    brand2 = pd.DataFrame(df_b.iloc[:,j])\n",
    "    attr = pd.DataFrame(df_attr.iloc[:,k])\n",
    "    slice_df = pd.concat([brand1, attr, brand2], axis=1, join=\"inner\")\n",
    "    a_in_b = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)&(slice_df.iloc[:,2]>0)]\n",
    "    a_occur = slice_df[(slice_df.iloc[:,0]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    b_occur = slice_df[(slice_df.iloc[:,2]>0)&(slice_df.iloc[:,1]>0)]\n",
    "    jacc_index = a_in_b.shape[0]/(a_occur.shape[0]+b_occur.shape[0]-a_in_b.shape[0])\n",
    "    return jacc_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence Similarity\n",
    "def create_Random_Poportion(df_b, df_attr):\n",
    "    precomputed_matrix = pd.DataFrame(index=df_b.columns,columns=df_b.columns).fillna(0)\n",
    "    \n",
    "    jacc = pd.DataFrame(columns=df_attr.columns)\n",
    "    jacc = jacc.append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)\n",
    "    \n",
    "    for i in range(0,len(precomputed_matrix.columns)):\n",
    "        for j in range(0,len(precomputed_matrix.columns)):\n",
    "            for k in range(0,len(df_attr.columns)): # 0 to 329\n",
    "                try:\n",
    "                    jacc.iloc[0,k] = jaccard_index(df_b, df_attr,i, j, k)\n",
    "                except Exception:\n",
    "                    jacc.iloc[0,k] = None\n",
    "                    continue\n",
    "            precomputed_matrix.iloc[i,j] = jacc.mean(axis=1)[0]\n",
    "            jacc = jacc.iloc[0:0].append(pd.Series([],dtype='float64'), ignore_index=True).fillna(0.0)\n",
    "    return precomputed_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand1_brand,matrix_rand1_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion1.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand2_brand,matrix_rand2_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion2.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand3_brand,matrix_rand3_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion3.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_Random_Poportion(matrix_rand4_brand,matrix_rand4_unbrand)\n",
    "item_item_matrix.to_excel(root_output_path+\"/poportion4.xlsx\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE\n",
    "การเทียบ QAP - matrix จะต้องเป็น sim หรือ dissim เหมือนกันทั้งสองฝั่ง (ในที่นี้ใช้ sim)<br>\n",
    "การออกกราฟ - matrix ใช้ Similarity<br>\n",
    "การทำ MDS - matrix ใช้ Dissimilarity (distance) เท่านั้น<br>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EpwX95XlTCdl",
    "_Q9pU1J6TCe5",
    "NKW--A73mzli",
    "uBBA36fDTCfZ",
    "O8nlNNE4TCfj"
   ],
   "name": "EDA_Token_CoocMat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
