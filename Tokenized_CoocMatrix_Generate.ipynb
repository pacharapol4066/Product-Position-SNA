{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xoY8sy40TCb5"
   },
   "source": [
    "### IS - Brand position\n",
    "Finding Product position on Semantic Network (PPSN)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28353,
     "status": "ok",
     "timestamp": 1604024868503,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "GkBEUBUqTGuf",
    "outputId": "cb22db45-820a-48fd-c11a-a0568439778f"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1693,
     "status": "ok",
     "timestamp": 1604024868819,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_5mrzpx3TH9K",
    "outputId": "129bb192-4ac2-4b03-bc89-7ee7a65d5032"
   },
   "source": [
    "cd /content/drive/My\\ Drive/Colab\\ Notebooks/Master_PJ_DRMABS/Datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2631,
     "status": "ok",
     "timestamp": 1604024879769,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cC0cBdCdTCb6"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "import string\n",
    "import json\n",
    "import pymongo\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\types\\oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\past\\builtins\\misc.py:4: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.core.common.SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2031,
     "status": "ok",
     "timestamp": 1604024879770,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "1kqXURiiTCb-"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "today = datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3451,
     "status": "ok",
     "timestamp": 1604028167896,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "weEcXSD8TCcI",
    "outputId": "1219680e-0d54-4649-a26e-535e112f0650"
   },
   "outputs": [],
   "source": [
    "from pythainlp.util import normalize\n",
    "from newnewthaicut import word_tokenize  # IOB Tagging tokenized\n",
    "from pythainlp.corpus import thai_stopwords\n",
    "from pythainlp.spell import correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import statistics as stat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import jaccard_score\n",
    "import scipy.stats\n",
    "from scipy.spatial.distance import cosine\n",
    "from mlxtend.evaluate import lift_score\n",
    "from gensim.models import TfidfModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 831,
     "status": "ok",
     "timestamp": 1604027698593,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "sna_e7nATCch"
   },
   "outputs": [],
   "source": [
    "# Files definition\n",
    "root_input_path = 'Datasource'\n",
    "root_output_path = 'output'\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(root_input_path+\"/comment_meiji.csv\")\n",
    "#comment_file.append(root_input_path+\"/comment_DDCF.csv\")\n",
    "\n",
    "#comment_file = []\n",
    "#comment_file.append(\"comment_meiji.csv\")\n",
    "#comment_file.append(\"comment_DDCF.csv\")\n",
    "\n",
    "comment_nlp_file = root_output_path+\"/comment_nlpToken.csv\"\n",
    "comment_cooc_freq_file = root_output_path+\"/comment_cooc_freq.xlsx\"\n",
    "comment_cooc_lift_file = root_output_path+\"/comment_cooc_Lift.xlsx\"\n",
    "comment_cooc_jacc_file = root_output_path+\"/comment_cooc_jacc.xlsx\"\n",
    "comment_cooc_corr_file = root_output_path+\"/comment_cooc_corr.xlsx\"\n",
    "comment_cooc_cosine_file = root_output_path+\"/comment_cooc_cosine.xlsx\"\n",
    "\n",
    "#comment_nlp_file = \"comment_nlpToken.csv\"\n",
    "#comment_cooc_nlp_file = \"comment_cooc.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect MongoDB\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "mydb = myclient[\"NIDA_PPSN_PRD\"]\n",
    "col_thread = mydb[\"NIDA_PPSN_THREAD\"]\n",
    "col_comment = mydb[\"NIDA_PPSN_COMMENT\"]\n",
    "col_scrape = mydb[\"NIDA_PPSN_SCRAPE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlnotsqqTCcl"
   },
   "source": [
    "### 1.Clean data & NLP Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_corpus = col_scrape.find()\n",
    "df_Corpus = pd.DataFrame(cursor_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 2677,
     "status": "ok",
     "timestamp": 1604027704431,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "VXYRZDubTCcm"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5fc2853c77db91fa3d980f8d</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5fc2853c77db91fa3d980f8e</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เบาหวานครับ แฮ่ๆ</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5fc2853c77db91fa3d980f8f</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5fc2853c77db91fa3d980f90</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5fc2853c77db91fa3d980f91</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id                               URLs  \\\n",
       "0  5fc2853c77db91fa3d980f8d  https://pantip.com/topic/39868603   \n",
       "1  5fc2853c77db91fa3d980f8e  https://pantip.com/topic/39868603   \n",
       "2  5fc2853c77db91fa3d980f8f  https://pantip.com/topic/39868603   \n",
       "3  5fc2853c77db91fa3d980f90  https://pantip.com/topic/39868603   \n",
       "4  5fc2853c77db91fa3d980f91  https://pantip.com/topic/39868603   \n",
       "\n",
       "                     headline  \\\n",
       "0  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "2  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "3  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "4  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "\n",
       "                                                text        article_date  \\\n",
       "0  เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา... 2020-05-05 13:22:59   \n",
       "1                                   เบาหวานครับ แฮ่ๆ 2020-05-05 13:22:59   \n",
       "2  หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย... 2020-05-05 13:22:59   \n",
       "3  เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย... 2020-05-05 13:22:59   \n",
       "4  ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย... 2020-05-05 13:22:59   \n",
       "\n",
       "            Retrived_date  \n",
       "0 2020-11-29 00:13:26.571  \n",
       "1 2020-11-29 00:13:26.571  \n",
       "2 2020-11-29 00:13:26.571  \n",
       "3 2020-11-29 00:13:26.571  \n",
       "4 2020-11-29 00:13:26.571  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1604027718134,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "Xf0_nwz8TCdB",
    "outputId": "d39ed4de-8549-4488-d8c5-04e62e8a4dfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All comment: 63661\n",
      "All URLs ก่อนตัด: 1516\n"
     ]
    }
   ],
   "source": [
    "print('All comment:',df_Corpus.shape[0])\n",
    "print('All URLs ก่อนตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1032,
     "status": "ok",
     "timestamp": 1604027719151,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "vRH0T2gLTCdE",
    "outputId": "0722d375-5945-44d8-bc71-f39dcc58a0e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_id              0\n",
      "URLs             0\n",
      "headline         0\n",
      "text             0\n",
      "article_date     0\n",
      "Retrived_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 828,
     "status": "ok",
     "timestamp": 1604027721340,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "LXg1m0eoTCdK",
    "outputId": "567e2a04-8322-4104-9f68-6d509815fd24"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63656</th>\n",
       "      <td>5fc2ec7c77db91fa3d990835</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>พี่มานะน่าร๊ากมากเลย เห็นแล้วอยากจกพุง</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63657</th>\n",
       "      <td>5fc2ec7c77db91fa3d990836</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>ลู่ 44 isoulmate เปเป้\\n\\nเช้า ... แซนวิส\\n\\nก...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63658</th>\n",
       "      <td>5fc2ec7c77db91fa3d990837</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>ลำดับที่ 41\\nชื่อlogin โดนัทแสนหวาน \\nชื่อเล่น...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63659</th>\n",
       "      <td>5fc2ec7c77db91fa3d990838</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>มีใครตั้งทู้ยังเอ่ย\\nงั้นเดี๋ยวเค้าตั้งให้ แป้...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63660</th>\n",
       "      <td>5fc2ec7c77db91fa3d990839</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>กระทู้วันเสาร์ พร้อมแล้วค่ะ \\nhttp://pantip.co...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            _id                               URLs  \\\n",
       "63656  5fc2ec7c77db91fa3d990835  https://pantip.com/topic/30011023   \n",
       "63657  5fc2ec7c77db91fa3d990836  https://pantip.com/topic/30011023   \n",
       "63658  5fc2ec7c77db91fa3d990837  https://pantip.com/topic/30011023   \n",
       "63659  5fc2ec7c77db91fa3d990838  https://pantip.com/topic/30011023   \n",
       "63660  5fc2ec7c77db91fa3d990839  https://pantip.com/topic/30011023   \n",
       "\n",
       "                                                headline  \\\n",
       "63656  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63657  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63658  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63659  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63660  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "\n",
       "                                                    text        article_date  \\\n",
       "63656             พี่มานะน่าร๊ากมากเลย เห็นแล้วอยากจกพุง 2013-01-04 07:03:18   \n",
       "63657  ลู่ 44 isoulmate เปเป้\\n\\nเช้า ... แซนวิส\\n\\nก... 2013-01-04 07:03:18   \n",
       "63658  ลำดับที่ 41\\nชื่อlogin โดนัทแสนหวาน \\nชื่อเล่น... 2013-01-04 07:03:18   \n",
       "63659  มีใครตั้งทู้ยังเอ่ย\\nงั้นเดี๋ยวเค้าตั้งให้ แป้... 2013-01-04 07:03:18   \n",
       "63660  กระทู้วันเสาร์ พร้อมแล้วค่ะ \\nhttp://pantip.co... 2013-01-04 07:03:18   \n",
       "\n",
       "                Retrived_date  \n",
       "63656 2020-11-29 07:33:59.076  \n",
       "63657 2020-11-29 07:33:59.076  \n",
       "63658 2020-11-29 07:33:59.076  \n",
       "63659 2020-11-29 07:33:59.076  \n",
       "63660 2020-11-29 07:33:59.076  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Corpus.drop('_id',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1006,
     "status": "ok",
     "timestamp": 1604027723160,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "_O0BSe9ETCdO"
   },
   "outputs": [],
   "source": [
    "seqNum = list(range(1,df_Corpus.shape[0]+1))\n",
    "df_Corpus.insert(0,'commentId',seqNum)\n",
    "df_Corpus.columns = ['commentId','URLs','headline','text','article_date','Retrived_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "executionInfo": {
     "elapsed": 811,
     "status": "ok",
     "timestamp": 1604027724691,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "w-muagoxTCdR",
    "outputId": "a8afe33d-943b-422e-838d-ba8514e9497d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63656</th>\n",
       "      <td>63657</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>พี่มานะน่าร๊ากมากเลย เห็นแล้วอยากจกพุง</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63657</th>\n",
       "      <td>63658</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>ลู่ 44 isoulmate เปเป้\\n\\nเช้า ... แซนวิส\\n\\nก...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63658</th>\n",
       "      <td>63659</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>ลำดับที่ 41\\nชื่อlogin โดนัทแสนหวาน \\nชื่อเล่น...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63659</th>\n",
       "      <td>63660</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>มีใครตั้งทู้ยังเอ่ย\\nงั้นเดี๋ยวเค้าตั้งให้ แป้...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63660</th>\n",
       "      <td>63661</td>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>กระทู้วันเสาร์ พร้อมแล้วค่ะ \\nhttp://pantip.co...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       commentId                               URLs  \\\n",
       "63656      63657  https://pantip.com/topic/30011023   \n",
       "63657      63658  https://pantip.com/topic/30011023   \n",
       "63658      63659  https://pantip.com/topic/30011023   \n",
       "63659      63660  https://pantip.com/topic/30011023   \n",
       "63660      63661  https://pantip.com/topic/30011023   \n",
       "\n",
       "                                                headline  \\\n",
       "63656  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63657  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63658  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63659  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63660  Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "\n",
       "                                                    text        article_date  \\\n",
       "63656             พี่มานะน่าร๊ากมากเลย เห็นแล้วอยากจกพุง 2013-01-04 07:03:18   \n",
       "63657  ลู่ 44 isoulmate เปเป้\\n\\nเช้า ... แซนวิส\\n\\nก... 2013-01-04 07:03:18   \n",
       "63658  ลำดับที่ 41\\nชื่อlogin โดนัทแสนหวาน \\nชื่อเล่น... 2013-01-04 07:03:18   \n",
       "63659  มีใครตั้งทู้ยังเอ่ย\\nงั้นเดี๋ยวเค้าตั้งให้ แป้... 2013-01-04 07:03:18   \n",
       "63660  กระทู้วันเสาร์ พร้อมแล้วค่ะ \\nhttp://pantip.co... 2013-01-04 07:03:18   \n",
       "\n",
       "                Retrived_date  \n",
       "63656 2020-11-29 07:33:59.076  \n",
       "63657 2020-11-29 07:33:59.076  \n",
       "63658 2020-11-29 07:33:59.076  \n",
       "63659 2020-11-29 07:33:59.076  \n",
       "63660 2020-11-29 07:33:59.076  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1604027727940,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "jZFN_aTsTCdU"
   },
   "outputs": [],
   "source": [
    "# Drop NA & banned comments\n",
    "df_Corpus = df_Corpus.dropna()\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('ความคิดเห็นนี้ถูกลบ')!= 0]\n",
    "df_Corpus = df_Corpus[df_Corpus[\"text\"].str.find('แก้ไขข้อความเมื่อ')!= 0]\n",
    "df_Corpus = df_Corpus.set_index('commentId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 619,
     "status": "ok",
     "timestamp": 1604027727941,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "ki-qD4YMTCdX",
    "outputId": "3102d8b3-3251-463e-f3e2-50a119fe787b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs             0\n",
      "headline         0\n",
      "text             0\n",
      "article_date     0\n",
      "Retrived_date    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing = df_Corpus.isnull().sum()\n",
    "print(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1135,
     "status": "ok",
     "timestamp": 1604027730567,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "c0J7GD3ATCda",
    "outputId": "f8748ddd-9aab-40d2-ee9e-38ba742906b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน comment หลังตัด: 62710\n",
      "จำนวนกระทู้หลังตัด: 1515\n"
     ]
    }
   ],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027730892,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "PKvz8tQpTCdd",
    "outputId": "62e2d990-0240-4a01-cef5-515147c6750c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>token_text</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63657</th>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>พี่มานะน่าร๊ากมากเลย เห็นแล้วอยากจกพุง</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63658</th>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>ลู่ 44 isoulmate เปเป้\\n\\nเช้า ... แซนวิส\\n\\nก...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63659</th>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>ลำดับที่ 41\\nชื่อlogin โดนัทแสนหวาน \\nชื่อเล่น...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63660</th>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>มีใครตั้งทู้ยังเอ่ย\\nงั้นเดี๋ยวเค้าตั้งให้ แป้...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63661</th>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>กระทู้วันเสาร์ พร้อมแล้วค่ะ \\nhttp://pantip.co...</td>\n",
       "      <td>2013-01-04 07:03:18</td>\n",
       "      <td>None</td>\n",
       "      <td>2020-11-29 07:33:59.076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        URLs  \\\n",
       "commentId                                      \n",
       "63657      https://pantip.com/topic/30011023   \n",
       "63658      https://pantip.com/topic/30011023   \n",
       "63659      https://pantip.com/topic/30011023   \n",
       "63660      https://pantip.com/topic/30011023   \n",
       "63661      https://pantip.com/topic/30011023   \n",
       "\n",
       "                                                    headline  \\\n",
       "commentId                                                      \n",
       "63657      Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63658      Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63659      Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63660      Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "63661      Fit and Firm to Slim ครั้งที่ 21\"New Year New ...   \n",
       "\n",
       "                                                        text  \\\n",
       "commentId                                                      \n",
       "63657                 พี่มานะน่าร๊ากมากเลย เห็นแล้วอยากจกพุง   \n",
       "63658      ลู่ 44 isoulmate เปเป้\\n\\nเช้า ... แซนวิส\\n\\nก...   \n",
       "63659      ลำดับที่ 41\\nชื่อlogin โดนัทแสนหวาน \\nชื่อเล่น...   \n",
       "63660      มีใครตั้งทู้ยังเอ่ย\\nงั้นเดี๋ยวเค้าตั้งให้ แป้...   \n",
       "63661      กระทู้วันเสาร์ พร้อมแล้วค่ะ \\nhttp://pantip.co...   \n",
       "\n",
       "                 article_date token_text           Retrived_date  \n",
       "commentId                                                         \n",
       "63657     2013-01-04 07:03:18       None 2020-11-29 07:33:59.076  \n",
       "63658     2013-01-04 07:03:18       None 2020-11-29 07:33:59.076  \n",
       "63659     2013-01-04 07:03:18       None 2020-11-29 07:33:59.076  \n",
       "63660     2013-01-04 07:03:18       None 2020-11-29 07:33:59.076  \n",
       "63661     2013-01-04 07:03:18       None 2020-11-29 07:33:59.076  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Corpus.insert(4,'token_text',None)\n",
    "df_Corpus.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เช็ควันเวลา"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "กระทู้เก่าที่สุด : 2013-01-03 09:20:18\n",
      "กระทู้ใหม่ที่สุด : 2020-09-11 19:21:41\n"
     ]
    }
   ],
   "source": [
    "print('กระทู้เก่าที่สุด :',min(df_Corpus.article_date))\n",
    "print('กระทู้ใหม่ที่สุด :',max(df_Corpus.article_date))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เก็บเฉพาะหัวกระทู้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>mention_product</th>\n",
       "      <th>mention_brand</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commentId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63500</th>\n",
       "      <td>https://pantip.com/topic/30059506</td>\n",
       "      <td>อยากทราบว่า ตอนตั้งครรถ์คุณแม่บำรุงอะไรกันบ้าง...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63529</th>\n",
       "      <td>https://pantip.com/topic/30007179</td>\n",
       "      <td>นมยี่ห้ออะไรดีสุดสำหรับคนท้องค่ะ</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63551</th>\n",
       "      <td>https://pantip.com/topic/30020409</td>\n",
       "      <td>ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63578</th>\n",
       "      <td>https://pantip.com/topic/30049123</td>\n",
       "      <td>เมื่อเพื่อนของข้าพเจ้า...เข้าวงการบันเทิง!!! (...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63606</th>\n",
       "      <td>https://pantip.com/topic/30011023</td>\n",
       "      <td>Fit and Firm to Slim ครั้งที่ 21\"New Year New ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        URLs  \\\n",
       "commentId                                      \n",
       "63500      https://pantip.com/topic/30059506   \n",
       "63529      https://pantip.com/topic/30007179   \n",
       "63551      https://pantip.com/topic/30020409   \n",
       "63578      https://pantip.com/topic/30049123   \n",
       "63606      https://pantip.com/topic/30011023   \n",
       "\n",
       "                                                    headline token_headline  \\\n",
       "commentId                                                                     \n",
       "63500      อยากทราบว่า ตอนตั้งครรถ์คุณแม่บำรุงอะไรกันบ้าง...           None   \n",
       "63529                       นมยี่ห้ออะไรดีสุดสำหรับคนท้องค่ะ           None   \n",
       "63551      ฝึกสอนลูกดื่มนม UHT จากกล่องสำเร็จยังไงกันบ้าง...           None   \n",
       "63578      เมื่อเพื่อนของข้าพเจ้า...เข้าวงการบันเทิง!!! (...           None   \n",
       "63606      Fit and Firm to Slim ครั้งที่ 21\"New Year New ...           None   \n",
       "\n",
       "          mention_product mention_brand  \n",
       "commentId                                \n",
       "63500                None          None  \n",
       "63529                None          None  \n",
       "63551                None          None  \n",
       "63578                None          None  \n",
       "63606                None          None  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_thread = df_Corpus.copy()\n",
    "df_thread = df_thread[['URLs','headline']]\n",
    "df_thread.drop_duplicates(subset =\"URLs\", keep = 'first', inplace = True)\n",
    "df_thread.insert(2,'token_headline',None)\n",
    "df_thread.insert(3,'mention_product',None)\n",
    "df_thread.insert(4,'mention_brand',None)\n",
    "df_thread.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EpwX95XlTCdl"
   },
   "source": [
    "## 2.ตัดคำและเก็บลง MongoDB (ใช้ insight จาก jupyter งานก่อน)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6U__d4agTCdl"
   },
   "source": [
    "https://www.thainlp.org/pythainlp/tutorials/notebooks/pythainlp-get-started.html#Thai-Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 880,
     "status": "ok",
     "timestamp": 1604028299778,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "cr_O7hE5htx2"
   },
   "outputs": [],
   "source": [
    "def normThai(w):\n",
    "    returnList = []\n",
    "    for i in w:\n",
    "        returnList.append(normalize(i))\n",
    "    return returnList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 962,
     "status": "ok",
     "timestamp": 1604030224171,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "rAcuuoYiTCdu"
   },
   "outputs": [],
   "source": [
    "garbage_char = ['ไม่','','.','..','...','มกราคม', 'กุมภาพันธ์','มีนาคม', 'เมษายน','พฤษภาคม', 'มิถุนายน', 'กรกฎาคม','สิงหาคม','กันยายน'\n",
    "                ,'ตุลาคม','พฤศจิกายน', 'ธันวาคม','วันจันทร์','วันอังคาร','วันพุธ','วันพฤหัสบดี','วันศุกร์','วันเสาร์','วันอาทิตย์','กก'\n",
    "                ,'เมนู','Menu','Net','net','สาขา','บาท','ราคา','ฯ','ๆ','กก','อันนี้','😆', '🤣','😢','😏','😂','😿','🥺','ววว','xx','อิอิ','แย้ววว']\n",
    "naka = ['นะคะ','นะค่ะ','น่ะค่ะ','น่ะคะ','ฮ้าฟ','ค้าบ','คร้าบ']\n",
    "\n",
    "stopwords = set(thai_stopwords()).union(set(naka))\n",
    "stopwords.remove('ไม่')\n",
    "stopwords.remove('สูง')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 813,
     "status": "ok",
     "timestamp": 1604027849933,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "mAwAGA5ITCdx",
    "outputId": "d95e59bb-b35e-4592-f16e-0915a7975f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "จำนวน comment หลังตัด: 62710\n",
      "จำนวนกระทู้หลังตัด: 1515\n"
     ]
    }
   ],
   "source": [
    "print('จำนวน comment หลังตัด:',df_Corpus.shape[0])\n",
    "print('จำนวนกระทู้หลังตัด:',len(df_Corpus.URLs.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_custom(x):\n",
    "    custom_punc = '!.—-\"$#&฿/&\\'()*+,:;<=>?@[\\\\]^_`{|}~'\n",
    "    x = x.translate(str.maketrans('', '', custom_punc)).strip()\n",
    "    x = x.translate(str.maketrans({\"\\t\":None,\"\\n\": None})).strip()\n",
    "    x = x.lower()\n",
    "    wtkn = word_tokenize(x)\n",
    "    wtkn = [j for j in wtkn if j not in stopwords]\n",
    "    wtkn = [w for w in wtkn if len(w) >= 2]\n",
    "    wtkn = [y for y in wtkn if y not in garbage_char]\n",
    "    wtkn = [s for s in wtkn if not s.isdigit()]\n",
    "    wtkn = normThai(wtkn)\n",
    "    return wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_Thread(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"URLs\": lx,\n",
    "            \"headline\": df.headline[c],\n",
    "            \"token_headline\":df.token_headline[c],\n",
    "            \"t_mention_dairy\":df.t_mention_dairy[c],\n",
    "            \"t_mention_product\": df.t_mention_product[c],\n",
    "            \"t_mention_brand\": df.t_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_InsertMany_comments(df):\n",
    "    listofdict = []\n",
    "    for c,lx in enumerate(df.URLs,0):\n",
    "        info = {\n",
    "            \"commentId\":int(df.commentId[c]),\n",
    "            \"URLs\": lx,\n",
    "            \"headline\":df.headline[c],\n",
    "            \"text\": df.text[c],\n",
    "            \"Retrived_date\": df.Retrived_date[c],\n",
    "            \"token_text\":df.token_text[c],\n",
    "            \"cmt_mention_dairy\": df.cmt_mention_dairy[c],\n",
    "            \"cmt_mention_product\": df.cmt_mention_product[c],\n",
    "            \"cmt_mention_brand\": df.cmt_mention_brand[c]\n",
    "        }\n",
    "        listofdict.append(info)\n",
    "    return listofdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalize_keyword(wtkn):  \n",
    "    ret_wtkn = wtkn\n",
    "    for i,each in enumerate(ret_wtkn,0):\n",
    "        if each in ['ดัชมิลล์','ดัชมิล','ดัชมิว','dutchmill','dutch mill','dutch milk','dutchmilk','duchmill','duchie-bio','ดัชชี่']:\n",
    "            ret_wtkn[i] = 'ดัชมิลล์'\n",
    "        elif each  in ['เมจิ','ซีพีเมจิ','ซีพี เมจิ','cp meiji','meiji','meji','miji','cpmeijicom','cpmeijitensai','cpmeijithailand']:\n",
    "            ret_wtkn[i] = 'เมจิ'\n",
    "        elif each  in ['โฟร์โมสต์','โฟร์โมส','โฟโมสต์','โฟโมต','โฟรโมสต์','โฟรโมสต','foremost']:\n",
    "            ret_wtkn[i] = 'โฟร์โมสต์'\n",
    "        elif each  in ['แดรี่โฮม','dairy home','dairyhome','เดรี่โฮม','เดลี่โฮม']:\n",
    "            ret_wtkn[i] = 'แดรี่โฮม'\n",
    "        elif each  in ['โชคชัย','อืมม มิลค์','umm milk','นมฟาร์มโชคชัย']:\n",
    "            ret_wtkn[i] = 'โชคชัย'\n",
    "        elif each  in ['เอ็มมิลค์','mmilk','เอ็มมิ้ลค์','เอ็มมิลล์','m milk']:\n",
    "            ret_wtkn[i] = 'เอ็มมิลค์'\n",
    "        elif each  in ['ไทยเดนมาร์ค','ไทยเดนมาร์ก','วัวแดง']:\n",
    "            ret_wtkn[i] = 'ไทยเดนมาร์ค'\n",
    "        elif each  in ['สตอเบอร์รี่','สตรอว์เบอร์รี','รสสตรอเบอรี่','สตอเบอรี่','สตรอเบอรี่','สตรอวเบอรี่','สตรอเบอร์รี่']:\n",
    "            ret_wtkn[i] = 'สตรอว์เบอร์รี'\n",
    "        elif each  in ['ชอคโกแล็ต','ช็อกโกแลต','ช็อคโกแลต','ช๊อกโกแลต','ช็อคโกแล็ต','ช็อกโกเลต','ช็อค']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลต'\n",
    "        elif each  in ['มิ้นท์ชอค','มิ้นต์ช้อก','ช็อคโกแลตมินต์','มินต์ช็อคโกแลต']:\n",
    "            ret_wtkn[i] = 'ช็อกโกแลตมินต์'\n",
    "        elif each  in ['ไขมันต่ำ','low fat','พร่องมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมันต่ำ'\n",
    "        elif each  in ['ไขมัน 0','ไขมัน 0%','0 fat','0% fat','ขาดมันเนย']:\n",
    "            ret_wtkn[i] = 'ไขมัน 0%'\n",
    "        elif each  in ['high protein','hi protein','ไฮโปรตีน']:\n",
    "            ret_wtkn[i] = 'ไฮโปรตีน'\n",
    "        elif each  in ['free lactose','lactose free','ฟรีแลคโตส','แลคโตสฟรี']:\n",
    "            ret_wtkn[i] = 'นมฟรีแลคโตส'\n",
    "        elif each  in ['พาส','พาสเจอไรซ์','พาสเจอร์ไรซ์','พาสเจอร์ไรส์','พาซเจอไรซ์','พาสเจอร์ไลท์']:\n",
    "            ret_wtkn[i] = 'พาสเจอร์ไรส์'\n",
    "        elif each  in ['เมจิโกลด์ แม็กซ์','เมจิโกลด์','เมจิ โกลด์','เมจิโกล์ดแม็กซ์','gold','gold max']:\n",
    "            ret_wtkn[i] = 'เมจิโกลด์'\n",
    "        elif each  in ['ฝาน้ำเงิน','รสจืด']:\n",
    "            ret_wtkn[i] = 'รสจืด'\n",
    "        elif each  in ['ท็อปส์','ทอปส์','ท้อปส์','ท๊อปส์','tops']:\n",
    "            ret_wtkn[i] = 'tops'\n",
    "        elif each  in ['แมคโคร','แม็คโคร','makro']:\n",
    "            ret_wtkn[i] = 'makro'\n",
    "        elif each  in ['โลตัส','lotus']:\n",
    "            ret_wtkn[i] = 'lotus'\n",
    "        elif each  in ['บิ๊กซี','bigc','big c']:\n",
    "            ret_wtkn[i] = 'bigc'\n",
    "        elif each in ['ดาร์คช็อกโกแลต','ดาร์กช็อก','ดาร์กช็อกโกแลต']:\n",
    "            ret_wtkn[i] = 'ดาร์คช็อกโกแลต'\n",
    "        elif each in ['bedtime','bed time','เบดไทม์']:\n",
    "            ret_wtkn[i] = 'เบดไทม์'\n",
    "        elif each in ['เมจิ บัลแกเรีย','เมจิบัลแกเรีย','บัลแกเรีย','bulgaria']:\n",
    "            ret_wtkn[i] = 'เมจิบัลแกเรีย'\n",
    "        elif each in ['โยเกิร์ต','โยเกิต','โยเกิรต','โยเกิร์ตพร้อมดื่ม']:\n",
    "            ret_wtkn[i] = 'โยเกิร์ต'\n",
    "        elif each in ['7 Eleven','7 eleven','เซเว่น อีเลฟเว่น','เซเว่นอีเลฟเว่น','เซเว่น','เซเวน','7 11']:\n",
    "            ret_wtkn[i] = '7-Eleven'\n",
    "        elif each in ['บีทาเก้น','บีทาเกน']:\n",
    "            ret_wtkn[i] = 'บีทาเก้น'\n",
    "        elif each in ['โปร','โปรโมชั่น']:\n",
    "            ret_wtkn[i] = 'โปรโมชั่น'\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_brands_product(x,catType):\n",
    "    ret_wtkn = []\n",
    "    brands = ['ดัชมิลล์','เมจิ','โฟร์โมสต์','โชคชัย','แดรี่โฮม','เอ็มมิลค์','แมคโนเลีย','ไทยเดนมาร์ค','หนองโพ','คาเนชั่น','บีทาเก้น','จิตรลดา']\n",
    "    products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ','วิปครีม']\n",
    "    milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์','nondairy','non dairy']\n",
    "    \n",
    "    choiceList = []\n",
    "    if catType == 'b':\n",
    "        choiceList = brands\n",
    "    elif catType == 'm':\n",
    "        choiceList = milk_kind\n",
    "    elif catType == 'p':\n",
    "        choiceList = products\n",
    "        \n",
    "    for i,each in enumerate(x,0):\n",
    "        if each in choiceList:\n",
    "            ret_wtkn.append(each)\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy ชุดคำจาก File มา Process ก่อนลง MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment = df_Corpus.reset_index().copy()\n",
    "df_process_thread = df_thread.reset_index().copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1) Tokenize comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['text'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>text</th>\n",
       "      <th>article_date</th>\n",
       "      <th>token_text</th>\n",
       "      <th>Retrived_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[ปี, เซเว่น, ยังมี, นม, เมจิ, รสหวาน, ขาย, อยู...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เบาหวานครับ แฮ่ๆ</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[เบาหวาน, แฮ่]</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[หาซื้อไม่ได้นี่คิดได้, , คน, กินกัน, ทำ, คน, ...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[รส, ขายไม่ดี, รส, พื้นฐาน, จืด, แบ่ง, 100%, l...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย...</td>\n",
       "      <td>2020-05-05 13:22:59</td>\n",
       "      <td>[ขายไม่ดี, เค้า, shelf life, เวลา, หมดอายุ, ค่...</td>\n",
       "      <td>2020-11-29 00:13:26.571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                               URLs                    headline  \\\n",
       "0          1  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1          2  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "2          3  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "3          4  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "4          5  https://pantip.com/topic/39868603  นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "\n",
       "                                                text        article_date  \\\n",
       "0  เมื่อก่อนหลายปีมาแล้ว ในเซเว่นยังมีนมเมจิรสหวา... 2020-05-05 13:22:59   \n",
       "1                                   เบาหวานครับ แฮ่ๆ 2020-05-05 13:22:59   \n",
       "2  หาซื้อไม่ได้นี่คิดได้  2 อย่างนะ.    คนไม่ค่อย... 2020-05-05 13:22:59   \n",
       "3  เป็นรสที่ขายไม่ดีครับ\\nรสพื้นฐานคือ\\nจืด แบ่งย... 2020-05-05 13:22:59   \n",
       "4  ถ้าขายไม่ดีเค้าก็เอาออกครับ shelf life มันน้อย... 2020-05-05 13:22:59   \n",
       "\n",
       "                                          token_text           Retrived_date  \n",
       "0  [ปี, เซเว่น, ยังมี, นม, เมจิ, รสหวาน, ขาย, อยู... 2020-11-29 00:13:26.571  \n",
       "1                                     [เบาหวาน, แฮ่] 2020-11-29 00:13:26.571  \n",
       "2  [หาซื้อไม่ได้นี่คิดได้, , คน, กินกัน, ทำ, คน, ... 2020-11-29 00:13:26.571  \n",
       "3  [รส, ขายไม่ดี, รส, พื้นฐาน, จืด, แบ่ง, 100%, l... 2020-11-29 00:13:26.571  \n",
       "4  [ขายไม่ดี, เค้า, shelf life, เวลา, หมดอายุ, ค่... 2020-11-29 00:13:26.571  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process_comment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['token_text'] = df_process_comment['token_text'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_comment['cmt_mention_dairy'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_comment['cmt_mention_brand'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_comment['cmt_mention_product'] = df_process_comment['token_text'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3) Insert comments to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hunm5MT7TCd2",
    "outputId": "15710375-8df1-46f0-85a2-04c66e1de5d9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x151e63a7fc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_comment.delete_many({})\n",
    "process_data = create_InsertMany_comments(df_process_comment)\n",
    "col_comment.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4) Tokenize head of thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['headline'].apply(lambda x: tokenize_custom(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.5) Generalized keyword (Brand & product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['token_headline'] = df_process_thread['token_headline'].apply(lambda x: generalize_keyword(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.6) Mark domain/entity mention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_process_thread['t_mention_dairy'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'m'))\n",
    "df_process_thread['t_mention_brand'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'b'))\n",
    "df_process_thread['t_mention_product'] = df_process_thread['token_headline'].apply(lambda x: find_brands_product(x,'p'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commentId</th>\n",
       "      <th>URLs</th>\n",
       "      <th>headline</th>\n",
       "      <th>token_headline</th>\n",
       "      <th>mention_product</th>\n",
       "      <th>mention_brand</th>\n",
       "      <th>t_mention_dairy</th>\n",
       "      <th>t_mention_brand</th>\n",
       "      <th>t_mention_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://pantip.com/topic/39868603</td>\n",
       "      <td>นมเมจิรสหวานทำไมหายากจังคะ</td>\n",
       "      <td>[นม, เมจิ, รสหวาน, หายาก]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>[รสหวาน]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>https://pantip.com/topic/39597709</td>\n",
       "      <td>ระหว่างนมเมจิต้มกับนมเมจิที่ไม่ได้ต้ม เมื่อนำไ...</td>\n",
       "      <td>[นม, เมจิ, ต้ม, นม, เมจิ, ไม่ได้, ต้ม, ทำ, เคร...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม, นม]</td>\n",
       "      <td>[เมจิ, เมจิ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>https://pantip.com/topic/39747201</td>\n",
       "      <td>ทำไมนมเมจิขวดใหญ่ 2 ลิตร ไม่มีซีลที่ปากแบบขวดเล็ก</td>\n",
       "      <td>[นม, เมจิ, ขวด, ลิตร, ไม่มีซีล, ปาก, ขวด]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[เมจิ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>https://pantip.com/topic/39732615</td>\n",
       "      <td>Makro มีนม meiji(เมจิ) ขายมั้ยครัย</td>\n",
       "      <td>[makro, นม, เมจิ, เมจิ, ขาย, รัย]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[เมจิ, เมจิ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>https://pantip.com/topic/39005469</td>\n",
       "      <td>ใครเคยสั่งซื้อนมเมจิ (Meiji) ให้มาส่งครั้งละเย...</td>\n",
       "      <td>[สั่งซื้อ, นม, เมจิ, เมจิ]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[นม]</td>\n",
       "      <td>[เมจิ, เมจิ]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   commentId                               URLs  \\\n",
       "0          1  https://pantip.com/topic/39868603   \n",
       "1          8  https://pantip.com/topic/39597709   \n",
       "2         14  https://pantip.com/topic/39747201   \n",
       "3         15  https://pantip.com/topic/39732615   \n",
       "4         20  https://pantip.com/topic/39005469   \n",
       "\n",
       "                                            headline  \\\n",
       "0                         นมเมจิรสหวานทำไมหายากจังคะ   \n",
       "1  ระหว่างนมเมจิต้มกับนมเมจิที่ไม่ได้ต้ม เมื่อนำไ...   \n",
       "2  ทำไมนมเมจิขวดใหญ่ 2 ลิตร ไม่มีซีลที่ปากแบบขวดเล็ก   \n",
       "3                 Makro มีนม meiji(เมจิ) ขายมั้ยครัย   \n",
       "4  ใครเคยสั่งซื้อนมเมจิ (Meiji) ให้มาส่งครั้งละเย...   \n",
       "\n",
       "                                      token_headline mention_product  \\\n",
       "0                          [นม, เมจิ, รสหวาน, หายาก]            None   \n",
       "1  [นม, เมจิ, ต้ม, นม, เมจิ, ไม่ได้, ต้ม, ทำ, เคร...            None   \n",
       "2          [นม, เมจิ, ขวด, ลิตร, ไม่มีซีล, ปาก, ขวด]            None   \n",
       "3                  [makro, นม, เมจิ, เมจิ, ขาย, รัย]            None   \n",
       "4                         [สั่งซื้อ, นม, เมจิ, เมจิ]            None   \n",
       "\n",
       "  mention_brand t_mention_dairy t_mention_brand t_mention_product  \n",
       "0          None            [นม]          [เมจิ]          [รสหวาน]  \n",
       "1          None        [นม, นม]    [เมจิ, เมจิ]                []  \n",
       "2          None            [นม]          [เมจิ]                []  \n",
       "3          None            [นม]    [เมจิ, เมจิ]                []  \n",
       "4          None            [นม]    [เมจิ, เมจิ]                []  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_process_thread.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.7) Insert thread to DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x151e14d1dc8>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_thread.delete_many({})\n",
    "process_data = create_InsertMany_Thread(df_process_thread)\n",
    "col_thread.insert_many(process_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "executionInfo": {
     "elapsed": 890,
     "status": "ok",
     "timestamp": 1604027734766,
     "user": {
      "displayName": "Pacharapol O.",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiBNaVjsCxoMVUqEvSDC7eauF0V2ZD7B-TzevR1TQ=s64",
      "userId": "00378494490135533545"
     },
     "user_tz": -420
    },
    "id": "J30GMUlJTCdh"
   },
   "outputs": [],
   "source": [
    "del df_thread,df_Corpus,df_process_comment,df_process_thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Process หัวกระทู้ เพื่อทำ Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "เคสหลุดเงื่อนไข แต่ต้องใช้\n",
    "1. https://pantip.com/topic/30833944\n",
    "2. https://pantip.com/topic/30105850\n",
    "4. https://pantip.com/topic/35439062"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]\n",
    "df_urls_milk['t_mention_dairy'] = df_urls_milk['t_mention_dairy'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_brand'] = df_urls_milk['t_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_urls_milk['t_mention_product'] = df_urls_milk['t_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_urls_milk = df_cmt_process[(df_cmt_process.cmt_mention_dairy.str.len() != 0) | (df_cmt_process.URLs.isin(execption_urls))]\n",
    "df_c_urls_milk['cmt_mention_dairy'] = df_c_urls_milk['cmt_mention_dairy'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_brand'] = df_c_urls_milk['cmt_mention_brand'].apply(lambda x: repr(set(x)))\n",
    "df_c_urls_milk['cmt_mention_product'] = df_c_urls_milk['cmt_mention_product'].apply(lambda x: repr(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('จำนวนกระทู้ที่มีการพูดถึงนม:',df_urls_milk.shape[0])\n",
    "print('%จำนวนกระทู้ที่มีการพูดถึงนมเทียบทั้งหมด:',round((df_urls_milk.shape[0]/df_thr_process.shape[0])*100,2))\n",
    "print('จำนวน comment ที่มีการพูดถึงนม:',df_c_urls_milk.shape[0])\n",
    "print('%จำนวน comment ที่มีการพูดถึงนมเทียบทั้งหมด:',round((df_c_urls_milk.shape[0]/df_cmt_process.shape[0])*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* จำนวน comment ที่มีการพูดถึงนม ไม่ได้ impute มาจากหัวกระทู้ ถ้า impute จะมีเยอะกว่านี้อีก"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA#2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุ domain ของนม บนหัวกระทู้"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_dairy']]\n",
    "df_view.column = ['URLs','t_mention_dairy']\n",
    "df_view_count = df_view.groupby('t_mention_dairy').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]\n",
    "\n",
    "# set() ในเคสนี้คือกระทู้ที่พูดถึงนมแต่ไม่มี domain ในหัวกระทู้ ต้องดึง custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ Product บนหัวกระทู้ (Headline)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_urls_milk[['URLs','t_mention_product']]\n",
    "df_view.column = ['URLs','t_mention_product']\n",
    "df_view_count = df_view.groupby('t_mention_product').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]\n",
    "\n",
    "# set() หมายถึง กระทู้นั้นอยู่ใน domain นม แต่ไม่ระบุ product flavor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ Product ใน comment ทั้งใต้หัวกระทู้ ที่มี domain ของนม และส่วน comment<br>\n",
    "อย่างไรก็ตามยังไม่ได้ impute domain จากหัวกระทู้เข้าไป"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_c_urls_milk[['URLs','cmt_mention_product']]\n",
    "df_view.column = ['URLs','cmt_mention_product']\n",
    "df_view_count = df_view.groupby('cmt_mention_product').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "การระบุชื่อ brand ใน comment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_view = df_c_urls_milk[['URLs','cmt_mention_brand']]\n",
    "df_view.column = ['URLs','cmt_mention_brand']\n",
    "df_view_count = df_view.groupby('cmt_mention_brand').count()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_view_count.sort_values(by='URLs',ascending=False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.สรุป Term & reduced_keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execption_urls = ['https://pantip.com/topic/30833944','https://pantip.com/topic/30105850','https://pantip.com/topic/35439062']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrributes = ['การบูด','โปร','โปรโมชั่น','แถม','บูด','เป็นผลดี','หา','หมดอายุ', 'กลิ่น','หอม','กลิ่นหอม', 'แนะนำ', 'กิน', 'shelf life','แม่','คุณแม่'\n",
    " ,'ลูก','เด็ก','เลี้ยงลูก','เลี้ยงเด็ก','พัฒนาการ','คุณแม่มือใหม่','สั่ง', 'ค่าใช้จ่าย', 'เพิ่มขึ้น', 'สินค้า', 'ชอบ','นิยม', 'สี', 'ซื้อไม่ได้'\n",
    " , 'ทิ้ง', 'จืด','หวาน' , 'fat', 'นิยม','ราคาสูง','กาแฟ','ชงกาแฟ','หาย','ต้ม','อุ่น','ร้อน', 'พื้นฐาน', 'ขายไม่ดี','สูง','ส่วนสูง'\n",
    " , 'กาแฟสด', 'จ่าย', 'ขาย', 'รส','รสชาติ', 'กลมกล่อม','ไขมัน','พนักงาน','ไมโครเวฟ','ฟาร์ม'\n",
    " ,'ส่วนผสม','ผสม','เบาหวาน','รสพื้นฐาน','โปรตีน','เวย์','เวท','วิ่ง','protein','whey','ขับถ่าย','อึ','dha','น้ำตาล','เบาหวาน'\n",
    " ,'ฝา', 'นมสด','ถ้วย', 'ร้าน', 'ดื่ม', 'เซเว่น', 'ขวด', 'นึกถึง', 'เสียใจ', 'แตก', 'ซื้อ','ขาย','มีลูก','เทรนเนอร์'\n",
    " ,'ขายไม่ดี','แพคคู่','ค่าจัดส่ง','shelf life','พนักงานขายนม','แพ้นม','แพ้นมวัว','เล่นเวท','ฝาน้ำเงิน','ฝาสีเขียว'\n",
    " ,'นมอุ่น','ชานม','กินนม','ดื่มนม','ท้องเสีย','ลูกสุนัข','สุนัข','หมา','แมว','คายทิ้ง','เจมส์จิ','แป้ง','ลดราคา'\n",
    " ,'ซื้อประจำ','ซื้อไม่ได้','คาปูชิโน่','อเมริกาโน่','ร้านนม','whey formula','ผิดสังเกต','เสียความรู้สึก','ชี้แจง','บำรุง','น้ำผึ้ง'\n",
    " ,'อาหารเสริม','มีประโยชน์','วิตามิน','นมผง','แคลเซี่ยม','ท้อง','แพะ','อร่อย','โภชนาการ','โรงเรียน','พ่อแม่','ครู','ยูเอชที'\n",
    " ,'ผู้บริโภค','ขโมย','ไอโอดีน','นมข้นหวาน','เนย','ตรวจสอบ','แกลลอน','มันดี','นมวัว','อาเจียน','เวฟ','ไมโครเวฟ','สารอาหาร'\n",
    " ,'ขนส่ง','ถูก','แพง','เค้ก','ทิ้ง','วันหมดอายุ','โอเมก้า','กล่อง','พลังงาน','โภชนาการ','ขนมปัง','ของแถม','ราคาสูง','น้ำนมโค'\n",
    " ,'บรรจุภัณฑ์','ความแข็งแรง','แข็งแรง','พรีเซ็นเตอร์','ญี่ปุ่น','น้ำผลไม้','ออกกำลังกาย','ประหยัด','วิปปิ้ง','เชื้อจุลินทรีย์'\n",
    " ,'แลคโตส']\n",
    "\n",
    "stores = ['tops','makro','lotus','bigc','7-Eleven']\n",
    "\n",
    "products = ['สตรอว์เบอร์รี','ช็อกโกแลต','รสกาแฟ','รสหวาน','รสจืด','ไขมันต่ำ','ไขมัน 0%','ไฮโปรตีน','อัลมอนด์'\n",
    "                ,'รสกล้วย','grass fed','นมฟรีแลคโตส','เมจิโกลด์','นมฮอกไกโด','เบดไทม์','ดาร์คช็อกโกแลต','ไฮแคลเซียม'\n",
    "                ,'คาราเมล','มอลต์','เมล่อน','ชาเขียวมัจฉะ','บัลแกเรีย','รสธรรมชาติ','รสกลมกล่อม','ซากุระ']\n",
    "milk_kind=['นม','นมข้น','นมจืด','นมสด','กินนม','ดื่มนม','ขวดนม','นมวัว','นมกล่อง','ผลิตภันท์นม','น้ำนมโค'\n",
    "                     ,'โยเกิร์ต','นมเปรี้ยว','uht','นมถั่วเหลือง','นมผง','พาสเจอร์ไรส์']\n",
    "\n",
    "#  EDA ใน Excel ได้ flavor 68 ตัว (ถ้าดึงยี่ห้ออื่นก็เพิ่มอีก)\n",
    "avai_flavs = ['เมจิเมจิโกลด์','เมจิเมล่อน','เมจิไขมัน 0%','เมจิไขมันต่ำ','เมจิไฮโปรตีน','เมจิช็อกโกแลต','เมจิชาเขียวมัจฉะ','เมจิดาร์คช็อกโกแลต'\n",
    " ,'เมจินมฟรีแลคโตส','เมจิบัลแกเรีย','เมจิมอลต์','เมจิรสกลมกล่อม','เมจิรสกล้วย','เมจิรกาแฟ','เมจิรสจืด','เมจิรสธรรมชาติ','เมจิรสหวาน'\n",
    " ,'เมจิสตรอว์เบอร์รี','เมจิอัลมอนด์','เอ็มมิลค์นมฟรีแลคโตส','เอ็มมิลค์รสจืด','แดรี่โฮมgrass fed','แดรี่โฮมเบดไทม์','แดรี่โฮมช็อกโกแลต'\n",
    " ,'แดรี่โฮมรสกล้วย','แดโฮมรสจืด','แดรี่โฮมรสหวาน','แดรี่โฮมสตรอว์เบอร์รี','แมคโนเลียไขมันต่ำ','แมคโนเลียช็อกโกแลต','แมคโนเลียรสจืด'\n",
    " ,'โชคชัยไขมันต่ำ','โชคชัยช็อกโกแลต','โชคชัยรสกาแฟ','โชคชัยรสจืด','โชคชัยสตรอว์เบอร์รี','ฟร์โมสต์ไขมัน 0%','โฟร์โมสต์ไขมันต่ำ'\n",
    " ,'โฟร์โมสต์คาราเมล','โฟร์โมสต์ช็อกโกแลต','โฟร์โมสต์รสกาแฟ','โฟร์โมสต์รสจืด','โฟร์โมสต์สตรอว์เบอร์รี','ไทยเดนมาร์คช็อกโกแลต'\n",
    " ,'ไทยเดนมาร์ครสกาแฟ','ไทยเดนมาร์ครสจืด','ไทยเดนมาร์ครสหวาน','ไทยเดนมาร์คสตรอว์เบอร์รี','คาเนชั่นรสจืด','จิตรลดาช็อกโกแลต'\n",
    " ,'จิตรลดารสจืด','จิตรลดารสหวาน','จิตรลดาสตรอว์เบอร์รี','ดัชมิลล์ไขมัน 0%','ดัชมิลล์ไขมันต่ำ','ดัชมิลล์ไฮโปรตีน','ดัชลล์อกกแลต'\n",
    " ,'ดัชมิลล์มอลต์','ดัชมิลล์รสกาแฟ','ดัชมิลล์รสจืด','ดัชมิลล์สตรอว์เบอร์รี','หนองโพไขมัน 0%','หนองโพไขมันต่ำ','หนองโพช็อกโกแลต'\n",
    " ,'หนองโพรสกาแฟ','หนองโพรสจืด','หนองโพรสหวาน','หนองโพสตรอว์เบอร์รี']\n",
    "\n",
    "reduceCol = attrributes + stores \n",
    "reduceCol_all = attrributes + stores + milk_kind + products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduced_keyword(wtkn,redCol):\n",
    "    del_list = []\n",
    "    ret_wtkn = wtkn\n",
    "    for each in ret_wtkn:\n",
    "        if each not in redCol:\n",
    "            del_list.append(each)\n",
    "    ret_wtkn = [x for x in ret_wtkn if x not in del_list]\n",
    "    return ret_wtkn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def freq_brand(x):\n",
    "    #e = eval(x)\n",
    "    e = x\n",
    "    e.sort()\n",
    "    f = [(k,len(list(g))) for k, g in groupby(e)]\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_flavor(x,y):\n",
    "    listflav = []\n",
    "    for i in x:\n",
    "        for j in y:\n",
    "            listflav.append(i+j)\n",
    "    return listflav"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKW--A73mzli"
   },
   "source": [
    "### 5.สร้าง (Reduce) Bag of word ด้วย dictionary.doc2bow จัดลง dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_thread = col_thread.find()\n",
    "df_thr_process = pd.DataFrame(cursor_thread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor_comment = col_comment.find()\n",
    "df_cmt_process = pd.DataFrame(cursor_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# คัด headline ที่พูดถึง domain นม\n",
    "df_urls_milk = df_thr_process[(df_thr_process.t_mention_dairy.str.len() != 0) | (df_thr_process.URLs.isin(execption_urls))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# เมื่อ join กันแล้ว คอมเม้นทุกคอมเม้นจะอยู่ใน domain นมทั้งหมด\n",
    "df_join_url = pd.merge(df_urls_milk,df_cmt_process,how='inner',on='URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['_id_x','_id_y','headline_y'],inplace=True)\n",
    "df_join_url.rename(columns={\"headline_x\":\"headline\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง QAP mathod case2,4\n",
    "df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol))\n",
    "\n",
    "# ทดลอง QAP mathod  case1,5\n",
    "#df_join_url['token_text_reduce'] = df_join_url['token_text'].apply(lambda x: reduced_keyword(x, reduceCol_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_join_url.set_index('commentId',inplace=True)\n",
    "df_join_url.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(df_join_url['token_text_reduce'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dictionary_tfidf = gensim.corpora.Dictionary(df_join_url['token_text_reduce_tfidf'])\n",
    "gensim_corpus = [dictionary_tfidf.doc2bow(text, allow_update=True) for text in df_join_url['token_text_reduce_tfidf']]\n",
    "tfidf_model = TfidfModel(gensim_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url['reduce_bow'] = df_join_url[\"token_text_reduce\"].map(dictionary.doc2bow)\n",
    "df_join_url['reduce_bow_txt'] = df_join_url[\"reduce_bow\"].apply(lambda x:[(dictionary[id_], frequence) for id_, frequence in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['Retrived_date','reduce_bow'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_join_url.insert(3,'mention_domain',value=None)\n",
    "df_join_url.insert(4,'mention_product',value=None)\n",
    "df_join_url.insert(5,'mention_brand',value=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute brand & product เข้า comment และสรุปก่อนเข้า BoW"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Impute จากหัวกระทู้\n",
    "\n",
    "# 1.headline มี comment มี เอา comment\n",
    "# 2.headline มี comment ไม่มี เอา headline\n",
    "# 3.headline ไม่มี comment มี เอา comment\n",
    "# 4.ไม่มีทั้งคู่ ปล่อยไป"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) > 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.t_mention_dairy.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_dairy.iloc[i]) == 0) & (len(df_join_url.cmt_mention_dairy.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_domain'].iloc[i] = df_join_url.cmt_mention_dairy.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_domain'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) > 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.t_mention_brand.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_brand.iloc[i]) == 0) & (len(df_join_url.cmt_mention_brand.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_brand'].iloc[i] = df_join_url.cmt_mention_brand.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_brand'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,e in enumerate(df_join_url.index,0):\n",
    "    if (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):         # 1.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) > 0) & (len(df_join_url.cmt_mention_product.iloc[i]) == 0):  # 2.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.t_mention_product.iloc[i]\n",
    "    elif  (len(df_join_url.t_mention_product.iloc[i]) == 0) & (len(df_join_url.cmt_mention_product.iloc[i]) > 0):  # 3.\n",
    "        df_join_url['mention_product'].iloc[i] = df_join_url.cmt_mention_product.iloc[i]\n",
    "    else:\n",
    "        df_join_url['mention_product'].iloc[i] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join_url.drop(columns=['t_mention_dairy','t_mention_product','t_mention_brand'\n",
    "                          ,'cmt_mention_dairy','cmt_mention_product','cmt_mention_brand'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "tfidf_list = []\n",
    "for doc in tfidf_model[gensim_corpus]:\n",
    "    tfidf_list.append([(dictionary_tfidf[id], np.around(freq, decimals=4)) for id, freq in doc])\n",
    "df_join_url.insert(11,'reduce_tfidf',value=tfidf_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "concat Brand + Product มาต่อกันเพื่อระบุตราและยี่ห้อ เพื่อลงระดับ flavor"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_join_url['mention_domain_count'] = df_join_url['mention_domain'].apply(lambda x: 0 if x is None else len(x))\n",
    "df_join_url['mention_product_count'] = df_join_url['mention_product'].apply(lambda x: 0 if x is None else len(x))\n",
    "df_join_url['mention_brand_count'] = df_join_url['mention_brand'].apply(lambda x: 0 if x is None else len(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor = df_join_url[(df_join_url['mention_brand_count']>0)&(df_join_url['mention_product_count']>0)]\n",
    "df_withOutFlavor = df_join_url[(df_join_url['mention_brand_count']<=0)|(df_join_url['mention_product_count']<=0)]\n",
    "df_withFlavor['concat_domain'] = df_withFlavor['mention_domain'].apply(lambda x: x if x is None else list(set(x)))\n",
    "df_withFlavor['concat_brand'] = df_withFlavor['mention_brand'].apply(lambda x: x if x is None else list(set(x)))\n",
    "df_withFlavor['concat_product'] = df_withFlavor['mention_product'].apply(lambda x: x if x is None else list(set(x)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor['mention_product'] = df_withFlavor.apply(lambda x: concat_flavor(x.concat_brand,x.concat_product), axis=1)\n",
    "df_withFlavor['mention_product'] = df_withFlavor['mention_product'] .apply(lambda x: x if x is None else reduced_keyword(x,avai_flavs))\n",
    "df_withFlavor['mention_product'] = df_withFlavor['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withFlavor['mention_brand'] = df_withFlavor['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withFlavor['mention_domain'] = df_withFlavor['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withOutFlavor['mention_product'] = df_withOutFlavor['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withOutFlavor['mention_brand'] = df_withOutFlavor['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_withOutFlavor['mention_domain'] = df_withOutFlavor['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor.drop(columns=['mention_domain_count','mention_product_count','mention_brand_count'\n",
    "                          ,'concat_domain','concat_brand','concat_product'],inplace=True)\n",
    "df_withOutFlavor.drop(columns=['mention_domain_count','mention_product_count','mention_brand_count'],inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_withFlavor.head(3)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df_final = pd.concat([df_withFlavor,df_withOutFlavor], axis=0, sort=False)\n",
    "df_final.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create cooccurence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment ออกเมื่อไม่ concat brand+flavor\n",
    "df_final = df_join_url.copy()\n",
    "df_final.set_index('commentId',inplace=True)\n",
    "df_final['mention_product'] = df_final['mention_product'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_final['mention_brand'] = df_final['mention_brand'].apply(lambda x: x if x is None else freq_brand(x))\n",
    "df_final['mention_domain'] = df_final['mention_domain'].apply(lambda x: x if x is None else freq_brand(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brand_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_brand\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "df_prd_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"mention_product\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)\n",
    "df_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_final[\"reduce_bow_txt\"]], axis=1, sort=False).fillna(0).T.set_index(df_final.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# TF-IDF Matrix\n",
    "df_tfidf_cooc = pd.concat([pd.DataFrame(s,columns=['w','c']).set_index('w') for s in df_join_url[\"reduce_tfidf\"]], axis=1, sort=False).fillna(0).T.set_index(df_join_url.index)\n",
    "df_tfidf_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_brand_cooc.reset_index(inplace=True)\n",
    "df_prd_cooc.reset_index(inplace=True)\n",
    "df_cooc.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ทดลอง  QAP mathod case2,4\n",
    "#join_df = pd.merge(df_brand_cooc, df_prd_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "#join_df = pd.merge(join_df, df_cooc, on='commentId', how='inner')\n",
    "\n",
    "# ทดลอง  QAP mathod case3\n",
    "#join_df = pd.merge(df_prd_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "# ทดลอง  QAP mathod case1,5\n",
    "join_df = pd.merge(df_brand_cooc, df_cooc, on='commentId', how='inner', suffixes=(False, False))\n",
    "\n",
    "\n",
    "join_df.set_index('commentId',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export ข้อมูล เพื่อนำไปสุ่มแถวทำ QAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df.to_csv(root_output_path+\"/cooc_bow_all.csv\",index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBBA36fDTCfZ"
   },
   "source": [
    "## Create frequency co-occurrence matrix จาก Bag of word<br>\n",
    "* ใช้สำหรับทำ MDS และโยนเข้า R (ทำ normalized บน R) ในลักษณะ Term-Term Cross tabulation<br> \n",
    "(คนละอย่างกับ TF-IDF cooc matrix ที่เป็น Word-word ซึ่งต้องรัน bigram เป็นราย document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgE1okejTCfZ"
   },
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnt_Grpby(df,i,j):\n",
    "    PAIB = pd.DataFrame(df.groupby(df.iloc[:,i].name)[df.iloc[:,j].name].value_counts())\n",
    "    PAIB.index.names = ['A','B']\n",
    "    PAIB.columns = ['freq']\n",
    "    PAIB.reset_index(inplace=True)\n",
    "    _PAIB = PAIB[(PAIB.A>0)&(PAIB.B>0)]\n",
    "    return _PAIB.freq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I like machine learning love NLP\n",
    "#cnt_Grpby(pd.DataFrame([[1,1,1,1,0,0],[1,0,0,0,1,1]]),0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1jhFte5eTCfd"
   },
   "outputs": [],
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        if i != j:\n",
    "            item_item_matrix.iloc[i,j] = cnt_Grpby(join_df,i,j)\n",
    "        else:\n",
    "            item_item_matrix.iloc[i,j] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OhtvLfMXTCfg"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsbsqduDTCfh"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_freq_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8nlNNE4TCfj"
   },
   "source": [
    "### Create co-occurrence matrix with Lift normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qykd9Z88TCfj"
   },
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ElfF27atTCfp"
   },
   "outputs": [],
   "source": [
    "def a_in_b(df,i,j):\n",
    "    PAIB = pd.DataFrame(df.groupby(df.iloc[:,i].name)[df.iloc[:,j].name].value_counts())\n",
    "    PAIB.index.names = ['A','B']\n",
    "    PAIB.columns = ['freq']\n",
    "    PAIB.reset_index(inplace=True)\n",
    "    PAIB_ = PAIB[(PAIB.A>0)&(PAIB.B>0)]\n",
    "    return PAIB_.freq.sum()/PAIB.freq.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h1sDGAMWTCfr"
   },
   "outputs": [],
   "source": [
    "for i in range(0,len(item_item_matrix.columns)) :\n",
    "    for j in range(0,len(item_item_matrix.columns)) :\n",
    "        A = join_df.iloc[:,i]\n",
    "        B = join_df.iloc[:,j]\n",
    "        #PA = A[A!=0].count()/A.shape[0]\n",
    "        #PB = B[B!=0].count()/B.shape[0]\n",
    "        #PB_ = B[B==0].count()/B.shape[0]\n",
    "        #PAB = PB*a_in_b(join_df,i,j)\n",
    "        #item_item_matrix.iloc[i,j] = PAB/(PA*PB)\n",
    "        item_item_matrix.iloc[i,j] = lift_score(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wzd336KbTCfs"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "item_item_matrix.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qG7pCYfTCfu"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_lift_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create co-occurrence matrix with Jaccard Distance<br>\n",
    "* สำหรับทำ Robusness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        item_item_matrix.iloc[i,j] = jaccard_score(join_df.iloc[i],join_df.iloc[j], average='weighted')\n",
    "item_item_matrix.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LsZZMOcTTCfw"
   },
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_jacc_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create pearson correlation matrix<br>\n",
    "* สำหรับทำ Robusness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        item_item_matrix.iloc[i,j] = scipy.stats.pearsonr(join_df.iloc[i],join_df.iloc[j])[0]\n",
    "item_item_matrix.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_corr_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create cosine similarity correlation matrix<br>\n",
    "* สำหรับทำ Robusness check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = pd.DataFrame(index=join_df.columns,columns=join_df.columns).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Co-occurrence\n",
    "for i in range(0,len(item_item_matrix.columns)):\n",
    "    for j in range(0,len(item_item_matrix.columns)):\n",
    "        item_item_matrix.iloc[i,j] = 1 - cosine(join_df.iloc[i],join_df.iloc[j])\n",
    "item_item_matrix.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix.to_excel(comment_cooc_cosine_file, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### สุ่มตัดจำนวน Row-Col เพื่อนำไปทำ QAP Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "สุ่ม Document 1/16, 1/8, 1/4, 1/2 เอามาทำ Cooc-matrix แล้วไล่ทำ QAP เทียบ 9000 doc กับ 4 ชุด dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(all='ignore')\n",
    "df_cooc_frq = pd.read_csv(root_output_path+\"/cooc_bow_all.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rand1 = df_cooc_frq.sample(frac=(1/16))\n",
    "df_rand2 = df_cooc_frq.sample(frac=(1/8))\n",
    "df_rand3 = df_cooc_frq.sample(frac=(1/4))\n",
    "df_rand4 = df_cooc_frq.sample(frac=(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_rand1.shape[0],df_rand2.shape[0],df_rand3.shape[0],df_rand4.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_RandomcoccMat_Lift(df):\n",
    "    item_item_matrix = pd.DataFrame(index=df.columns,columns=df.columns).fillna(0)\n",
    "    for i in range(0,len(item_item_matrix.columns)) :\n",
    "        for j in range(0,len(item_item_matrix.columns)) :\n",
    "            A = df.iloc[:,i]\n",
    "            B = df.iloc[:,j]\n",
    "            item_item_matrix.iloc[i,j] = lift_score(A,B)\n",
    "    item_item_matrix.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "    item_item_matrix.fillna(0,inplace=True)\n",
    "    return item_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_RandomcoccMat_Lift(df_rand1)\n",
    "item_item_matrix.to_excel('lift1.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_RandomcoccMat_Lift(df_rand2)\n",
    "item_item_matrix.to_excel('lift2.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_RandomcoccMat_Lift(df_rand3)\n",
    "item_item_matrix.to_excel('lift3.xlsx', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_item_matrix = create_RandomcoccMat_Lift(df_rand4)\n",
    "item_item_matrix.to_excel('lift4.xlsx', index=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "EpwX95XlTCdl",
    "_Q9pU1J6TCe5",
    "NKW--A73mzli",
    "uBBA36fDTCfZ",
    "O8nlNNE4TCfj"
   ],
   "name": "EDA_Token_CoocMat.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
